{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import time\n",
    "import json\n",
    "import heapq\n",
    "import itertools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import colormaps\n",
    "import pickle\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "import seaborn as sns\n",
    "from torch_geometric.data import Data\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap, BoundaryNorm\n",
    "from typing import Union\n",
    "import networkx as nx\n",
    "\n",
    "from env.graph_env import copy_graph, Indices, is_stable, in_table_index, get_node_poses\n",
    "from env.graph_env import create_graph, flatten_pos, unflatten_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEFAULT_SIZES = {\n",
    "\t\t# non-container\n",
    "\t\t0: (7, 7), # fork, spoon, knife  /  yellow\n",
    "\t\t1: (11, 11), # apple, pear  /  orange\n",
    "\t\t2: (17, 17), # banana  /  orange\n",
    "\t\t# container\n",
    "\t\t3: (11, 11), # cup, mug  /  green\n",
    "\t\t4: (17, 17), # bowl  /  green\n",
    "\t\t5: (21, 21), # basket, box  /  blue\n",
    "\t\t6: (27, 27), # pan  /  blue\n",
    "\t}\n",
    "\n",
    "def copy_state(state):\n",
    "\treturn {'graph': copy_graph(state['graph']), 'manipulator': state['manipulator'].clone()}\n",
    "\n",
    "def find_target_obj(graph, node):\n",
    "\ti = (graph.x[node, Indices.RELATION] == 1).nonzero(as_tuple=True)[0]\n",
    "\tif len(i):\n",
    "\t\treturn i.item()\n",
    "\treturn None\n",
    "\n",
    "def find_start_obj(graph, node):\n",
    "\ti = (graph.x[:, Indices.RELATION.start + node] == 1).nonzero(as_tuple=True)[0]\n",
    "\tif len(i):\n",
    "\t\treturn i.item()\n",
    "\treturn None\n",
    "\n",
    "def is_empty_object(graph, node):\n",
    "\treturn find_start_obj(graph, node) is None\n",
    "\n",
    "def is_edge_in_graph(graph, node1, node2):\n",
    "\tif graph.x[node1, Indices.RELATION.start + node2] == 0:\n",
    "\t\treturn False\n",
    "\treturn True\n",
    "\n",
    "def is_stacked_object(graph, node):\n",
    "\treturn graph.x[node, Indices.RELATION].sum() > 0\n",
    "\n",
    "def is_in_env(coor, size, grid_size):\n",
    "\tif coor[0] - size[0]//2 < 0 or coor[0] + size[0]//2 >= grid_size[0]:\n",
    "\t\treturn False\n",
    "\tif coor[1] - size[1]//2 < 0 or coor[1] + size[1]//2 >= grid_size[1]:\n",
    "\t\treturn False\n",
    "\treturn True\n",
    "\n",
    "def find_base_obj(graph, node):\n",
    "\twhile is_stacked_object(graph, node):\n",
    "\t\tnode = find_target_obj(graph, node)\n",
    "\treturn node\n",
    "\n",
    "def find_occupying_objs(table, coor, size):\n",
    "\toccupying_objs = []\n",
    "\tunique_nums = np.unique(table[in_table_index(coor, size)])\n",
    "\n",
    "\tfor num in unique_nums:\n",
    "\t\tif num == 0:\n",
    "\t\t\tcontinue\n",
    "\t\toccupying_objs.append(num-1)\n",
    "\n",
    "\treturn occupying_objs\n",
    "\n",
    "def get_obj_pos(graph, node):\n",
    "\treturn graph.x[node, Indices.COORD].clone()\n",
    "\n",
    "def get_obj_size(graph, node):\n",
    "\treturn graph.x[node, Indices.SIZE].clone().tolist()\n",
    "\n",
    "def get_obj_label(graph, node):\n",
    "\treturn graph.x[node, Indices.LABEL].item()\n",
    "\n",
    "def get_empty_objs(env, ref_node, n=1):\n",
    "\tall_objects = list(range(env.num_objects))\n",
    "\tnp.random.shuffle(all_objects)\n",
    "\n",
    "\tempty_objs = []\n",
    "\tfor obj in all_objects:\n",
    "\t\tif is_empty_object(env.state_graph, obj) and is_stable(env.state_graph.x, ref_node, obj):\n",
    "\t\t\tempty_objs.append(obj)\n",
    "\t\t\tif len(empty_objs) >= n:\n",
    "\t\t\t\tbreak\n",
    "\t\t\t\n",
    "\treturn empty_objs\n",
    "\n",
    "def get_all_positions_of_object(coord, size):\n",
    "    idx = in_table_index(coord, size)\n",
    "    x_range = np.arange(idx[0].start, idx[0].stop)\n",
    "    y_range = np.arange(idx[1].start, idx[1].stop)\n",
    "    x, y = np.meshgrid(x_range, y_range, indexing='ij')\n",
    "    return np.column_stack((x.ravel(), y.ravel()))\n",
    "\n",
    "def score(env, coor, obj):\n",
    "\tdis_obj = torch.norm(get_obj_pos(env.target_graph, obj) - coor).item()\n",
    "\treturn env.occupied_score(coor, obj) + dis_obj * env.normalization_factor\n",
    "\n",
    "def get_all_positions_in_env(grid_size, size):\n",
    "    x_range = np.arange(size[0] // 2, grid_size[0] - size[0] // 2)\n",
    "    y_range = np.arange(size[1] // 2, grid_size[1] - size[1] // 2)\n",
    "    x, y = np.meshgrid(x_range, y_range, indexing='ij')\n",
    "    return np.column_stack((x.ravel(), y.ravel()))\n",
    "\n",
    "def get_empty_positions(env, ref_node, n=1, sort=False):\n",
    "\tref_size = get_obj_size(env.state_graph, ref_node)\n",
    "\tall_positions = get_all_positions_in_env(env.grid_size, ref_size)\n",
    "\tif sort:\n",
    "\t\tall_positions = sorted(all_positions, key=lambda x: score(env, x, ref_node))\n",
    "\telse:\n",
    "\t\tnp.random.shuffle(all_positions)\n",
    "\n",
    "\tpositions = []\n",
    "\tfor position in all_positions:\n",
    "\t\tposition = torch.tensor(position, dtype=torch.float32)\n",
    "\t\tif not env.is_coor_occupied(position, ref_node):\n",
    "\t\t\tpositions.append(flatten_pos(position, env.grid_size))\n",
    "\t\t\tif len(positions) >= n:\n",
    "\t\t\t\tbreak\n",
    "\n",
    "\treturn positions\n",
    "\n",
    "def get_empty_positions_with_target(env, ref_node, n=1, sort=False):\n",
    "\tpositions = []\n",
    "\ttarget_pos = get_obj_pos(env.target_graph, ref_node)\n",
    "\tif not env.is_coor_occupied(target_pos, ref_node):\n",
    "\t\t# TK is free\n",
    "\t\tpositions.append(flatten_pos(target_pos, env.grid_size))\n",
    "\telse:\n",
    "\t\tif n == 0:\n",
    "\t\t\treturn positions\n",
    "\t\t# Choose random buffer position\n",
    "\t\tfor position in get_empty_positions(env, ref_node=ref_node, n=n+1, sort=sort):\n",
    "\t\t\tif position != flatten_pos(target_pos, env.grid_size):\n",
    "\t\t\t\tpositions.append(position)\n",
    "\t\t\t\tif len(positions) >= n:\n",
    "\t\t\t\t\tbreak\n",
    "\treturn positions\n",
    "\n",
    "def draw_dependency_graph(env, fig_size=(2.5, 2.5)):\n",
    "\tdependency_graph = nx.DiGraph()\n",
    "\tfor k in range(env.num_objects):\n",
    "\t\tdependency_graph.add_node(k)\n",
    "\t\ti = find_target_obj(env.target_graph, k)\n",
    "\t\tif i is None:\n",
    "\t\t\tj = find_target_obj(env.state_graph, k)\n",
    "\t\t\tCK = get_obj_pos(env.state_graph, k)\n",
    "\t\t\tTK = get_obj_pos(env.target_graph, k)\n",
    "\t\t\tif torch.equal(CK, TK):\n",
    "\t\t\t\twhile j is not None:\n",
    "\t\t\t\t\tif not dependency_graph.has_edge(k, j):\n",
    "\t\t\t\t\t\tdependency_graph.add_edge(k, j)\n",
    "\t\t\t\t\tj = find_target_obj(env.state_graph, j)\n",
    "\t\t\telse:\n",
    "\t\t\t\tsize_k = get_obj_size(env.state_graph, k)\n",
    "\t\t\t\toccupying_nodes = find_occupying_objs(env.table, TK, size_k)\n",
    "\t\t\t\tfor j in occupying_nodes:\n",
    "\t\t\t\t\tif j != k:\n",
    "\t\t\t\t\t\tj = find_base_obj(env.state_graph, j)\n",
    "\t\t\t\t\t\tif not dependency_graph.has_edge(k, j):\n",
    "\t\t\t\t\t\t\tdependency_graph.add_edge(k, j)\n",
    "\t\telse:\n",
    "\t\t\tj = find_start_obj(env.state_graph, i)\n",
    "\t\t\tif j is not None and j != k:\n",
    "\t\t\t\tdependency_graph.add_edge(k, j)\n",
    "\n",
    "\tfig, ax = plt.subplots(1, 1, figsize=fig_size)\n",
    "\tnx.draw(dependency_graph, env.state_graph.pos, with_labels=True, node_size=400, ax=ax, node_color='skyblue')\n",
    "\tplt.title('Dependency Graph')\n",
    "\tplt.show()\n",
    "\n",
    "def draw_manipulator_decoding(env):\n",
    "\theight_grid, width_grid = env.grid_size\n",
    "\ttable = np.zeros(env.grid_size, dtype=int)\n",
    "\n",
    "\tfor i in range(height_grid):\n",
    "\t\tfor j in range(width_grid):\n",
    "\t\t\ttable[i, j] = env.manipulator_decode([i, j])[0]\n",
    "\n",
    "\tplt.imshow(table, cmap='viridis')\n",
    "\tplt.show()\n",
    "\n",
    "def env_cost(env, actions, initial_scene, target_scene, log=True):\n",
    "\tenv.reset(initial_scene, target_scene)\n",
    "\tif actions is None:\n",
    "\t\treturn None\n",
    "\t\n",
    "\tep_cost = 0\n",
    "\tfor action in actions:\n",
    "\t\tep_cost += env.step(action, log=log)[0]\n",
    "\tif log:\n",
    "\t\tprint(f'episode cost: {ep_cost:.3f}')\n",
    "\tenv.reset(initial_scene, target_scene)\n",
    "\treturn ep_cost\n",
    "\n",
    "def evaluate_alg(env, alg, initial_scene, target_scene, **kwargs):\n",
    "\tenv.reset(initial_scene, target_scene)\n",
    "\tprint(f\"--------{alg.__name__}--------\")\n",
    "\tplan, steps, elapsed_time = alg(env).solve(**kwargs)\n",
    "\n",
    "\tprint(f'plan: {plan}')\n",
    "\tprint(f'elapsed time: {elapsed_time:.2f}s | steps: {steps}')\n",
    "\tif plan is not None:\n",
    "\t\tenv_cost(env, plan, initial_scene, target_scene)\n",
    "\tenv.reset(initial_scene, target_scene)\n",
    "\treturn plan\n",
    "\n",
    "def positional_encode(one_hot_position):\n",
    "\tpositions = torch.argmax(one_hot_position, dim=1)\n",
    "\tencodings = torch.zeros((len(positions), 1))\n",
    "\n",
    "\tfor i, position in enumerate(positions):\n",
    "\t\tif torch.sum(one_hot_position[i]) == 0:\n",
    "\t\t\tencodings[i] = -1\n",
    "\t\telse:\n",
    "\t\t\tencodings[i] = position\n",
    "\n",
    "\treturn encodings\n",
    "\n",
    "def cal_density(graph, grid_size):\n",
    "\tphi = 0\n",
    "\tfor i in range(graph.num_nodes):\n",
    "\t\tsize_i = get_obj_size(graph, i)\n",
    "\t\tphi += (size_i[0] * size_i[1])\n",
    "\n",
    "\treturn phi / (grid_size[0] * grid_size[1])\n",
    "\n",
    "def evaluate_alg_n_times(env, alg, initial_scene, target_scene, num_runs=1, **kwargs):\n",
    "\tplan = None\n",
    "\tsteps = []\n",
    "\tcosts = []\n",
    "\telapsed_time = []\n",
    "\tbest_cost = np.inf\n",
    "\n",
    "\tprint(f\"--------{alg.__name__}--------\")\n",
    "\tfor i in range(num_runs):\n",
    "\t\tenv.reset(initial_scene, target_scene)\n",
    "\t\tplan_i, steps_i, elapsed_time_i = alg(env).solve(**kwargs)\n",
    "\t\tif plan_i:\n",
    "\t\t\tcost = env_cost(env, plan_i, initial_scene, target_scene, log=False)\n",
    "\t\t\tif cost < best_cost:\n",
    "\t\t\t\tplan = plan_i\n",
    "\t\t\tcosts.append(cost)\n",
    "\t\t\tsteps.append(steps_i)\n",
    "\t\t\telapsed_time.append(elapsed_time_i)\n",
    "\t\t# print('--')\n",
    "\t\n",
    "\tenv.reset(initial_scene, target_scene)\n",
    "\tprint(f'plan: {plan}')\n",
    "\tprint(f'mean cost: {np.mean(costs):.2f}')\n",
    "\tprint(f'mean elapsed_time: {np.mean(elapsed_time):.2f}s | mean steps: {np.mean(steps)}')\n",
    "\t\n",
    "\treturn plan\n",
    "\n",
    "def plot_graph(graph, grid_size, ax=None, fig_size=2.5, title=None, constraints=[]):\n",
    "\tif ax is None:\n",
    "\t\tfig, ax = plt.subplots(1, 1, figsize=(fig_size, fig_size*(grid_size[1]/grid_size[0])))\n",
    "\n",
    "\t# Create a color grid based on the labels and the color dictionary\n",
    "\tcolor_by_label = {\n",
    "\t\t0: 'white',\t\t# background\n",
    "\t\t1: 'yellow',\n",
    "\t\t2: 'orange',\n",
    "\t\t3: 'orange',\n",
    "\t\t4: 'green',\n",
    "\t\t5: 'green',\n",
    "\t\t6: 'blue',\n",
    "\t\t7: 'blue',\n",
    "\t\t8: 'red',\t\t# manipulator\n",
    "\t}\n",
    "\t# color_by_label = {\n",
    "\t# \t0: 'white',\t\t# background\n",
    "\t# \t1: 'yellow',\n",
    "\t# \t2: 'orange',\n",
    "\t# \t3: 'green',\n",
    "\t# \t4: 'blue',\n",
    "\t# \t5: 'red',\t\t# manipulator\n",
    "\t# }\n",
    "\n",
    "\t# Map the table values to colormap indices\n",
    "\tmapped_table = np.zeros(grid_size, dtype=int)\n",
    "\tunrendered_nodes = list(range(graph.num_nodes))\n",
    "\twhile len(unrendered_nodes) > 0:\n",
    "\t\ti = unrendered_nodes.pop(0)\n",
    "\t\tlabel_i = get_obj_label(graph, i)\n",
    "\t\tcoor_i = get_obj_pos(graph, i).numpy()\n",
    "\t\tsize_i = get_obj_size(graph, i)\n",
    "\t\tif is_stacked_object(graph, i):\n",
    "\t\t\tchild = find_target_obj(graph, i)\n",
    "\t\t\tif child in unrendered_nodes:\n",
    "\t\t\t\tunrendered_nodes.append(i)\n",
    "\t\t\t\tcontinue\n",
    "\t\t\tif label_i == 0 and (get_obj_label(graph, child) in [3, 4]):\n",
    "\t\t\t# if label_i == 0 and get_obj_label(graph, child) == 2:\n",
    "\t\t\t\tsize_i = (3, 3)\n",
    "\t\tmapped_table[in_table_index(coor_i, size_i)] = label_i + 1\n",
    "\t\n",
    "\tfor i in range(len(constraints)):\n",
    "\t\t# if the type of constraints is tensor, convert it to int\n",
    "\t\tif isinstance(constraints[i], torch.Tensor):\n",
    "\t\t\tconstraints = constraints[i].numpy()\n",
    "\t\telse:\n",
    "\t\t\tconstraints = constraints[i]\n",
    "\t\tc_x, c_y = list(map(int, constraints))\n",
    "\t\t# mapped_table[c_x, c_y] = 5\n",
    "\t\tmapped_table[c_x, c_y] = 8\n",
    "\n",
    "\t# Create a color list based on the numbers in the table\n",
    "\tunique_values = np.unique(mapped_table)\n",
    "\tcolor_list = [color_by_label[val] for val in unique_values]\n",
    "\n",
    "\t# Create a colormap and a normalization based on the unique values\n",
    "\tcmap = ListedColormap(color_list)\n",
    "\tbounds = np.append(unique_values, unique_values[-1] + 1)\n",
    "\tnorm = BoundaryNorm(bounds, cmap.N)\n",
    "\n",
    "\t# Plot the table\n",
    "\tax.imshow(mapped_table, cmap=cmap, norm=norm, origin='upper')\n",
    "\n",
    "\t# Add gridlines for better visualization\n",
    "\tax.set_xticks(np.arange(-0.5, mapped_table.shape[1], 1), minor=True)\n",
    "\tax.set_yticks(np.arange(-0.5, mapped_table.shape[0], 1), minor=True)\n",
    "\tax.grid(which='minor', color='gray', linestyle='-', linewidth=0.3)\n",
    "\tax.tick_params(which='minor', bottom=False, left=False)\n",
    "\n",
    "\t# Remove major ticks\n",
    "\tax.set_xticks([])\n",
    "\tax.set_yticks([])\n",
    "\n",
    "\t# Add labels to cells for clarity\n",
    "\tfor i in range(graph.num_nodes):\n",
    "\t\tcoor_i = get_obj_pos(graph, i).numpy()\n",
    "\t\tlabel_i = get_obj_label(graph, i)\n",
    "\t\tsize_i = get_obj_size(graph, i)\n",
    "\t\tif is_stacked_object(graph, i):\n",
    "\t\t\tchild = find_target_obj(graph, i)\n",
    "\t\t\tif label_i == 0 and (get_obj_label(graph, child) in [3, 4]):\n",
    "\t\t\t# if label_i == 0 and get_obj_label(graph, child) == 2:\n",
    "\t\t\t\tsize_i = (1, 1)\n",
    "\t\tax.text(coor_i[1]-size_i[1]//2, coor_i[0]-size_i[0]//2, str(i), ha='center', va='center', color='black')\n",
    "\t\n",
    "\tif title is not None:\n",
    "\t\tax.set_title(title)\n",
    "\n",
    "def _save_scene(file_name, initial_scene, target_scene, grid_size):\n",
    "\tdata = {\n",
    "\t\t'initial_scene': copy_graph(initial_scene),\n",
    "\t\t'target_scene': copy_graph(target_scene),\n",
    "\t\t'grid_size': grid_size,\n",
    "\t}\n",
    "\twith open(file_name, 'wb') as f:\n",
    "\t\tpickle.dump(data, f)\n",
    "\n",
    "def save_scene(file_name, env):\n",
    "\t_save_scene(file_name, env.initial_graph, env.target_graph, env.grid_size)\n",
    "\n",
    "def save_scene_json(file_name, grid_size, initial_scene, target_scene, id):\n",
    "\tnum_objects = initial_scene.num_nodes\n",
    "\t\n",
    "\t# save the scene in a json file\n",
    "\tobjs = []\n",
    "\tfor obj in range(num_objects):\n",
    "\t\tobj_label = get_obj_label(initial_scene, obj)\n",
    "\t\tobjs.append({\n",
    "\t\t\t'label': int(obj_label),\n",
    "\t\t\t'initial_pos': get_obj_pos(initial_scene, obj).tolist(),\n",
    "\t\t\t'initial_relation': initial_scene.x[obj, Indices.RELATION].clone().tolist(),\n",
    "\t\t\t'target_pos': get_obj_pos(target_scene, obj).tolist(),\n",
    "\t\t\t'target_relation': target_scene.x[obj, Indices.RELATION].clone().tolist(), \n",
    "\t\t\t'size': get_obj_size(initial_scene, obj)\n",
    "\t\t})\n",
    "\t\n",
    "\tjson_scene = {\n",
    "\t\t'id': id,\n",
    "\t\t'phi': cal_density(initial_scene, grid_size),\n",
    "\t\t'num_objects': num_objects,\n",
    "\t\t'grid_size': grid_size,\n",
    "\t\t'objects': objs\n",
    "\t}\n",
    "\t\n",
    "\t# Save the scene in a json file\n",
    "\twith open(f'{file_name}_{id}.json', 'w') as f:\n",
    "\t\tjson.dump(json_scene, f, indent=4)\n",
    "\tprint(f'Saved scene to {file_name}.json')\n",
    "\n",
    "def load_scene(file_name):\n",
    "\twith open(file_name, 'rb') as f:\n",
    "\t\tdata = pickle.load(f)\n",
    "\tinitial_scene = copy_graph(data['initial_scene'])\n",
    "\ttarget_scene = copy_graph(data['target_scene'])\n",
    "\tgrid_size = data['grid_size']\n",
    "\treturn initial_scene, target_scene, grid_size, initial_scene.num_nodes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "phi: 0.218 | uniform size: (7, 7)\n",
      "Manipulator: [14.5 14.5]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 880x440 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def get_obj_sizes(num_objects, grid_size, phi, verbose=0):\n",
    "\tobject_sizes = DEFAULT_SIZES.copy()\n",
    "\n",
    "\tif phi == 'mix':\n",
    "\t\tif verbose > 0:\n",
    "\t\t\tprint('Using default object sizes')\n",
    "\t\treturn object_sizes\n",
    "\n",
    "\tphis = []\n",
    "\tfor key in DEFAULT_SIZES.keys():\n",
    "\t\tobject_sizes[key] = (1, 1)\n",
    "\t\n",
    "\tfor _ in range(max(grid_size)//3):\n",
    "\t\ttry:\n",
    "\t\t\tgraph = create_graph(num_objects, grid_size, len(object_sizes), object_sizes, p=0.0)\n",
    "\t\texcept:\n",
    "\t\t\tbreak\n",
    "\t\tphis.append({cal_density(graph, grid_size): object_sizes.copy()})\n",
    "\t\tfor key in object_sizes.keys():\n",
    "\t\t\tobject_sizes[key] = (object_sizes[key][0]+2, object_sizes[key][1]+2)\n",
    "\t\n",
    "\tbest_phi = min(phis, key=lambda x: abs(list(x.keys())[0] - phi))\n",
    "\tif verbose > 0:\n",
    "\t\tprint(f'phi: {list(best_phi.keys())[0]:.3f} | uniform size: {list(best_phi.values())[0][0]}')\n",
    "\t\n",
    "\treturn list(best_phi.values())[0]\n",
    "\n",
    "class ContinuousEnv:\n",
    "\tdef __init__(\n",
    "\t\t\tself, mode, \n",
    "\t\t\tnum_objects, grid_size, \n",
    "\t\t\tmoving_buff=True, terminal_cost=False, \n",
    "\t\t\tphi='mix', verbose=1,\n",
    "\t\t):\n",
    "\t\tself.mode = mode\n",
    "\t\tself.num_objects = num_objects\n",
    "\t\tself.grid_size = grid_size\n",
    "\t\tself.moving_buff = moving_buff\n",
    "\t\tself.terminal_cost = terminal_cost\n",
    "\t\tself.verbose = verbose\n",
    "\t\tself.object_sizes = get_obj_sizes(num_objects, grid_size, phi, verbose=verbose)\n",
    "\n",
    "\t\tif self.mode == 'mobile':\n",
    "\t\t\tself.manipulator_initial_pos = torch.tensor([0, (self.grid_size[1]-1)/2], dtype=torch.float32)\n",
    "\t\telif self.mode == 'stationary':\n",
    "\t\t\tself.manipulator_initial_pos = torch.tensor([(self.grid_size[0]-1)/2, (self.grid_size[1]-1)/2], dtype=torch.float32)\n",
    "\t\telse:\n",
    "\t\t\traise ValueError('Invalid mode')\n",
    "\t\t\n",
    "\t\tself.normalization_factor = 1 / min(self.grid_size)\n",
    "\t\tself.manipulator = self.manipulator_initial_pos.clone()\n",
    "\t\tself.pp_cost = 0.2\n",
    "\t\tself.punish_cost = 100\n",
    "\t\tself.num_labels = len(self.object_sizes)\n",
    "\n",
    "\tdef is_terminal_state(self):\n",
    "\t\treturn torch.equal(self.state_graph.x, self.target_graph.x)\n",
    "\n",
    "\tdef remove_edge(self, node1, node2):\n",
    "\t\tmask = ~((self.state_graph.edge_index[0] == node1) & (self.state_graph.edge_index[1] == node2))\n",
    "\t\tself.state_graph.edge_index = self.state_graph.edge_index[:, mask]\n",
    "\t\tself.state_graph.x[node1][Indices.RELATION.start+node2] = 0\n",
    "\n",
    "\tdef add_edge(self, node1, node2):\n",
    "\t\tnew_edge = torch.tensor([[node1], [node2]], dtype=torch.long)\n",
    "\t\tself.state_graph.edge_index = torch.cat([self.state_graph.edge_index, new_edge], dim=1)\n",
    "\t\tself.state_graph.x[node1][Indices.RELATION.start+node2] = 1\n",
    "\n",
    "\tdef decode_action(self, action: int):\n",
    "\t\tn = self.num_objects\n",
    "\t\tm = self.grid_size[0] * self.grid_size[1]\n",
    "\t\tnum_edge_actions = n * (n - 1)\n",
    "\t\tcoordinates = 0\n",
    "\n",
    "\t\tif action < num_edge_actions:\n",
    "\t\t\taction_type = 'stack'\n",
    "\t\t\tstart_node = action // (n - 1)\n",
    "\t\t\ttarget_node = action % (n - 1)\n",
    "\t\t\tif target_node >= start_node:\n",
    "\t\t\t\ttarget_node += 1\n",
    "\t\telse:\n",
    "\t\t\taction_type = 'move'\n",
    "\t\t\tadjusted_action = action - num_edge_actions\n",
    "\t\t\tstart_node = adjusted_action // m\n",
    "\t\t\tcoordinates = adjusted_action % m\n",
    "\t\t\ttarget_node = start_node\n",
    "\n",
    "\t\treturn action_type, start_node, target_node, coordinates\n",
    "\n",
    "\tdef encode_action(self, action_type: str, start_node: int, target_node: int, coordinates: Union[int, list, np.ndarray, torch.Tensor])-> int:\n",
    "\t\t# Convert coordinate pair to flattened index if needed\n",
    "\t\tif isinstance(coordinates, torch.Tensor):\n",
    "\t\t\tcoordinates = int(flatten_pos(coordinates, self.grid_size).item())\n",
    "\t\telif isinstance(coordinates, list) or isinstance(coordinates, np.ndarray):\n",
    "\t\t\tcoordinates = int(flatten_pos(coordinates, self.grid_size))\n",
    "\n",
    "\t\tn = self.num_objects\n",
    "\t\tm = self.grid_size[0] * self.grid_size[1]\n",
    "\t\tnum_edge_actions = n * (n - 1)\n",
    "\n",
    "\t\tif action_type == 'stack':\n",
    "\t\t\tif target_node >= start_node:\n",
    "\t\t\t\ttarget_node -= 1\n",
    "\t\t\taction = start_node * (n - 1) + target_node\n",
    "\t\telif action_type == 'move':\n",
    "\t\t\taction = num_edge_actions + start_node * m + coordinates\n",
    "\t\telse:\n",
    "\t\t\traise ValueError('Invalid action type')\n",
    "\n",
    "\t\treturn action\n",
    "\n",
    "\tdef create_graph(self, labels=None, stack=True, ratio=0.5):\n",
    "\t\tif stack:\n",
    "\t\t\treturn create_graph(self.num_objects, self.grid_size, self.num_labels, self.object_sizes, labels, p=0.9, ratio=ratio)\n",
    "\t\telse:\n",
    "\t\t\treturn create_graph(self.num_objects, self.grid_size, self.num_labels, self.object_sizes, labels, p=0.0, ratio=ratio)\n",
    "\n",
    "\tdef get_state(self):\n",
    "\t\treturn {'graph': copy_graph(self.state_graph), 'manipulator': self.manipulator.clone()}\n",
    "\n",
    "\tdef set_state(self, state):\n",
    "\t\tself.state_graph = copy_graph(state['graph'])\n",
    "\t\tself.manipulator = state['manipulator'].clone()\n",
    "\t\tself.make_table()\n",
    "\n",
    "\tdef make_table(self, state_graph=None):\n",
    "\t\tif state_graph is None:\n",
    "\t\t\tstate_graph = self.state_graph\n",
    "\n",
    "\t\tself.table = np.zeros(self.grid_size, dtype=int)\n",
    "\t\tfor i in range(self.num_objects):\n",
    "\t\t\tif is_stacked_object(state_graph, i):\n",
    "\t\t\t\tcontinue\n",
    "\t\t\tcoor_i = get_obj_pos(state_graph, i).tolist()\n",
    "\t\t\tsize_i = get_obj_size(state_graph, i)\n",
    "\t\t\tself.table[in_table_index(coor_i, size_i)] = i+1\n",
    "\n",
    "\tdef make_target_table(self):\n",
    "\t\tself.target_table = np.zeros(self.grid_size, dtype=int)\n",
    "\t\tfor i in range(self.num_objects):\n",
    "\t\t\tif is_stacked_object(self.target_graph, i):\n",
    "\t\t\t\tcontinue\n",
    "\t\t\tcoor_i = get_obj_pos(self.target_graph, i).numpy()\n",
    "\t\t\tsize_i = get_obj_size(self.target_graph, i)\n",
    "\t\t\tself.target_table[in_table_index(coor_i, size_i)] = i+1\n",
    "\n",
    "\tdef reset(self, state_graph=None, target_graph=None, stack=True, ratio=0.5):\n",
    "\t\tself.steps = 0\n",
    "\t\tif state_graph is None:\n",
    "\t\t\tself.state_graph = self.create_graph(stack=stack, ratio=ratio)\n",
    "\t\telse:\n",
    "\t\t\tself.state_graph = copy_graph(state_graph)\n",
    "\t\t\tfor i in range(self.num_objects):\n",
    "\t\t\t\tlabel_i = get_obj_label(self.state_graph, i)\n",
    "\t\t\t\tself.object_sizes[label_i] = get_obj_size(self.state_graph, i)\n",
    "\n",
    "\t\tself.initial_graph = copy_graph(self.state_graph)\n",
    "\t\tlabels = list(self.state_graph.x[:, Indices.LABEL].reshape(-1).numpy())\n",
    "\t\tlabels = list(map(int, labels))\n",
    "\t\tif target_graph is None:\n",
    "\t\t\tself.target_graph = self.create_graph(labels, stack=stack, ratio=1-ratio)\n",
    "\t\t\twhile torch.equal(self.state_graph.x, self.target_graph.x):\n",
    "\t\t\t\tself.target_graph = self.create_graph(labels, stack=stack, ratio=1-ratio)\n",
    "\t\telse:\n",
    "\t\t\tself.target_graph = copy_graph(target_graph)\n",
    "\t\t\ttarget_labels = list(self.target_graph.x[:, Indices.LABEL].reshape(-1).numpy())\n",
    "\t\t\ttarget_labels = list(map(int, target_labels))\n",
    "\t\t\t# check whether the target graph has the same labels as the state graph\n",
    "\t\t\tif labels != target_labels:\n",
    "\t\t\t\traise ValueError('Target graph has different labels than the state graph')\n",
    "\t\t\n",
    "\t\tif stack is False:\n",
    "\t\t\tif torch.sum(self.state_graph.x[:, Indices.RELATION]) > 0:\n",
    "\t\t\t\traise ValueError('Initial graph has edges in Non-stack mode')\n",
    "\t\t\tif torch.sum(self.target_graph.x[:, Indices.RELATION]) > 0:\n",
    "\t\t\t\traise ValueError('Target graph has edges in Non-stack mode')\n",
    "\t\t\t\n",
    "\t\tself.manipulator = self.manipulator_initial_pos.clone()\n",
    "\t\tself.make_table()\n",
    "\t\tself.make_target_table()\n",
    "\t\treturn self.get_state(), {}\n",
    "\n",
    "\tdef render(self, with_target=True, fig_size=2.5, return_fig=False, manipulator=False):\n",
    "\t\tif self.verbose > 0:\n",
    "\t\t\tprint(f'Manipulator: {self.manipulator.numpy()}')\n",
    "\t\tconstraints = [self.manipulator] if manipulator else []\n",
    "\n",
    "\t\tif with_target:\n",
    "\t\t\tscale = max(self.grid_size) / min(self.grid_size)\n",
    "\t\t\tfig, ax = plt.subplots(1, 2, figsize=(fig_size*2*scale, fig_size))\n",
    "\t\t\tplot_graph(self.state_graph, self.grid_size, ax=ax[0], fig_size=fig_size, title='State Scene', constraints=constraints)\t\n",
    "\t\t\tplot_graph(self.target_graph, self.grid_size, ax=ax[1], fig_size=fig_size, title='Target Scene')\n",
    "\t\t\tplt.suptitle(f\"Density: {cal_density(self.state_graph, self.grid_size):.2f}\")\n",
    "\t\telse:\n",
    "\t\t\tfig, ax = plt.subplots(1, 1, figsize=(fig_size, fig_size))\n",
    "\t\t\tplot_graph(self.state_graph, self.grid_size, ax=ax, fig_size=fig_size, title='State Scene', constraints=constraints)\t\t\t\n",
    "\n",
    "\t\tif return_fig:\n",
    "\t\t\tplt.close()\n",
    "\t\t\treturn fig\n",
    "\t\telse:\n",
    "\t\t\tplt.show()\n",
    "\n",
    "\tdef get_valid_stacks(self):\n",
    "\t\tvalid_stacks = []\n",
    "\n",
    "\t\tfor k in range(self.num_objects):\n",
    "\t\t\tif not self.moving_buff and not is_empty_object(self.state_graph, k):\n",
    "\t\t\t\tcontinue\n",
    "\t\t\tfor i in get_empty_objs(self, ref_node=k, n=np.inf):\n",
    "\t\t\t\tvalid_stacks.append(self.encode_action('stack', k, i, 0))\n",
    "\n",
    "\t\treturn valid_stacks\n",
    "\t\n",
    "\tdef get_valid_moves(self, max_num=10):\n",
    "\t\tvalid_moves = []\n",
    "\n",
    "\t\tfor k in range(self.num_objects):\n",
    "\t\t\tif not self.moving_buff and not is_empty_object(self.state_graph, k):\n",
    "\t\t\t\tcontinue\n",
    "\t\t\tfor position in get_empty_positions(self, ref_node=k, n=max_num):\n",
    "\t\t\t\tvalid_moves.append(self.encode_action('move', k, k, position))\n",
    "\n",
    "\t\treturn valid_moves\n",
    "\n",
    "\tdef get_valid_actions(self):\n",
    "\t\treturn self.get_valid_stacks() + self.get_valid_moves()\n",
    "\n",
    "\tdef move_obj_with_stacked_ones(self, node, coordinates):\n",
    "\t\tvisited = [False] * self.num_objects\n",
    "\t\tvisited[node] = True\n",
    "\t\tstack = [node]\n",
    "\t\twhile len(stack) > 0:\n",
    "\t\t\tnode = stack.pop()\n",
    "\t\t\tself.state_graph.x[node, Indices.COORD] = coordinates.clone()\n",
    "\t\t\ti = find_start_obj(self.state_graph, node)\n",
    "\t\t\tif i is not None and not visited[i]:\n",
    "\t\t\t\tstack.append(i)\n",
    "\t\t\t\tvisited[i] = True\n",
    "\n",
    "\tdef is_coor_occupied(self, coor, node, table=None):\n",
    "\t\tif table is None:\n",
    "\t\t\ttable = self.table\n",
    "\t\t\n",
    "\t\tsize = get_obj_size(self.state_graph, node)\n",
    "\t\tif torch.equal(coor, get_obj_pos(self.state_graph, node)):\n",
    "\t\t\treturn True\n",
    "\t\tif not is_in_env(coor, size, self.grid_size):\n",
    "\t\t\treturn True\n",
    "\t\tif np.any((table[in_table_index(coor, size)] != 0) & (table[in_table_index(coor, size)] != node+1)):\n",
    "\t\t\treturn True\n",
    "\t\t\n",
    "\t\treturn False\n",
    "\n",
    "\tdef occupied_score(self, coor, node, table=None):\n",
    "\t\tif table is None:\n",
    "\t\t\ttable = self.target_table\n",
    "\t\t\n",
    "\t\tsize = get_obj_size(self.state_graph, node)\n",
    "\t\toccupied = np.sum((table[in_table_index(coor, size)] != 0) & (table[in_table_index(coor, size)] != node+1))\n",
    "\t\treturn occupied / (size[0] * size[1])\n",
    "\n",
    "\tdef manipulator_decode(self, coord):\n",
    "\t\tx, y = coord.tolist()\n",
    "\t\theight, width = self.grid_size\n",
    "\t\td_t, d_l, d_b, d_r = x, y, height-1-x, width-1-y\n",
    "\t\tmin_d = min(d_t, d_l, d_b, d_r)\n",
    "\n",
    "\t\tif min_d == d_t:\n",
    "\t\t\treturn 0, y, width-1-y\n",
    "\t\telif min_d == d_r:\n",
    "\t\t\treturn 1, x, height-1-x\n",
    "\t\telif min_d == d_b:\n",
    "\t\t\treturn 2, width-1-y, y\n",
    "\t\telse:\n",
    "\t\t\treturn 3, height-1-x, x\n",
    "\n",
    "\tdef cal_manipulator_movement(self, pre_coord, new_coord):\n",
    "\t\tif self.mode == 'mobile':\n",
    "\t\t\tpre_s, pre_cc, pre_cw = self.manipulator_decode(pre_coord)\n",
    "\t\t\tnew_s, new_cc, new_cw = self.manipulator_decode(new_coord)\n",
    "\t\t\tif pre_s == new_s:\n",
    "\t\t\t\tif pre_s == 0 or pre_s == 2:\n",
    "\t\t\t\t\treturn torch.norm(pre_coord[1] - new_coord[1]).item()\n",
    "\t\t\t\telse:\n",
    "\t\t\t\t\treturn torch.norm(pre_coord[0] - new_coord[0]).item()\n",
    "\t\t\telif (new_s==1 and pre_s==3) or (new_s==3 and pre_s==1):\n",
    "\t\t\t\treturn min(pre_cw + new_cc, pre_cc + new_cw) + self.grid_size[1]\n",
    "\t\t\telif (new_s==2 and pre_s==0) or (new_s==0 and pre_s==2):\n",
    "\t\t\t\treturn min(pre_cw + new_cc, pre_cc + new_cw) + self.grid_size[0]\n",
    "\t\t\telif new_s == pre_s+1 or (new_s == 0 and pre_s == 3):\n",
    "\t\t\t\treturn pre_cw + new_cc + 1\n",
    "\t\t\telse:\n",
    "\t\t\t\treturn pre_cc + new_cw + 1\n",
    "\t\telif self.mode == 'stationary':\n",
    "\t\t\treturn torch.norm(pre_coord - new_coord).item()\n",
    "\n",
    "\tdef cal_movement(self, pre_coord, new_coord):\n",
    "\t\ttotal_movement = 0\n",
    "\t\ttotal_movement += self.cal_manipulator_movement(self.manipulator, pre_coord)\n",
    "\t\ttotal_movement += self.cal_manipulator_movement(pre_coord, new_coord)\n",
    "\t\tif self.mode == 'mobile':\n",
    "\t\t\tnew_s = self.manipulator_decode(new_coord)[0]\n",
    "\t\t\tif new_s == 0:\n",
    "\t\t\t\tself.manipulator = torch.tensor([0, new_coord[1]], dtype=torch.float32)\n",
    "\t\t\telif new_s == 1:\n",
    "\t\t\t\tself.manipulator = torch.tensor([new_coord[0], self.grid_size[1]-1], dtype=torch.float32)\n",
    "\t\t\telif new_s == 2:\n",
    "\t\t\t\tself.manipulator = torch.tensor([self.grid_size[0]-1, new_coord[1]], dtype=torch.float32)\n",
    "\t\t\telse:\n",
    "\t\t\t\tself.manipulator = torch.tensor([new_coord[0], 0], dtype=torch.float32)\n",
    "\t\telif self.mode == 'stationary':\n",
    "\t\t\tself.manipulator = new_coord.clone()\n",
    "\n",
    "\t\treturn total_movement * self.normalization_factor\n",
    "\n",
    "\tdef move_free_obj_func(self, start_node, coordinates):\n",
    "\t\tif not is_empty_object(self.state_graph, start_node):\n",
    "\t\t\tprint(f'can not move non-empty objects')\n",
    "\t\t\tcost = self.punish_cost\n",
    "\t\telif self.is_coor_occupied(coordinates, start_node):\n",
    "\t\t\tprint(f'occupied {coordinates.numpy()}')\n",
    "\t\t\tcost = self.punish_cost\n",
    "\t\telse:\n",
    "\t\t\tprev_target = find_target_obj(self.state_graph, start_node)\n",
    "\t\t\tif prev_target is not None:\n",
    "\t\t\t\tself.remove_edge(start_node, prev_target)\n",
    "\t\t\tprev_coord = get_obj_pos(self.state_graph, start_node)\n",
    "\t\t\tself.state_graph.x[start_node, Indices.COORD] = coordinates.clone()\n",
    "\t\t\tcost = self.cal_movement(prev_coord, coordinates)\n",
    "\t\t\n",
    "\t\treturn cost\n",
    "\n",
    "\tdef move_func(self, start_node, coordinates):\n",
    "\t\tif self.is_coor_occupied(coordinates, start_node):\n",
    "\t\t\tprint(f'occupied {coordinates.numpy()}')\n",
    "\t\t\tcost = self.punish_cost\n",
    "\t\telse:\n",
    "\t\t\tprev_target = find_target_obj(self.state_graph, start_node)\n",
    "\t\t\tif prev_target is not None:\n",
    "\t\t\t\tself.remove_edge(start_node, prev_target)\n",
    "\t\t\tprev_coord = get_obj_pos(self.state_graph, start_node)\n",
    "\t\t\tself.move_obj_with_stacked_ones(start_node, coordinates)\n",
    "\t\t\tcost = self.cal_movement(prev_coord, coordinates)\n",
    "\t\t\n",
    "\t\treturn cost\n",
    "\n",
    "\tdef stack_free_obj_func(self, start_node, target_node):\n",
    "\t\tif not is_empty_object(self.state_graph, start_node):\n",
    "\t\t\tprint(f'can not stack non-empty objects')\n",
    "\t\t\tcost = self.punish_cost\n",
    "\t\telif not is_stable(self.state_graph.x, start_node, target_node):\n",
    "\t\t\tprint(f'not stable {start_node} -> {target_node}')\n",
    "\t\t\tcost = self.punish_cost\n",
    "\t\telif not is_empty_object(self.state_graph, target_node):\n",
    "\t\t\tprint(f'obj {target_node} is not empty')\n",
    "\t\t\tcost = self.punish_cost\n",
    "\t\telse:\n",
    "\t\t\tprev_target = find_target_obj(self.state_graph, start_node)\n",
    "\t\t\tif prev_target == target_node:\n",
    "\t\t\t\tprint(f'already stacked {start_node} -> {target_node}')\n",
    "\t\t\t\tcost = self.punish_cost\n",
    "\t\t\telif prev_target is None:\n",
    "\t\t\t\tprev_coord = get_obj_pos(self.state_graph, start_node)\n",
    "\t\t\t\tdestination = get_obj_pos(self.state_graph, target_node)\n",
    "\t\t\t\tself.add_edge(start_node, target_node)\n",
    "\t\t\t\tself.state_graph.x[start_node, Indices.COORD] = destination.clone()\n",
    "\t\t\t\tcost = self.cal_movement(prev_coord, destination)\n",
    "\t\t\telse:\n",
    "\t\t\t\tprev_coord = get_obj_pos(self.state_graph, start_node)\n",
    "\t\t\t\tdestination = get_obj_pos(self.state_graph, target_node)\n",
    "\t\t\t\tself.remove_edge(start_node, prev_target)\n",
    "\t\t\t\tself.add_edge(start_node, target_node)\n",
    "\t\t\t\tself.state_graph.x[start_node, Indices.COORD] = destination.clone()\n",
    "\t\t\t\tcost = self.cal_movement(prev_coord, destination)\n",
    "\t\t\n",
    "\t\treturn cost\n",
    "\t\n",
    "\tdef stack_func(self, start_node, target_node):\n",
    "\t\tif not is_stable(self.state_graph.x, start_node, target_node):\n",
    "\t\t\tprint(f'not stable {start_node} -> {target_node}')\n",
    "\t\t\tcost = self.punish_cost\n",
    "\t\telif not is_empty_object(self.state_graph, target_node):\n",
    "\t\t\tprint(f'obj {target_node} is not empty')\n",
    "\t\t\tcost = self.punish_cost\n",
    "\t\telse:\n",
    "\t\t\tprev_target = find_target_obj(self.state_graph, start_node)\n",
    "\t\t\tif prev_target == target_node:\n",
    "\t\t\t\tprint(f'already stacked {start_node} -> {target_node}')\n",
    "\t\t\t\tcost = self.punish_cost\n",
    "\t\t\telif prev_target is None:\n",
    "\t\t\t\tprev_coord = get_obj_pos(self.state_graph, start_node)\n",
    "\t\t\t\tdestination = get_obj_pos(self.state_graph, target_node)\n",
    "\t\t\t\tself.add_edge(start_node, target_node)\n",
    "\t\t\t\tself.move_obj_with_stacked_ones(start_node, destination)\n",
    "\t\t\t\tcost = self.cal_movement(prev_coord, destination)\n",
    "\t\t\telse:\n",
    "\t\t\t\tprev_coord = get_obj_pos(self.state_graph, start_node)\n",
    "\t\t\t\tdestination = get_obj_pos(self.state_graph, target_node)\n",
    "\t\t\t\tself.remove_edge(start_node, prev_target)\n",
    "\t\t\t\tself.add_edge(start_node, target_node)\n",
    "\t\t\t\tself.move_obj_with_stacked_ones(start_node, destination)\n",
    "\t\t\t\tcost = self.cal_movement(prev_coord, destination)\n",
    "\t\t\n",
    "\t\treturn cost\n",
    "\n",
    "\tdef step_move(self, node, coordinates, log=True):\n",
    "\t\taction = self.encode_action('move', node, node, flatten_pos(coordinates, self.grid_size))\n",
    "\t\treturn self.step(action, log)\n",
    "\n",
    "\tdef step_stack(self, start_node, target_node, log=True):\n",
    "\t\taction = self.encode_action('stack', start_node, target_node, 0)\n",
    "\t\treturn self.step(action, log)\n",
    "\n",
    "\tdef step(self, action, log=False):\n",
    "\t\taction_type, start_node, target_node, coordinates = self.decode_action(action)\n",
    "\t\treturn self._step(action_type, start_node, target_node, coordinates, log=log)\n",
    "\n",
    "\tdef _step(self, action_type, start_node, target_node, coordinates, log=False):\n",
    "\t\tcoordinates = unflatten_pos(coordinates, self.grid_size)\n",
    "\t\tcost, truncated, terminated = 0.0, False, False\n",
    "\n",
    "\t\tif action_type == 'move':\n",
    "\t\t\tif self.moving_buff:\n",
    "\t\t\t\tcost += self.move_func(start_node, coordinates)\n",
    "\t\t\telse:\n",
    "\t\t\t\tcost += self.move_free_obj_func(start_node, coordinates)\n",
    "\t\telif action_type == 'stack':\n",
    "\t\t\tif self.moving_buff:\n",
    "\t\t\t\tcost += self.stack_func(start_node, target_node)\n",
    "\t\t\telse:\n",
    "\t\t\t\tcost += self.stack_free_obj_func(start_node, target_node)\n",
    "\t\t\t\t\t\n",
    "\t\tcost += self.pp_cost\n",
    "\t\t\n",
    "\t\tif self.is_terminal_state():\n",
    "\t\t\tif self.terminal_cost:\n",
    "\t\t\t\tcost += self.cal_manipulator_movement(self.manipulator, self.manipulator_initial_pos) * self.normalization_factor\n",
    "\t\t\tself.manipulator = self.manipulator_initial_pos.clone()\n",
    "\t\t\tterminated = True\n",
    "\t\n",
    "\t\tif log:\n",
    "\t\t\tif action_type == 'move':\n",
    "\t\t\t\tprint(f'Moved {start_node} to: {coordinates.numpy()} | cost: {cost:.3f} | done: {terminated or truncated}')\n",
    "\t\t\telse:\n",
    "\t\t\t\tprint(f'Stacked {start_node} -> {target_node} | cost: {cost:.3f} | done: {terminated or truncated}')\n",
    "\n",
    "\t\tself.make_table()\n",
    "\t\treturn cost, self.get_state()\n",
    "\n",
    "phi = 0.2\n",
    "num_objects = 4\n",
    "grid_size = (30, 30)\n",
    "\n",
    "env = ContinuousEnv(mode='stationary', num_objects=num_objects, grid_size=grid_size, phi=phi, verbose=1)\n",
    "env.reset(stack=False)\n",
    "initial_scene, target_scene = copy_graph(env.initial_graph), copy_graph(env.target_graph)\n",
    "env.reset(initial_scene, target_scene)\n",
    "env.render(fig_size=4.4, manipulator=False)\n",
    "# save_scene_json('scene', grid_size, initial_scene, target_scene, id=6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Algs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseSearch:\n",
    "\tdef __init__(self, env, node_class):\n",
    "\t\t\"\"\"\n",
    "\t\tBase class for search algorithms.\n",
    "\t\t:param env: The environment in which the search is performed.\n",
    "\t\t:param node_class: The class used for representing nodes in the search.\n",
    "\t\t\"\"\"\n",
    "\t\tself.env = env\n",
    "\t\tself.node_class = node_class  # Generalized node class\n",
    "\n",
    "def state_to_hashable(state):\n",
    "\tnew_state = torch.cat([\n",
    "\t\tstate['graph'].x[:, Indices.LABEL], \n",
    "\t\tstate['graph'].x[:, Indices.COORD], \n",
    "\t\tpositional_encode(state['graph'].x[:, Indices.RELATION])], \n",
    "\t\tdim=1\n",
    "\t)\n",
    "\treturn tuple(state['manipulator'].numpy().tolist() + new_state.view(-1).tolist())\n",
    "\n",
    "def reconstruct_path(node):\n",
    "    path = []\n",
    "    while node.parent is not None:\n",
    "        path.append(node.action)\n",
    "        node = node.parent\n",
    "    path.reverse()\n",
    "    return path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LabbeNode:\n",
    "\tnode_counter = 0  # Static variable to assign unique IDs to each node\n",
    "\n",
    "\tdef __init__(self, state, remaining_objs, obj=None, parent=None, action=None, c=1, depth=0):\n",
    "\t\tself.state = state\n",
    "\t\tself.obj = obj\n",
    "\t\tself.parent = parent\n",
    "\t\tself.action = action\n",
    "\t\tself.children = {}\n",
    "\t\tself.n = 0\n",
    "\t\tself.w = 0.0\n",
    "\t\tself.c = c\n",
    "\t\tself.terminal_flag = False\n",
    "\t\tself.remaining_objs = remaining_objs\n",
    "\t\tself.depth = depth\n",
    "\t\t\n",
    "\t\t# Assign a unique ID to each node\n",
    "\t\tself.id = LabbeNode.node_counter\n",
    "\t\tLabbeNode.node_counter += 1\n",
    "\n",
    "\tdef get_state(self):\n",
    "\t\treturn copy_state(self.state)\n",
    "\n",
    "\tdef is_fully_expanded(self):\n",
    "\t\treturn len(self.remaining_objs) == 0\n",
    "\n",
    "\tdef ucb(self):\n",
    "\t\tif self.n == 0:\n",
    "\t\t\treturn float('inf')  # Prioritize unvisited nodes\n",
    "\n",
    "\t\texpected_value = self.w / self.n\n",
    "\t\texploration_term = self.c * np.sqrt(2 * np.log(self.parent.n) / self.n)\n",
    "\n",
    "\t\treturn expected_value + exploration_term\n",
    "\n",
    "class Labbe(BaseSearch):\n",
    "\t\"\"\"\n",
    "\tChildren are states and actions are the objects to move.\n",
    "\tGiving birth to a child means manipulating an object which is non-stationary\n",
    "\tbacause of the random sampling of buffers durring the birth. \n",
    "\tIf choosing an object leads to non-expandable node, we assign different buffer to the object.\n",
    "\tIf after max_rebuffering times still it leads to non-expandable node, we give up on that object\n",
    "\tand remove that object and try rebuffering on its parent if all of its brothers are non-expandable too.\n",
    "\t\"\"\"\n",
    "\tdef __init__(self, env):\n",
    "\t\tsuper().__init__(env, LabbeNode)\n",
    "\n",
    "\tdef get_remaining_objs(self, state):\n",
    "\t\tstate_graph = state['graph']\n",
    "\n",
    "\t\tremaining_objs = []\n",
    "\t\tfor k in range(state_graph.num_nodes):\n",
    "\t\t\tif not torch.equal(get_obj_pos(state_graph, k), get_obj_pos(self.env.target_graph, k)):\n",
    "\t\t\t\tremaining_objs.append(k)\n",
    "\n",
    "\t\t# shuffle remaining nodes\n",
    "\t\tnp.random.shuffle(remaining_objs)\n",
    "\t\t\n",
    "\t\treturn remaining_objs\n",
    "\n",
    "\tdef get_action_move_obj_away(self, k):\n",
    "\t\tTK = get_obj_pos(self.env.target_graph, k)\n",
    "\t\tif not self.env.is_coor_occupied(TK, k):\n",
    "\t\t\tposition = flatten_pos(TK, self.env.grid_size)\n",
    "\t\t\treturn self.env.encode_action('move', k, k, position)\n",
    "\t\tfree_positions = get_empty_positions(self.env, ref_node=k, n=1)\n",
    "\t\tif len(free_positions) > 0:\n",
    "\t\t\t# move the node to a random position\n",
    "\t\t\treturn self.env.encode_action('move', k, k, free_positions[0])\n",
    "\t\treturn None\n",
    "\n",
    "\tdef get_motion(self, k):\n",
    "\t\tCK = get_obj_pos(self.env.state_graph, k)\n",
    "\t\tTK = get_obj_pos(self.env.target_graph, k)\n",
    "\t\tif torch.equal(TK, CK):\n",
    "\t\t\traise ValueError(f'The node {k} is already in its target position')\n",
    "\t\telif not self.env.is_coor_occupied(TK, k):\n",
    "\t\t\t# TK is free\n",
    "\t\t\tposition = flatten_pos(TK, self.env.grid_size)\n",
    "\t\t\treturn self.env.encode_action('move', k, k, position)\n",
    "\t\telse:\n",
    "\t\t\t# find which node is occupying TK\n",
    "\t\t\tsize_k = get_obj_size(self.env.state_graph, k)\n",
    "\t\t\toccupying_nodes = find_occupying_objs(self.env.table, TK, size_k)\n",
    "\t\t\tif len(occupying_nodes) == 0:\n",
    "\t\t\t\traise ValueError('No node is occupying the target position')\n",
    "\t\t\tfor j in occupying_nodes:\n",
    "\t\t\t\tif j != k:\n",
    "\t\t\t\t\taction_away = self.get_action_move_obj_away(j)\n",
    "\t\t\t\t\tif action_away is not None:\n",
    "\t\t\t\t\t\treturn action_away\n",
    "\t\t\treturn None\n",
    "\n",
    "\tdef evaluate_state(self, state):\n",
    "\t\tstate_graph = state['graph']\n",
    "\t\treward = 0\n",
    "\t\t\n",
    "\t\tfor k in range(state_graph.num_nodes):\n",
    "\t\t\tif torch.equal(get_obj_pos(state_graph, k), get_obj_pos(self.env.target_graph, k)):\n",
    "\t\t\t\treward += 1\n",
    "\n",
    "\t\treturn reward / state_graph.num_nodes\n",
    "\n",
    "\tdef select(self, node):\n",
    "\t\t# Accesses child nodes for best selection\n",
    "\t\treturn max(node.children.values(), key=lambda child: child.ucb())\n",
    "\n",
    "\tdef expand(self, node):\n",
    "\t\tif node.is_fully_expanded():\n",
    "\t\t\treturn None  # Prevents further expansion if no actions remain\n",
    "\n",
    "\t\tself.env.set_state(node.get_state())\n",
    "\t\taction = self.get_motion(node.remaining_objs.pop())\n",
    "\t\tif action is None:\n",
    "\t\t\treturn self.expand(node)\n",
    "\t\t\n",
    "\t\t# Continue expanding if this action has already been taken\n",
    "\t\t# if action in node.children:\n",
    "\t\t# \treturn self.expand(node)\n",
    "\t\t\n",
    "\t\taction_type, start_obj, target_obj, coordinates = self.env.decode_action(action)\n",
    "\t\t\n",
    "\t\t# Continue expanding if the last changed obj is the same as the current obj\n",
    "\t\tif node.obj == start_obj:\n",
    "\t\t\treturn self.expand(node)\n",
    "\t\t\n",
    "\t\t_, child_state = self.env._step(action_type, start_obj, target_obj, coordinates)\n",
    "\n",
    "\t\tif torch.equal(child_state['graph'].x, node.state['graph'].x):\n",
    "\t\t\traise ValueError('State has not changed')\n",
    "\n",
    "\t\tchild_node = self.node_class(\n",
    "\t\t\tstate=child_state, \n",
    "\t\t\tremaining_objs=self.get_remaining_objs(self.env.get_state()), \n",
    "\t\t\tobj=start_obj, \n",
    "\t\t\tparent=node, \n",
    "\t\t\taction=action, \n",
    "\t\t\tc=node.c,\n",
    "\t\t\tdepth=node.depth+1\n",
    "\t\t)\n",
    "\t\tnode.children[action] = child_node\n",
    "\n",
    "\t\treturn child_node\n",
    "\n",
    "\tdef backup_search(self, node, value, terminal_flag):\n",
    "\t\twhile node is not None:\n",
    "\t\t\tnode.n += 1\n",
    "\t\t\tnode.w += value\n",
    "\t\t\tnode.terminal_flag = terminal_flag or node.terminal_flag\n",
    "\t\t\tnode = node.parent\n",
    "\n",
    "\tdef print_tree(self, node, depth=0, ter=False):\n",
    "\t\t# Print the current node with indentation to show its depth in the tree\n",
    "\t\tindent = \"    \" * depth  # Four spaces per level of depth\n",
    "\t\tif node.id == 0:\n",
    "\t\t\tprint(f\"Root | Visits: {node.n} | Value: {node.w:.2f} | Terminal: {node.terminal_flag}\")\n",
    "\t\telse:\n",
    "\t\t\tprint(f\"{indent}ID: {node.id} | Action: {node.action} | \"\n",
    "\t\t\t\t\tf\"Visits: {node.n} | Value: {node.w:.2f} | Terminal: {node.terminal_flag}\")\n",
    "\n",
    "\t\t# Sort children by value estimate\n",
    "\t\tif ter:\n",
    "\t\t\taccepted_children = [child for child in node.children.values() if child.terminal_flag]\n",
    "\t\t\tchildren = sorted(accepted_children, key=lambda child: child.w / child.n if child.n > 0 else float('inf'))\n",
    "\t\telse:\n",
    "\t\t\tchildren = sorted(node.children.values(), key=lambda child: child.w / child.n if child.n > 0 else float('inf'))\n",
    "\n",
    "\t\t# Recurse on children\n",
    "\t\tfor child in children:\n",
    "\t\t\tself.print_tree(child, depth + 1, ter)\n",
    "\n",
    "\tdef find_best_path(self, ter=False):\n",
    "\t\tpath = []\n",
    "\t\tcurrent_node = self.root_node\n",
    "\n",
    "\t\twhile current_node.children:\n",
    "\t\t\tif ter:\n",
    "\t\t\t\taccepted_children = [child for child in current_node.children.values() if child.terminal_flag]\n",
    "\t\t\t\tif len(accepted_children) == 0:\n",
    "\t\t\t\t\tbreak\n",
    "\t\t\t\tnext_node = max(accepted_children, key=lambda child: child.w / child.n if child.n > 0 else float('inf'))\n",
    "\t\t\telse:\n",
    "\t\t\t\tnext_node = max(current_node.children.values(), key=lambda child: child.w / child.n if child.n > 0 else float('inf'))\n",
    "\t\t\tpath.append((next_node.action, next_node.w))\n",
    "\t\t\tcurrent_node = next_node\n",
    "\n",
    "\t\treturn [action for action, _ in path]\n",
    "\n",
    "\tdef loop(self):\n",
    "\t\tnode = self.root_node\n",
    "\n",
    "\t\t# Selection\n",
    "\t\tself.env.set_state(node.get_state())\n",
    "\t\twhile node.is_fully_expanded() and not self.env.is_terminal_state():\n",
    "\t\t\tnode = self.select(node)\n",
    "\t\t\tself.env.set_state(node.get_state())\n",
    "\n",
    "\t\t# Expansion\n",
    "\t\tchild_node = None\n",
    "\t\tif not self.env.is_terminal_state():\n",
    "\t\t\tchild_node = self.expand(node)\n",
    "\t\t\tif child_node is not None:\n",
    "\t\t\t\tnode = child_node\n",
    "\t\t\telse:\n",
    "\t\t\t\twhile node.parent and len(node.children) == 0:\n",
    "\t\t\t\t\tnode.parent.children.pop(node.action)\n",
    "\t\t\t\t\tnode = node.parent\n",
    "\n",
    "\t\t# Simulation (Rollout)\n",
    "\t\tself.env.set_state(node.get_state())\n",
    "\t\tterminal_flag = True if self.env.is_terminal_state() else False\n",
    "\t\tif child_node is None:\n",
    "\t\t\tvalue = 0\n",
    "\t\telse:\n",
    "\t\t\tvalue = self.evaluate_state(node.get_state())\n",
    "\t\t\n",
    "\t\t# Backpropagation\n",
    "\t\tself.backup_search(node, value, terminal_flag)\n",
    "\n",
    "\tdef solve(self, c=0.5, verbose=0, time_limit=None):\n",
    "\t\tif torch.sum(self.env.state_graph.x[:, Indices.RELATION]) > 0:\n",
    "\t\t\traise ValueError('Initial graph has edges in Non-stack mode')\n",
    "\t\tif torch.sum(self.env.target_graph.x[:, Indices.RELATION]) > 0:\n",
    "\t\t\traise ValueError('Target graph has edges in Non-stack mode')\n",
    "\t\treturn self._solve(c, verbose, time_limit)\n",
    "\n",
    "\tdef _solve(self, c=0.5, verbose=0, time_limit=None):\n",
    "\t\tstart_time = time.time()\n",
    "\t\tLabbeNode.node_counter = 0\n",
    "\t\tself.root_node = self.node_class(\n",
    "\t\t\tstate=self.env.get_state(), \n",
    "\t\t\tremaining_objs=self.get_remaining_objs(self.env.get_state()), \n",
    "\t\t\tc=c\n",
    "\t\t)\n",
    "\t\t\n",
    "\t\tsteps = 0\n",
    "\t\tif verbose > 0:\n",
    "\t\t\tpbar = tqdm(total=None, unit='iterations')\n",
    "\n",
    "\t\twhile self.root_node.terminal_flag is False:\n",
    "\t\t\t# Check if the elapsed time has exceeded the limit\n",
    "\t\t\tif time_limit is not None and  time.time()-start_time > time_limit:\n",
    "\t\t\t\tif verbose > 0:\n",
    "\t\t\t\t\tpbar.close()\n",
    "\t\t\t\treturn None, steps, time.time()-start_time\n",
    "\t\t\n",
    "\t\t\tsteps += 1\n",
    "\t\t\tself.loop()\n",
    "\t\t\tif verbose > 0:\n",
    "\t\t\t\tpbar.update(1)\n",
    "\n",
    "\t\tif verbose > 0:\n",
    "\t\t\tpbar.close()\n",
    "\n",
    "\t\treturn self.find_best_path(ter=True), steps, time.time()-start_time\n",
    "\n",
    "class LabbeS(Labbe):\n",
    "\tdef get_remaining_objs(self, state):\n",
    "\t\tstate_graph = state['graph']\n",
    "\n",
    "\t\tremaining_objs = []\n",
    "\t\tfor k in range(state_graph.num_nodes):\n",
    "\t\t\ti = find_target_obj(self.env.target_graph, k)\n",
    "\t\t\tif i is not None:\n",
    "\t\t\t\tif not is_edge_in_graph(state_graph, k, i):\n",
    "\t\t\t\t\tremaining_objs.append(k)\n",
    "\t\t\telif find_target_obj(state_graph, k) is not None:\n",
    "\t\t\t\tremaining_objs.append(k)\n",
    "\t\t\telse:\n",
    "\t\t\t\tif not torch.equal(get_obj_pos(state_graph, k), get_obj_pos(self.env.target_graph, k)):\n",
    "\t\t\t\t\tremaining_objs.append(k)\n",
    "\n",
    "\t\t# shuffle remaining nodes\n",
    "\t\tnp.random.shuffle(remaining_objs)\n",
    "\n",
    "\t\treturn remaining_objs\n",
    "\n",
    "\tdef get_action_move_obj_away(self, k):\n",
    "\t\tif not self.moving_buff:\n",
    "\t\t\tj = find_start_obj(self.env.state_graph, k)\n",
    "\t\t\tif j is not None:\n",
    "\t\t\t\treturn None\n",
    "\n",
    "\t\ti = find_target_obj(self.env.target_graph, k)\n",
    "\t\tif i is not None:\n",
    "\t\t\tif is_empty_object(env.state_graph, i):\n",
    "\t\t\t\treturn self.env.encode_action('stack', k, i, 0)\n",
    "\t\telse:\n",
    "\t\t\tTK = get_obj_pos(self.env.target_graph, k)\n",
    "\t\t\tif not self.env.is_coor_occupied(TK, k):\n",
    "\t\t\t\tposition = flatten_pos(TK, self.env.grid_size)\n",
    "\t\t\t\treturn self.env.encode_action('move', k, k, position)\n",
    "\t\t\n",
    "\t\tfree_positions = get_empty_positions(self.env, ref_node=k, n=1)\n",
    "\t\tfree_objects = get_empty_objs(self.env, ref_node=k, n=1)\n",
    "\t\tif len(free_objects) > 0 and len(free_positions) > 0:\n",
    "\t\t\tif np.random.rand() < 0.5:\n",
    "\t\t\t\t# move the node to a random position\n",
    "\t\t\t\treturn self.env.encode_action('move', k, k, free_positions[0])\n",
    "\t\t\telse:\n",
    "\t\t\t\t# stack on a random node\n",
    "\t\t\t\treturn self.env.encode_action('stack', k, free_objects[0], 0)\n",
    "\t\telif len(free_objects) == 0 and len(free_positions) > 0:\n",
    "\t\t\t# move the node to a random position\n",
    "\t\t\treturn self.env.encode_action('move', k, k, free_positions[0])\n",
    "\t\telif len(free_positions) == 0 and len(free_objects) > 0:\n",
    "\t\t\t# stack on a random node\n",
    "\t\t\treturn self.env.encode_action('stack', k, free_objects[0], 0)\n",
    "\t\treturn None\n",
    "\t\n",
    "\tdef get_motion(self, k):\n",
    "\t\tif not self.moving_buff:\n",
    "\t\t\tj = find_start_obj(self.env.state_graph, k)\n",
    "\t\t\tif j is not None:\n",
    "\t\t\t\treturn self.get_action_move_obj_away(j)\n",
    "\n",
    "\t\ti = find_target_obj(self.env.target_graph, k)\n",
    "\t\tif i is not None:\n",
    "\t\t\tj = find_start_obj(self.env.state_graph, i)\n",
    "\t\t\tif j is not None:\n",
    "\t\t\t\treturn self.get_action_move_obj_away(j)\n",
    "\t\t\telse:\n",
    "\t\t\t\treturn self.env.encode_action('stack', k, i, 0)\n",
    "\t\telse:\n",
    "\t\t\tCK = get_obj_pos(self.env.state_graph, k)\n",
    "\t\t\tTK = get_obj_pos(self.env.target_graph, k)\n",
    "\t\t\tif torch.equal(TK, CK):\n",
    "\t\t\t\tj = find_target_obj(self.env.state_graph, k)\n",
    "\t\t\t\tif j is not None:\n",
    "\t\t\t\t\tj = find_base_obj(self.env.state_graph, j)\n",
    "\t\t\t\t\treturn self.get_action_move_obj_away(j)\n",
    "\t\t\telse:\n",
    "\t\t\t\tif not self.env.is_coor_occupied(TK, k):\n",
    "\t\t\t\t\t# TK is free\n",
    "\t\t\t\t\tposition = flatten_pos(TK, self.env.grid_size)\n",
    "\t\t\t\t\treturn self.env.encode_action('move', k, k, position)\n",
    "\t\t\t\telse:\n",
    "\t\t\t\t\t# find which nodes are occupying TK\n",
    "\t\t\t\t\tsize_k = get_obj_size(self.env.state_graph, k)\n",
    "\t\t\t\t\toccupying_nodes = find_occupying_objs(self.env.table, TK, size_k)\n",
    "\t\t\t\t\tif len(occupying_nodes) == 0:\n",
    "\t\t\t\t\t\traise ValueError('No node is occupying the target position')\n",
    "\t\t\t\t\tfor j in occupying_nodes:\n",
    "\t\t\t\t\t\tif j != k:\n",
    "\t\t\t\t\t\t\taction_away = self.get_action_move_obj_away(j)\n",
    "\t\t\t\t\t\t\tif action_away is not None:\n",
    "\t\t\t\t\t\t\t\treturn action_away\n",
    "\t\treturn None\n",
    "\n",
    "\tdef evaluate_state(self, state):\n",
    "\t\tstate_graph = state['graph']\n",
    "\t\treward = 0\n",
    "\t\t\n",
    "\t\tfor k in range(state_graph.num_nodes):\n",
    "\t\t\ti = find_target_obj(self.env.target_graph, k)\n",
    "\t\t\tif i is not None:\n",
    "\t\t\t\tif is_edge_in_graph(state_graph, k, i):\n",
    "\t\t\t\t\treward += 1\n",
    "\t\t\telif find_target_obj(state_graph, k) is None:\n",
    "\t\t\t\tif torch.equal(get_obj_pos(state_graph, k), get_obj_pos(self.env.target_graph, k)):\n",
    "\t\t\t\t\treward += 1\n",
    "\n",
    "\t\treturn reward / state_graph.num_nodes\n",
    "\t\n",
    "\tdef solve(self, c=0.5, moving_buff=True, verbose=0, time_limit=None):\n",
    "\t\tself.moving_buff = moving_buff\n",
    "\t\treturn self._solve(c, verbose, time_limit)\n",
    "\n",
    "# evaluate_alg_n_times(env, Labbe, initial_scene, target_scene, num_runs=5, c=0.5, time_limit=20);\n",
    "# evaluate_alg_n_times(env, LabbeS, initial_scene, target_scene, num_runs=5, c=0.5, time_limit=20);\n",
    "# evaluate_alg(env, Labbe, initial_scene, target_scene, c=0.5, time_limit=20);\n",
    "# env.moving_buff = False\n",
    "# evaluate_alg(env, LabbeS, initial_scene, target_scene, c=0.5, moving_buff=env.moving_buff, time_limit=20);\n",
    "# env.moving_buff = True\n",
    "# evaluate_alg(env, LabbeS, initial_scene, target_scene, c=0.5, moving_buff=env.moving_buff, time_limit=20);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LabbeMultiBuffer(Labbe):\n",
    "\tdef get_remaining_objs(self, state):\n",
    "\t\tstate_graph = state['graph']\n",
    "\n",
    "\t\tremaining_objs = []\n",
    "\t\tfor k in range(state_graph.num_nodes):\n",
    "\t\t\ti = find_target_obj(self.env.target_graph, k)\n",
    "\t\t\tif i is not None:\n",
    "\t\t\t\tif not is_edge_in_graph(state_graph, k, i):\n",
    "\t\t\t\t\tremaining_objs.append(k)\n",
    "\t\t\telif find_target_obj(state_graph, k) is not None:\n",
    "\t\t\t\tremaining_objs.append(k)\n",
    "\t\t\telse:\n",
    "\t\t\t\tif not torch.equal(get_obj_pos(state_graph, k), get_obj_pos(self.env.target_graph, k)):\n",
    "\t\t\t\t\tremaining_objs.append(k)\n",
    "\n",
    "\t\t# shuffle remaining nodes\n",
    "\t\tnp.random.shuffle(remaining_objs)\n",
    "\n",
    "\t\treturn remaining_objs\n",
    "\n",
    "\tdef get_action_move_obj_away(self, k):\n",
    "\t\ti = find_target_obj(self.env.target_graph, k)\n",
    "\t\tif i is not None:\n",
    "\t\t\tif is_empty_object(env.state_graph, i):\n",
    "\t\t\t\treturn self.env.encode_action('stack', k, i, 0)\n",
    "\t\telse:\n",
    "\t\t\tTK = get_obj_pos(self.env.target_graph, k)\n",
    "\t\t\tif not self.env.is_coor_occupied(TK, k):\n",
    "\t\t\t\tposition = flatten_pos(TK, self.env.grid_size)\n",
    "\t\t\t\treturn self.env.encode_action('move', k, k, position)\n",
    "\t\t\t\n",
    "\t\tstack_nums = max(int(0.6 * self.num_buffers), 1)\n",
    "\n",
    "\t\tfree_objects = get_empty_objs(self.env, ref_node=k, n=stack_nums)\n",
    "\t\tfree_positions = get_empty_positions(self.env, ref_node=k, n=self.num_buffers-len(free_objects))\n",
    "\t\tvalid_stacks = [self.env.encode_action('stack', k, obj, 0) for obj in free_objects]\n",
    "\t\tvalid_moves = [self.env.encode_action('move', k, k, pos) for pos in free_positions]\n",
    "\t\t\n",
    "\t\treturn valid_stacks + valid_moves\n",
    "\n",
    "\tdef get_motion(self, k):\n",
    "\t\ti = find_target_obj(self.env.target_graph, k)\n",
    "\t\tif i is not None:\n",
    "\t\t\tj = find_start_obj(self.env.state_graph, i)\n",
    "\t\t\tif j is not None:\n",
    "\t\t\t\treturn self.get_action_move_obj_away(j)\n",
    "\t\t\telse:\n",
    "\t\t\t\treturn self.env.encode_action('stack', k, i, 0)\n",
    "\t\telse:\n",
    "\t\t\tCK = get_obj_pos(self.env.state_graph, k)\n",
    "\t\t\tTK = get_obj_pos(self.env.target_graph, k)\n",
    "\t\t\tif torch.equal(TK, CK):\n",
    "\t\t\t\tj = find_target_obj(self.env.state_graph, k)\n",
    "\t\t\t\tif j is not None:\n",
    "\t\t\t\t\tj = find_base_obj(self.env.state_graph, j)\n",
    "\t\t\t\t\treturn self.get_action_move_obj_away(j)\n",
    "\t\t\telse:\n",
    "\t\t\t\tif not self.env.is_coor_occupied(TK, k):\n",
    "\t\t\t\t\t# TK is free\n",
    "\t\t\t\t\tposition = flatten_pos(TK, self.env.grid_size)\n",
    "\t\t\t\t\treturn self.env.encode_action('move', k, k, position)\n",
    "\t\t\t\telse:\n",
    "\t\t\t\t\t# find which nodes are occupying TK\n",
    "\t\t\t\t\tsize_k = get_obj_size(self.env.state_graph, k)\n",
    "\t\t\t\t\toccupying_nodes = find_occupying_objs(self.env.table, TK, size_k)\n",
    "\t\t\t\t\tif len(occupying_nodes) == 0:\n",
    "\t\t\t\t\t\traise ValueError('No node is occupying the target position')\n",
    "\t\t\t\t\tfor j in occupying_nodes:\n",
    "\t\t\t\t\t\tif j != k:\n",
    "\t\t\t\t\t\t\taction_away = self.get_action_move_obj_away(j)\n",
    "\t\t\t\t\t\t\tif action_away is not None:\n",
    "\t\t\t\t\t\t\t\treturn action_away\n",
    "\t\treturn None\n",
    "\n",
    "\tdef evaluate_state(self, state):\n",
    "\t\tstate_graph = state['graph']\n",
    "\t\treward = 0\n",
    "\t\t\n",
    "\t\tfor k in range(state_graph.num_nodes):\n",
    "\t\t\ti = find_target_obj(self.env.target_graph, k)\n",
    "\t\t\tif i is not None:\n",
    "\t\t\t\tif is_edge_in_graph(state_graph, k, i):\n",
    "\t\t\t\t\treward += 1\n",
    "\t\t\telif find_target_obj(state_graph, k) is None:\n",
    "\t\t\t\tif torch.equal(get_obj_pos(state_graph, k), get_obj_pos(self.env.target_graph, k)):\n",
    "\t\t\t\t\treward += 1\n",
    "\n",
    "\t\treturn reward / state_graph.num_nodes\n",
    "\n",
    "\tdef select(self, node):\n",
    "\t\t# Accesses child nodes for best selection\n",
    "\t\treturn max(node.children.values(), key=lambda child: child.ucb())\n",
    "\n",
    "\tdef expand(self, node):\n",
    "\t\tif node.is_fully_expanded():\n",
    "\t\t\treturn None  # Prevents further expansion if no actions remain\n",
    "\n",
    "\t\tself.env.set_state(node.get_state())\n",
    "\t\tactions = self.get_motion(node.remaining_objs.pop())\n",
    "\n",
    "\t\tif actions is None:\n",
    "\t\t\treturn self.expand(node)\n",
    "\t\telif isinstance(actions, list):\n",
    "\t\t\tfor action in actions:\n",
    "\t\t\t\tself.env.set_state(node.get_state())\n",
    "\t\t\t\taction_type, start_obj, target_obj, coordinates = self.env.decode_action(action)\n",
    "\t\t\t\n",
    "\t\t\t\t# Continue expanding if the last changed obj is the same as the current obj\n",
    "\t\t\t\tif node.obj == start_obj:\n",
    "\t\t\t\t\treturn self.expand(node)\n",
    "\t\t\t\t\n",
    "\t\t\t\t_, child_state = self.env._step(action_type, start_obj, target_obj, coordinates)\n",
    "\n",
    "\t\t\t\tif torch.equal(child_state['graph'].x, node.state['graph'].x):\n",
    "\t\t\t\t\traise ValueError('State has not changed')\n",
    "\n",
    "\t\t\t\tchild_node = self.node_class(\n",
    "\t\t\t\t\tstate=child_state, \n",
    "\t\t\t\t\tremaining_objs=self.get_remaining_objs(self.env.get_state()), \n",
    "\t\t\t\t\tobj=start_obj, \n",
    "\t\t\t\t\tparent=node, \n",
    "\t\t\t\t\taction=action, \n",
    "\t\t\t\t\tc=node.c,\n",
    "\t\t\t\t\tdepth=node.depth+1\n",
    "\t\t\t\t)\n",
    "\t\t\t\tnode.children[action] = child_node\n",
    "\t\telse:\n",
    "\t\t\taction = actions\n",
    "\t\t\t# Continue expanding if this action has already been taken\n",
    "\t\t\t# if action in node.children:\n",
    "\t\t\t# \treturn self.expand(node)\n",
    "\t\t\t\n",
    "\t\t\taction_type, start_obj, target_obj, coordinates = self.env.decode_action(action)\n",
    "\t\t\t\n",
    "\t\t\t# Continue expanding if the last changed obj is the same as the current obj\n",
    "\t\t\tif node.obj == start_obj:\n",
    "\t\t\t\treturn self.expand(node)\n",
    "\t\t\t\n",
    "\t\t\t_, child_state = self.env._step(action_type, start_obj, target_obj, coordinates)\n",
    "\n",
    "\t\t\tif torch.equal(child_state['graph'].x, node.state['graph'].x):\n",
    "\t\t\t\traise ValueError('State has not changed')\n",
    "\n",
    "\t\t\tchild_node = self.node_class(\n",
    "\t\t\t\tstate=child_state, \n",
    "\t\t\t\tremaining_objs=self.get_remaining_objs(self.env.get_state()), \n",
    "\t\t\t\tobj=start_obj, \n",
    "\t\t\t\tparent=node, \n",
    "\t\t\t\taction=action, \n",
    "\t\t\t\tc=node.c,\n",
    "\t\t\t\tdepth=node.depth+1\n",
    "\t\t\t)\n",
    "\t\t\tnode.children[action] = child_node\n",
    "\n",
    "\t\treturn child_node\n",
    "\n",
    "\tdef backup_search(self, node, value, terminal_flag):\n",
    "\t\twhile node is not None:\n",
    "\t\t\tnode.n += 1\n",
    "\t\t\tnode.w += value\n",
    "\t\t\tnode.terminal_flag = terminal_flag or node.terminal_flag\n",
    "\t\t\tnode = node.parent\n",
    "\n",
    "\tdef loop(self):\n",
    "\t\tnode = self.root_node\n",
    "\n",
    "\t\t# Selection\n",
    "\t\tself.env.set_state(node.get_state())\n",
    "\t\twhile node.is_fully_expanded() and not self.env.is_terminal_state():\n",
    "\t\t\tnode = self.select(node)\n",
    "\t\t\tself.env.set_state(node.get_state())\n",
    "\n",
    "\t\t# Expansion\n",
    "\t\tchild_node = None\n",
    "\t\tif not self.env.is_terminal_state():\n",
    "\t\t\tchild_node = self.expand(node)\n",
    "\t\t\tif child_node is not None:\n",
    "\t\t\t\tnode = child_node\n",
    "\t\t\telse:\n",
    "\t\t\t\twhile len(node.children) == 0:\n",
    "\t\t\t\t\tnode.parent.children.pop(node.action)\n",
    "\t\t\t\t\tnode = node.parent\n",
    "\n",
    "\t\t# Simulation (Rollout)\n",
    "\t\tself.env.set_state(node.get_state())\n",
    "\t\tterminal_flag = True if self.env.is_terminal_state() else False\n",
    "\t\tif child_node is None:\n",
    "\t\t\tvalue = 0\n",
    "\t\telse:\n",
    "\t\t\tvalue = self.evaluate_state(node.get_state())\n",
    "\t\t\n",
    "\t\t# Backpropagation\n",
    "\t\tself.backup_search(node, value, terminal_flag)\n",
    "\n",
    "\tdef solve(self, c=0.5, verbose=0, num_buffers=3, time_limit=None):\n",
    "\t\tself.num_buffers = num_buffers\n",
    "\t\treturn self._solve(c, verbose, time_limit)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SearchNode:\n",
    "\tdef __init__(self, state, parent=None, action=None, cost_to_come=0, heuristic=0, depth=0):\n",
    "\t\tself.state = state\n",
    "\t\tself.parent = parent\n",
    "\t\tself.action = action\n",
    "\t\tself.c_cost = cost_to_come\t  \t# cost-to-come\n",
    "\t\tself.h_cost = heuristic\t\t\t# cost-to-go\n",
    "\t\tself.total_cost = self.c_cost + self.h_cost\n",
    "\t\tself.depth = depth\n",
    "\n",
    "\tdef __lt__(self, other):\n",
    "\t\treturn self.total_cost < other.total_cost  # Lower cost first\n",
    "\n",
    "\tdef get_state(self):\n",
    "\t\treturn copy_state(self.state)\n",
    "\n",
    "class A_star(BaseSearch):\n",
    "\tdef __init__(self, env):\n",
    "\t\tsuper().__init__(env, SearchNode)\n",
    "\n",
    "\tdef get_remaining_objects(self, state):\n",
    "\t\tstate_graph = state['graph']\n",
    "\n",
    "\t\tremaining_objs = []\n",
    "\t\tfor k in range(state_graph.num_nodes):\n",
    "\t\t\ti = find_target_obj(self.env.target_graph, k)\n",
    "\t\t\tif i is not None:\n",
    "\t\t\t\tif not is_edge_in_graph(state_graph, k, i):\n",
    "\t\t\t\t\tremaining_objs.append(k)\n",
    "\t\t\telif find_target_obj(state_graph, k) is not None:\n",
    "\t\t\t\tremaining_objs.append(k)\n",
    "\t\t\telse:\n",
    "\t\t\t\tif not torch.equal(get_obj_pos(state_graph, k), get_obj_pos(self.env.target_graph, k)):\n",
    "\t\t\t\t\tremaining_objs.append(k)\n",
    "\n",
    "\t\t# shuffle remaining objs\n",
    "\t\tnp.random.shuffle(remaining_objs)\n",
    "\n",
    "\t\treturn remaining_objs\n",
    "\n",
    "\tdef get_valid_actions(self, state):\n",
    "\t\tself.env.set_state(state)\n",
    "\n",
    "\t\tstack_nums = max(int(0.6 * self.num_buffers), 1)\n",
    "\n",
    "\t\tobjects = list(range(self.env.num_objects))\n",
    "\t\tnp.random.shuffle(objects)\n",
    "\n",
    "\t\tvalid_actions = []\n",
    "\t\tfor k in self.get_remaining_objects(state):\n",
    "\t\t\tif not self.moving_buff:\n",
    "\t\t\t\tif find_start_obj(self.env.state_graph, k) is not None:\n",
    "\t\t\t\t\tcontinue\n",
    "\t\t\t\n",
    "\t\t\tvalid_stacks = []\n",
    "\t\t\tfor obj in objects:\n",
    "\t\t\t\tif k != obj and not is_edge_in_graph(self.env.state_graph, k, obj):\n",
    "\t\t\t\t\tif is_stable(self.env.state_graph.x, k, obj):\n",
    "\t\t\t\t\t\tif is_empty_object(self.env.state_graph, obj):\n",
    "\t\t\t\t\t\t\tvalid_stacks.append(self.env.encode_action('stack', k, obj, 0))\n",
    "\t\t\t\t\t\t\tif len(valid_stacks) >= stack_nums:\n",
    "\t\t\t\t\t\t\t\tbreak\n",
    "\n",
    "\t\t\tvalid_moves = []\n",
    "\t\t\tfor position in get_empty_positions_with_target(self.env, ref_node=k, n=self.num_buffers-len(valid_stacks)):\n",
    "\t\t\t\tvalid_moves.append(self.env.encode_action('move', k, k, position))\n",
    "\n",
    "\t\t\tvalid_actions += valid_stacks + valid_moves\n",
    "\n",
    "\t\treturn valid_actions\n",
    "\n",
    "\tdef evaluate_state(self, state):\n",
    "\t\tstate_graph = state['graph']\n",
    "\t\theuristic = 0\n",
    "\t\t# init_pos_dis = []\n",
    "\n",
    "\t\tfor k in self.get_remaining_objects(state):\n",
    "\t\t\tCK = get_obj_pos(state_graph, k)\n",
    "\t\t\tTK = get_obj_pos(self.env.target_graph, k)\n",
    "\t\t\tmin_dis = torch.norm(CK - TK)\n",
    "\t\t\t# init_pos_dis.append(torch.norm(TK - self.env.manipulator_initial_pos.clone()).item())\n",
    "\n",
    "\t\t\ti = find_target_obj(self.env.target_graph, k)\n",
    "\t\t\tif i is not None:\n",
    "\t\t\t\tif not is_edge_in_graph(state_graph, k, i):\n",
    "\t\t\t\t\tCI = get_obj_pos(state_graph, i)\n",
    "\t\t\t\t\tnew_dis = torch.norm(CK - CI)\n",
    "\t\t\t\t\tif new_dis < min_dis:\n",
    "\t\t\t\t\t\tmin_dis = new_dis\n",
    "\t\t\t\t\t\t# if find_start_obj(state_graph, i) is not None:\n",
    "\t\t\t\t\t\t# \theuristic += self.env.pp_cost\n",
    "\t\t\t\t\theuristic += self.env.pp_cost\n",
    "\t\t\telse:\n",
    "\t\t\t\tif min_dis == 0:\n",
    "\t\t\t\t\tif find_target_obj(state_graph, k) is not None:\n",
    "\t\t\t\t\t\theuristic += self.env.pp_cost\n",
    "\t\t\t\tif min_dis != 0:\n",
    "\t\t\t\t\tstack = False\n",
    "\t\t\t\t\tfor j in range(state_graph.num_nodes):\n",
    "\t\t\t\t\t\tif k != j and is_stable(state_graph.x, k, j):\n",
    "\t\t\t\t\t\t\tCJ = get_obj_pos(state_graph, j)\n",
    "\t\t\t\t\t\t\tTJ = get_obj_pos(self.env.target_graph, j)\n",
    "\t\t\t\t\t\t\tnew_dis = torch.norm(CK - CJ) + torch.norm(TK - TJ)\n",
    "\t\t\t\t\t\t\tif new_dis < min_dis:\n",
    "\t\t\t\t\t\t\t\tmin_dis = new_dis\n",
    "\t\t\t\t\t\t\t\tstack = True\n",
    "\t\t\t\t\tif stack:\n",
    "\t\t\t\t\t\theuristic += self.env.pp_cost\n",
    "\t\t\t\t\theuristic += self.env.pp_cost\n",
    "\t\t\t\n",
    "\t\t\theuristic += min_dis * self.env.normalization_factor\n",
    "\t\t\n",
    "\t\t# heuristic += min(init_pos_dis) * self.env.normalization_factor\n",
    "\t\treturn heuristic\n",
    "\n",
    "\tdef solve(self, max_depth=100, num_buffers=3, score_sorting=False, time_limit=None, moving_buff=True):\n",
    "\t\tself.score_sorting = score_sorting\n",
    "\t\tself.num_buffers = num_buffers\n",
    "\t\tself.moving_buff = moving_buff\n",
    "\t\treturn self._solve(max_depth, time_limit)\n",
    "\n",
    "\tdef _solve(self, max_depth=100, time_limit=None):\n",
    "\t\tstart_time = time.time()\n",
    "\n",
    "\t\tsteps = 0\n",
    "\t\troot_node = self.node_class(\n",
    "\t\t\tstate=self.env.get_state(), \n",
    "\t\t\tcost_to_come=0, \n",
    "\t\t\theuristic=self.evaluate_state(self.env.get_state())\n",
    "\t\t)\n",
    "\n",
    "\t\tqueue = []\n",
    "\t\theapq.heappush(queue, root_node)\n",
    "\t\tvisited = {}\n",
    "\n",
    "\t\twhile queue:\n",
    "\t\t\tcurrent_node = heapq.heappop(queue)\n",
    "\n",
    "\t\t\t# Check if the current node's state matches the target state\n",
    "\t\t\tself.env.set_state(current_node.get_state())\n",
    "\t\t\tif self.env.is_terminal_state():\n",
    "\t\t\t\treturn reconstruct_path(current_node), steps, time.time()-start_time\n",
    "\n",
    "\t\t\tif current_node.depth >= max_depth:\n",
    "\t\t\t\tcontinue\n",
    "\n",
    "\t\t\tif time_limit is not None and time.time() - start_time > time_limit:\n",
    "\t\t\t\tprint('Time limit exceeded')\n",
    "\t\t\t\treturn None, steps, time.time()-start_time\n",
    "\n",
    "\t\t\tlast_obj = self.env.decode_action(current_node.action)[1] if current_node.action is not None else None\n",
    "\t\t\tfor action in self.get_valid_actions(current_node.get_state()):\n",
    "\t\t\t\taction_type, start_obj, target_obj, coordinates = self.env.decode_action(action)\n",
    "\n",
    "\t\t\t\tif start_obj == last_obj:\n",
    "\t\t\t\t\t# If the last changed node is the same as the current node, continue\n",
    "\t\t\t\t\tcontinue\n",
    "\n",
    "\t\t\t\tsteps += 1\n",
    "\t\t\t\tself.env.set_state(current_node.get_state())\n",
    "\t\t\t\tcost, child_state = self.env._step(action_type, start_obj, target_obj, coordinates)\n",
    "\n",
    "\t\t\t\tif torch.equal(child_state['graph'].x, current_node.get_state()['graph'].x):\n",
    "\t\t\t\t\t# if state hasn't changed, continue\n",
    "\t\t\t\t\traise ValueError('State has not changed')\n",
    "\n",
    "\t\t\t\tchild_hash = state_to_hashable(child_state)\n",
    "\n",
    "\t\t\t\t# Calculate the accumulated cost for the current path\n",
    "\t\t\t\tnew_c_cost = current_node.c_cost + cost\n",
    "\t\t\t\th_cost = self.evaluate_state(child_state)\n",
    "\t\t\t\tnew_total_cost = new_c_cost + h_cost\n",
    "\n",
    "\t\t\t\t# Retain the node with better cost\n",
    "\t\t\t\tif child_hash not in visited or visited[child_hash] > new_total_cost:\n",
    "\t\t\t\t\tvisited[child_hash] = new_total_cost\n",
    "\t\t\t\t\tchild_node = self.node_class(\n",
    "\t\t\t\t\t\tstate=child_state, \n",
    "\t\t\t\t\t\tparent=current_node, \n",
    "\t\t\t\t\t\taction=action, \n",
    "\t\t\t\t\t\tcost_to_come=new_c_cost, \n",
    "\t\t\t\t\t\theuristic=h_cost,\n",
    "\t\t\t\t\t\tdepth=current_node.depth+1\n",
    "\t\t\t\t\t)\n",
    "\n",
    "\t\t\t\t\theapq.heappush(queue, child_node)\n",
    "\n",
    "\t\treturn None, steps, time.time()-start_time\n",
    "\n",
    "class A_starGA(A_star):\n",
    "\tdef _solve(self, max_depth=100, time_limit=None):\n",
    "\t\tstart_time = time.time()\n",
    "\t\tbest_plan = None\n",
    "\t\tbest_cost = float('inf')\n",
    "\n",
    "\t\tsteps = 0\n",
    "\t\troot_node = self.node_class(\n",
    "\t\t\tstate=self.env.get_state(), \n",
    "\t\t\tcost_to_come=0, \n",
    "\t\t\theuristic=self.evaluate_state(self.env.get_state())\n",
    "\t\t)\n",
    "\n",
    "\t\tqueue = []\n",
    "\t\theapq.heappush(queue, root_node)\n",
    "\t\tvisited = {}\n",
    "\n",
    "\t\twhile queue:\n",
    "\t\t\tcurrent_node = heapq.heappop(queue)\n",
    "\n",
    "\t\t\t# Check if the current node's state matches the target state\n",
    "\t\t\tself.env.set_state(current_node.get_state())\n",
    "\t\t\tif self.env.is_terminal_state():\n",
    "\t\t\t\tif best_plan is not None and current_node.total_cost < best_cost:\n",
    "\t\t\t\t\treturn reconstruct_path(current_node), steps, time.time()-start_time\n",
    "\t\t\t\telse:\n",
    "\t\t\t\t\treturn best_plan, steps, time.time()-start_time\n",
    "\n",
    "\t\t\tif current_node.depth >= max_depth:\n",
    "\t\t\t\tcontinue\n",
    "\n",
    "\t\t\tif time_limit is not None and time.time() - start_time > time_limit:\n",
    "\t\t\t\tprint('Time limit exceeded')\n",
    "\t\t\t\treturn best_plan, steps, time.time()-start_time\n",
    "\n",
    "\t\t\tlast_obj = self.env.decode_action(current_node.action)[1] if current_node.action is not None else None\n",
    "\t\t\tfor action in self.get_valid_actions(current_node.get_state()):\n",
    "\t\t\t\taction_type, start_obj, target_obj, coordinates = self.env.decode_action(action)\n",
    "\n",
    "\t\t\t\t# If the last changed node is the same as the current node, continue\n",
    "\t\t\t\tif start_obj == last_obj:\n",
    "\t\t\t\t\tcontinue\n",
    "\n",
    "\t\t\t\tsteps += 1\n",
    "\t\t\t\tself.env.set_state(current_node.get_state())\n",
    "\t\t\t\tcost, child_state = self.env._step(action_type, start_obj, target_obj, coordinates)\n",
    "\n",
    "\t\t\t\t# If state hasn't changed, continue\n",
    "\t\t\t\tif torch.equal(child_state['graph'].x, current_node.get_state()['graph'].x):\n",
    "\t\t\t\t\traise ValueError('State has not changed')\n",
    "\n",
    "\t\t\t\tchild_hash = state_to_hashable(child_state)\n",
    "\n",
    "\t\t\t\t# Calculate the accumulated cost for the current path\n",
    "\t\t\t\tnew_c_cost = current_node.c_cost + cost\n",
    "\t\t\t\th_cost = self.evaluate_state(child_state)\n",
    "\t\t\t\tnew_total_cost = new_c_cost + h_cost\n",
    "\n",
    "\t\t\t\t# Retain the node with better cost\n",
    "\t\t\t\tif child_hash not in visited or visited[child_hash] > new_total_cost:\n",
    "\t\t\t\t\tvisited[child_hash] = new_total_cost\n",
    "\t\t\t\t\tchild_node = self.node_class(\n",
    "\t\t\t\t\t\tstate=child_state, \n",
    "\t\t\t\t\t\tparent=current_node, \n",
    "\t\t\t\t\t\taction=action, \n",
    "\t\t\t\t\t\tcost_to_come=new_c_cost, \n",
    "\t\t\t\t\t\theuristic=h_cost,\n",
    "\t\t\t\t\t\tdepth=current_node.depth+1\n",
    "\t\t\t\t\t)\n",
    "\n",
    "\t\t\t\t\theapq.heappush(queue, child_node)\n",
    "\n",
    "\t\t\tif time_limit is not None and time.time() - start_time > time_limit:\n",
    "\t\t\t\tprint('Time limit exceeded')\n",
    "\t\t\t\treturn best_plan, steps, time.time()-start_time\n",
    "\n",
    "\t\t\t# Goal Attempting\n",
    "\t\t\tself.env.set_state(current_node.get_state())\n",
    "\t\t\tsim_time_limit = (time_limit - time.time() + start_time) / 4\n",
    "\t\t\tpath_to_go, labbe_steps, _ = LabbeS(self.env).solve(time_limit=sim_time_limit, moving_buff=self.moving_buff)\n",
    "\t\t\tsteps += labbe_steps\n",
    "\t\t\tself.env.set_state(current_node.get_state())\n",
    "\t\t\t\n",
    "\t\t\tif path_to_go is None:\n",
    "\t\t\t\tcontinue\n",
    "\t\t\t\n",
    "\t\t\tfeasible_path_cost = current_node.c_cost\n",
    "\t\t\tfor i, action in enumerate(path_to_go):\n",
    "\t\t\t\tcost, child_state = self.env.step(action)\n",
    "\t\t\t\tfeasible_path_cost += cost\n",
    "\t\t\t\tif i == 0:\n",
    "\t\t\t\t\tfirst_child = child_state\n",
    "\t\t\t\t\tfist_action = action\n",
    "\t\t\t\t\tfirst_cost = feasible_path_cost\n",
    "\n",
    "\t\t\tif feasible_path_cost < best_cost:\n",
    "\t\t\t\tbest_plan = reconstruct_path(current_node) + path_to_go\n",
    "\t\t\t\tbest_cost = feasible_path_cost\n",
    "\t\t\t\tchild_node = self.node_class(\n",
    "\t\t\t\t\tstate=first_child,\n",
    "\t\t\t\t\tparent=current_node,\n",
    "\t\t\t\t\taction=fist_action,\n",
    "\t\t\t\t\tcost_to_come=first_cost,\n",
    "\t\t\t\t\theuristic=self.evaluate_state(first_child),\n",
    "\t\t\t\t\tdepth=current_node.depth+1\n",
    "\t\t\t\t)\n",
    "\t\t\t\theapq.heappush(queue, child_node)\n",
    "\n",
    "\t\t\t# Remove all the nodes with their total cost is greater than the feasible path cost\n",
    "\t\t\tfor node in queue:\n",
    "\t\t\t\tif node.total_cost > feasible_path_cost:\n",
    "\t\t\t\t\tqueue.remove(node)\n",
    "\n",
    "\t\treturn best_plan, steps, time.time()-start_time\n",
    "\n",
    "class Strap(A_star):\n",
    "\tdef get_remaining_objects(self, state):\n",
    "\t\tstate_graph = state['graph']\n",
    "\n",
    "\t\tremaining_objs = []\n",
    "\t\tfor k in range(state_graph.num_nodes):\n",
    "\t\t\tif not torch.equal(get_obj_pos(state_graph, k), get_obj_pos(self.env.target_graph, k)):\n",
    "\t\t\t\tremaining_objs.append(k)\n",
    "\n",
    "\t\t# shuffle remaining objs\n",
    "\t\tnp.random.shuffle(remaining_objs)\n",
    "\t\t\n",
    "\t\treturn remaining_objs\n",
    "\n",
    "\tdef get_valid_actions(self, state):\n",
    "\t\tself.env.set_state(copy_state(state))\n",
    "\n",
    "\t\tvalid_actions = []\n",
    "\t\tfor k in self.get_remaining_objects(state):\n",
    "\t\t\tfor position in get_empty_positions_with_target(self.env, ref_node=k, n=self.num_buffers):\n",
    "\t\t\t\tvalid_actions.append(self.env.encode_action('move', k, k, position))\n",
    "\t\t\n",
    "\t\treturn valid_actions\n",
    "\n",
    "\tdef evaluate_state(self, state):\n",
    "\t\tstate_graph = state['graph']\n",
    "\t\theuristic = 0\n",
    "\n",
    "\t\tfor k in self.get_remaining_objects(state):\n",
    "\t\t\tCK = get_obj_pos(state_graph, k)\n",
    "\t\t\tTK = get_obj_pos(self.env.target_graph, k)\n",
    "\t\t\theuristic += self.env.pp_cost\n",
    "\t\t\theuristic += torch.norm(CK - TK).item() * self.env.normalization_factor\n",
    "\t\t\n",
    "\t\treturn heuristic\n",
    "\n",
    "\tdef solve(self, max_depth=100, num_buffers=3, score_sorting=False, time_limit=None):\n",
    "\t\tif torch.sum(self.env.state_graph.x[:, Indices.RELATION]) > 0:\n",
    "\t\t\traise ValueError('Initial graph has edges in Non-stack mode')\n",
    "\t\tif torch.sum(self.env.target_graph.x[:, Indices.RELATION]) > 0:\n",
    "\t\t\traise ValueError('Target graph has edges in Non-stack mode')\n",
    "\t\treturn super().solve(max_depth, num_buffers, score_sorting, time_limit)\n",
    "\n",
    "class StrapGA(Strap):\n",
    "\tdef _solve(self, max_depth=100, time_limit=None):\n",
    "\t\tstart_time = time.time()\n",
    "\t\tbest_plan = None\n",
    "\t\tbest_cost = float('inf')\n",
    "\n",
    "\t\tsteps = 0\n",
    "\t\troot_node = self.node_class(\n",
    "\t\t\tstate=self.env.get_state(), \n",
    "\t\t\tcost_to_come=0, \n",
    "\t\t\theuristic=self.evaluate_state(self.env.get_state())\n",
    "\t\t)\n",
    "\n",
    "\t\tqueue = []\n",
    "\t\theapq.heappush(queue, root_node)\n",
    "\t\tvisited = {}\n",
    "\n",
    "\t\twhile queue:\n",
    "\t\t\tcurrent_node = heapq.heappop(queue)\n",
    "\n",
    "\t\t\t# Check if the current node's state matches the target state\n",
    "\t\t\tself.env.set_state(current_node.get_state())\n",
    "\t\t\tif self.env.is_terminal_state():\n",
    "\t\t\t\tif best_plan is not None and current_node.total_cost < best_cost:\n",
    "\t\t\t\t\treturn reconstruct_path(current_node), steps, time.time()-start_time\n",
    "\t\t\t\telse:\n",
    "\t\t\t\t\treturn best_plan, steps, time.time()-start_time\n",
    "\n",
    "\t\t\tif current_node.depth >= max_depth:\n",
    "\t\t\t\tcontinue\n",
    "\n",
    "\t\t\tif time_limit is not None and time.time()-start_time > time_limit:\n",
    "\t\t\t\tprint('Time limit exceeded')\n",
    "\t\t\t\treturn best_plan, steps, time.time()-start_time\n",
    "\n",
    "\t\t\tlast_obj = self.env.decode_action(current_node.action)[1] if current_node.action is not None else None\n",
    "\t\t\tfor action in self.get_valid_actions(current_node.get_state()):\n",
    "\t\t\t\taction_type, start_obj, target_obj, coordinates = self.env.decode_action(action)\n",
    "\n",
    "\t\t\t\t# If the last changed node is the same as the current node, continue\n",
    "\t\t\t\tif start_obj == last_obj:\n",
    "\t\t\t\t\tcontinue\n",
    "\n",
    "\t\t\t\tsteps += 1\n",
    "\t\t\t\tself.env.set_state(current_node.get_state())\n",
    "\t\t\t\tcost, child_state = self.env._step(action_type, start_obj, target_obj, coordinates)\n",
    "\n",
    "\t\t\t\t# If state hasn't changed, continue\n",
    "\t\t\t\tif torch.equal(child_state['graph'].x, current_node.get_state()['graph'].x):\n",
    "\t\t\t\t\traise ValueError('State has not changed')\n",
    "\n",
    "\t\t\t\tchild_hash = state_to_hashable(child_state)\n",
    "\n",
    "\t\t\t\t# Calculate the accumulated cost for the current path\n",
    "\t\t\t\tnew_c_cost = current_node.c_cost + cost\n",
    "\t\t\t\th_cost = self.evaluate_state(child_state)\n",
    "\t\t\t\tnew_total_cost = new_c_cost + h_cost\n",
    "\n",
    "\t\t\t\t# Retain the node with better cost\n",
    "\t\t\t\tif child_hash not in visited or visited[child_hash] > new_total_cost:\n",
    "\t\t\t\t\tvisited[child_hash] = new_total_cost\n",
    "\t\t\t\t\tchild_node = self.node_class(\n",
    "\t\t\t\t\t\tstate=child_state, \n",
    "\t\t\t\t\t\tparent=current_node, \n",
    "\t\t\t\t\t\taction=action, \n",
    "\t\t\t\t\t\tcost_to_come=new_c_cost, \n",
    "\t\t\t\t\t\theuristic=h_cost,\n",
    "\t\t\t\t\t\tdepth=current_node.depth+1\n",
    "\t\t\t\t\t)\n",
    "\n",
    "\t\t\t\t\theapq.heappush(queue, child_node)\n",
    "\n",
    "\t\t\tif time_limit is not None and time.time()-start_time > time_limit:\n",
    "\t\t\t\tprint('Time limit exceeded')\n",
    "\t\t\t\treturn best_plan, steps, time.time()-start_time\n",
    "\n",
    "\t\t\t# Goal Attempting\n",
    "\t\t\tself.env.set_state(current_node.get_state())\n",
    "\t\t\tsim_time_limit = (time_limit - time.time() + start_time) / 4\n",
    "\t\t\tpath_to_go, labbe_steps, _ = Labbe(self.env).solve(time_limit=sim_time_limit)\n",
    "\t\t\tsteps += labbe_steps\n",
    "\t\t\tself.env.set_state(current_node.get_state())\n",
    "\n",
    "\t\t\tif path_to_go is None:\n",
    "\t\t\t\tcontinue\n",
    "\n",
    "\t\t\tfeasible_path_cost = current_node.c_cost\n",
    "\t\t\tfor i, action in enumerate(path_to_go):\n",
    "\t\t\t\tcost, child_state = self.env.step(action)\n",
    "\t\t\t\tfeasible_path_cost += cost\n",
    "\t\t\t\tif i == 0:\n",
    "\t\t\t\t\tfirst_child = child_state\n",
    "\t\t\t\t\tfist_action = action\n",
    "\t\t\t\t\tfirst_cost = feasible_path_cost\n",
    "\n",
    "\t\t\tif feasible_path_cost < best_cost:\n",
    "\t\t\t\tbest_plan = reconstruct_path(current_node) + path_to_go\n",
    "\t\t\t\tbest_cost = feasible_path_cost\n",
    "\t\t\t\tchild_node = self.node_class(\n",
    "\t\t\t\t\tstate=first_child,\n",
    "\t\t\t\t\tparent=current_node,\n",
    "\t\t\t\t\taction=fist_action,\n",
    "\t\t\t\t\tcost_to_come=first_cost,\n",
    "\t\t\t\t\theuristic=self.evaluate_state(first_child),\n",
    "\t\t\t\t\tdepth=current_node.depth+1\n",
    "\t\t\t\t)\n",
    "\t\t\t\theapq.heappush(queue, child_node)\n",
    "\n",
    "\t\t\t# Remove all the nodes with their total cost is greater than the feasible path cost\n",
    "\t\t\tfor node in queue:\n",
    "\t\t\t\tif node.total_cost > feasible_path_cost:\n",
    "\t\t\t\t\tqueue.remove(node)\n",
    "\n",
    "\t\treturn best_plan, steps, time.time()-start_time\n",
    "\n",
    "# env.moving_buff = False\n",
    "# evaluate_alg(env, A_starGA, initial_scene, target_scene, num_buffers=4, moving_buff=env.moving_buff, time_limit=60);\n",
    "# env.moving_buff = True\n",
    "# evaluate_alg(env, A_starGA, initial_scene, target_scene, num_buffers=4, moving_buff=env.moving_buff, time_limit=60);\n",
    "# evaluate_alg(env, StrapGA, initial_scene, target_scene, num_buffers=4, time_limit=40);\n",
    "# evaluate_alg_n_times(env, A_starGA, initial_scene, target_scene, num_runs=10, num_buffers=4, time_limit=30);\n",
    "# evaluate_alg_n_times(env, StrapGA, initial_scene, target_scene, num_runs=1, num_buffers=4, time_limit=10);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MctsNode:\n",
    "\tnode_counter = 0  # Static variable to assign unique IDs to each node\n",
    "\n",
    "\tdef __init__(self, state, valid_actions, parent=None, action=None, cost=0.0, cost_to_come=0.0, c=1, depth=0):\n",
    "\t\tself.state = state\n",
    "\t\tself.parent = parent\n",
    "\t\tself.action = action\n",
    "\t\tself.children = {}\n",
    "\t\tself.n = 0\n",
    "\t\t# self.w = 0\n",
    "\t\tself.w = np.inf\n",
    "\t\tself.c = c\n",
    "\t\tself.cost = cost\n",
    "\t\tself.c_cost = cost_to_come\n",
    "\t\tself.unexpanded_actions = valid_actions\n",
    "\t\tself.depth = depth\n",
    "\t\t\n",
    "\t\t# Assign a unique ID to each node\n",
    "\t\tself.id = MctsNode.node_counter\n",
    "\t\tMctsNode.node_counter += 1\n",
    "\n",
    "\tdef get_state(self):\n",
    "\t\treturn copy_state(self.state)\n",
    "\n",
    "\tdef is_fully_expanded(self):\n",
    "\t\treturn len(self.unexpanded_actions) == 0\n",
    "\n",
    "\tdef uct(self, c_min=0, c_max=1):\n",
    "\t\tn = self.n\n",
    "\n",
    "\t\t# expected_value = ( (self.c_cost + self.w / n) - c_min ) / (c_max - c_min)\n",
    "\t\texpected_value = ( (self.c_cost + self.w) - c_min ) / (c_max - c_min)\n",
    "\t\texploration_term = np.sqrt(2 * np.log(self.parent.n) / n)\n",
    "\n",
    "\t\treturn expected_value - self.c * exploration_term  # Minimization form\n",
    "\n",
    "class Sorp(BaseSearch):\n",
    "\tdef __init__(self, env):\n",
    "\t\tsuper().__init__(env, MctsNode)\n",
    "\t\n",
    "\tdef get_remaining_objects(self, state):\n",
    "\t\tstate_graph = state['graph']\n",
    "\n",
    "\t\tremaining_objs = []\n",
    "\t\tfor k in range(state_graph.num_nodes):\n",
    "\t\t\ti = find_target_obj(self.env.target_graph, k)\n",
    "\t\t\tif i is not None:\n",
    "\t\t\t\tif not is_edge_in_graph(state_graph, k, i):\n",
    "\t\t\t\t\tremaining_objs.append(k)\n",
    "\t\t\telif find_target_obj(state_graph, k) is not None:\n",
    "\t\t\t\tremaining_objs.append(k)\n",
    "\t\t\telse:\n",
    "\t\t\t\tif not torch.equal(get_obj_pos(state_graph, k), get_obj_pos(self.env.target_graph, k)):\n",
    "\t\t\t\t\tremaining_objs.append(k)\n",
    "\n",
    "\t\t# shuffle remaining objs\n",
    "\t\tnp.random.shuffle(remaining_objs)\n",
    "\n",
    "\t\treturn remaining_objs\n",
    "\n",
    "\tdef get_valid_actions(self, state):\n",
    "\t\tself.env.set_state(state)\n",
    "\n",
    "\t\tstack_nums = max(int(0.6 * self.num_buffers), 1)\n",
    "\n",
    "\t\tobjects = list(range(self.env.num_objects))\n",
    "\t\tnp.random.shuffle(objects)\n",
    "\n",
    "\t\tvalid_actions = []\n",
    "\t\tfor k in self.get_remaining_objects(state):\n",
    "\t\t\tif not self.moving_buff:\n",
    "\t\t\t\tif find_start_obj(self.env.state_graph, k) is not None:\n",
    "\t\t\t\t\tcontinue\n",
    "\t\t\t\n",
    "\t\t\tvalid_stacks = []\n",
    "\t\t\tfor j in objects:\n",
    "\t\t\t\tif k != j and not is_edge_in_graph(self.env.state_graph, k, j):\n",
    "\t\t\t\t\tif is_stable(self.env.state_graph.x, k, j):\n",
    "\t\t\t\t\t\tif is_empty_object(self.env.state_graph, j):\n",
    "\t\t\t\t\t\t\tvalid_stacks.append(self.env.encode_action('stack', k, j, 0))\n",
    "\t\t\t\t\t\t\tif len(valid_stacks) >= stack_nums:\n",
    "\t\t\t\t\t\t\t\tbreak\n",
    "\n",
    "\t\t\tvalid_moves = []\n",
    "\t\t\tfor position in get_empty_positions_with_target(self.env, ref_node=k, n=self.num_buffers-len(valid_stacks)):\n",
    "\t\t\t\tvalid_moves.append(self.env.encode_action('move', k, k, position))\n",
    "\n",
    "\t\t\tvalid_actions += valid_stacks + valid_moves\n",
    "\n",
    "\t\treturn valid_actions\n",
    "\n",
    "\tdef select(self, node):\n",
    "\t\t# Accesses child nodes for best selection\n",
    "\t\tif self.c_min == np.inf or self.c_max == self.c_min:\n",
    "\t\t\treturn min(node.children.values(), key=lambda child: child.uct())\n",
    "\t\telse:\n",
    "\t\t\treturn min(node.children.values(), key=lambda child: child.uct(self.c_min, self.c_max))\n",
    "\n",
    "\tdef expand(self, node):\n",
    "\t\tif node.is_fully_expanded():\n",
    "\t\t\treturn None  # Prevents further expansion if no actions remain\n",
    "\n",
    "\t\taction = node.unexpanded_actions.pop()\n",
    "\t\tself.env.set_state(node.get_state())\n",
    "\t\taction_type, start_obj, target_obj, coordinates = self.env.decode_action(action)\n",
    "\n",
    "\t\t# Continue expanding if the last changed node is the same as the current node\n",
    "\t\tif node.action is not None:\n",
    "\t\t\t_, last_obj, _, _ = self.env.decode_action(node.action)\n",
    "\t\t\tif last_obj == start_obj:\n",
    "\t\t\t\treturn self.expand(node)\n",
    "\n",
    "\t\tcost, child_state = self.env._step(action_type, start_obj, target_obj, coordinates)\n",
    "\n",
    "\t\t# Continue expanding if the state hasn't changed\n",
    "\t\tif torch.equal(child_state['graph'].x, node.state['graph'].x):\n",
    "\t\t\traise ValueError('State has not changed')\n",
    "\n",
    "\t\tchild_node = self.node_class(\n",
    "\t\t\tstate=child_state, \n",
    "\t\t\tvalid_actions=self.get_valid_actions(self.env.get_state()), \n",
    "\t\t\tparent=node, \n",
    "\t\t\taction=action, \n",
    "\t\t\tcost=cost, \n",
    "\t\t\tcost_to_come=cost+node.c_cost,\n",
    "\t\t\tc=node.c, \n",
    "\t\t\tdepth=node.depth+1\n",
    "\t\t)\n",
    "\t\tnode.children[action] = child_node\n",
    "\n",
    "\t\treturn child_node\n",
    "\n",
    "\tdef rollout_one(self, node):\n",
    "\t\tcosts = 0\n",
    "\n",
    "\t\tself.env.set_state(node.get_state())\n",
    "\t\tsim_time_limit = (self.time_limit - time.time() + self.start_time) / 4\n",
    "\t\tfeasible_path, steps, _ = LabbeS(self.env).solve(time_limit=sim_time_limit, moving_buff=self.moving_buff)\n",
    "\t\tself.env.set_state(node.get_state())\n",
    "\n",
    "\t\tif feasible_path:\t\t\n",
    "\t\t\tfor i, action in enumerate(feasible_path):\n",
    "\t\t\t\tcost, child_state = self.env.step(action)\n",
    "\t\t\t\tcosts += cost\n",
    "\t\t\t\tif i == 0:\n",
    "\t\t\t\t\t# remove action from the node's unexpanded actions\n",
    "\t\t\t\t\tif action in node.unexpanded_actions:\n",
    "\t\t\t\t\t\tnode.unexpanded_actions.remove(action)\n",
    "\t\t\t\t\t# add the new child to the node\n",
    "\t\t\t\t\tchild_node = self.node_class(\n",
    "\t\t\t\t\t\tstate=child_state, \n",
    "\t\t\t\t\t\tvalid_actions=self.get_valid_actions(self.env.get_state()), \n",
    "\t\t\t\t\t\tparent=node, \n",
    "\t\t\t\t\t\taction=action, \n",
    "\t\t\t\t\t\tcost=cost, \n",
    "\t\t\t\t\t\tcost_to_come=cost+node.c_cost,\n",
    "\t\t\t\t\t\tc=node.c, \n",
    "\t\t\t\t\t\tdepth=node.depth+1\n",
    "\t\t\t\t\t)\n",
    "\t\t\t\t\tnode.children[action] = child_node\n",
    "\t\t\t\t\tnode = child_node\n",
    "\n",
    "\t\treturn costs, steps, feasible_path, node\n",
    "\n",
    "\tdef rollout(self, node):\n",
    "\t\tcosts = 0\n",
    "\n",
    "\t\tself.env.set_state(node.get_state())\n",
    "\t\tsim_time_limit = (self.time_limit - time.time() + self.start_time) / 4\n",
    "\t\tfeasible_path, steps, _ = LabbeS(self.env).solve(time_limit=sim_time_limit, moving_buff=self.moving_buff)\n",
    "\t\tself.env.set_state(node.get_state())\n",
    "\n",
    "\t\tif feasible_path:\n",
    "\t\t\tfor action in feasible_path:\n",
    "\t\t\t\tcost, child_state = self.env.step(action)\n",
    "\t\t\t\tcosts += cost\n",
    "\t\t\t\t# remove action from the node's unexpanded actions\n",
    "\t\t\t\tif action in node.unexpanded_actions:\n",
    "\t\t\t\t\tnode.unexpanded_actions.remove(action)\n",
    "\t\t\t\t# add the new child to the node\n",
    "\t\t\t\tchild_node = self.node_class(\n",
    "\t\t\t\t\tstate=child_state, \n",
    "\t\t\t\t\tvalid_actions=self.get_valid_actions(self.env.get_state()), \n",
    "\t\t\t\t\tparent=node, \n",
    "\t\t\t\t\taction=action, \n",
    "\t\t\t\t\tcost=cost, \n",
    "\t\t\t\t\tcost_to_come=cost+node.c_cost,\n",
    "\t\t\t\t\tc=node.c, \n",
    "\t\t\t\t\tdepth=node.depth+1\n",
    "\t\t\t\t)\n",
    "\t\t\t\tnode.children[action] = child_node\n",
    "\t\t\t\tnode = child_node\n",
    "\n",
    "\t\treturn costs, steps, feasible_path, node\n",
    "\n",
    "\tdef backup_search(self, node, value):\n",
    "\t\twhile node is not None:\n",
    "\t\t\tnode.n += 1\n",
    "\t\t\t# node.w += value\n",
    "\t\t\tnode.w = min(node.w, value)\n",
    "\t\t\tvalue += node.cost\n",
    "\t\t\tnode = node.parent\n",
    "\n",
    "\tdef print_tree(self, node, depth=0, max_depth=float('inf'), ter=False):\n",
    "\t\tif depth >= max_depth:\n",
    "\t\t\treturn\n",
    "\n",
    "\t\t# Print the current node with indentation to show its depth in the tree\n",
    "\t\tindent = \"    \" * depth  # Four spaces per level of depth\n",
    "\t\tif node.id == 0:\n",
    "\t\t\tprint(f\"Root | n: {node.n} | w: {node.w:.2f}\")\n",
    "\t\telse:\n",
    "\t\t\tn = node.n\n",
    "\t\t\tif self.c_max == self.c_min:\n",
    "\t\t\t\t# expected_value = node.c_cost + node.w / n\n",
    "\t\t\t\texpected_value = node.c_cost + node.w\n",
    "\t\t\telse:\n",
    "\t\t\t\t# expected_value = ( (node.c_cost + node.w / n) - self.c_min ) / (self.c_max - self.c_min)\n",
    "\t\t\t\texpected_value = ( (node.c_cost + node.w) - self.c_min ) / (self.c_max - self.c_min)\n",
    "\t\t\texploration_term = np.sqrt(2 * np.log(node.parent.n) / n)\n",
    "\n",
    "\t\t\tprint(f\"{indent}ID: {node.id} | a: {node.action} | c: {node.cost:.2f} | ctc: {node.c_cost:.2f} | \"\n",
    "\t\t\t\t\tf\"n: {node.n} | w: {node.w:.2f} | expe: {expected_value:.4f} | expl: {exploration_term:.4f}\")\n",
    "\n",
    "\t\t# Sort children by w estimate\n",
    "\t\tif ter:\n",
    "\t\t\taccepted_children = [child for child in node.children.values()]\n",
    "\t\t\tchildren = sorted(accepted_children, key=lambda child: child.w)\n",
    "\t\telse:\n",
    "\t\t\tchildren = sorted(node.children.values(), key=lambda child: child.w)\n",
    "\n",
    "\t\t# Recurse on children\n",
    "\t\tfor child in children:\n",
    "\t\t\tself.print_tree(child, depth + 1, max_depth, ter)\n",
    "\n",
    "\tdef find_best_path(self):\n",
    "\t\t# self.print_tree(self.root_node, max_depth=5)\n",
    "\t\tif self.best_plan is None or self.best_plan[1] is None:\n",
    "\t\t\treturn None\n",
    "\t\treturn reconstruct_path(self.best_plan[0]) + self.best_plan[1]\n",
    "\n",
    "\tdef loop(self):\n",
    "\t\tnode = self.root_node\n",
    "\n",
    "\t\t# Selection\n",
    "\t\tself.env.set_state(node.get_state())\n",
    "\t\twhile node.is_fully_expanded() and not self.env.is_terminal_state():\n",
    "\t\t\tnode = self.select(node)\n",
    "\t\t\tself.env.set_state(node.get_state())\n",
    "\n",
    "\t\t# Expansion\n",
    "\t\tif not self.env.is_terminal_state():\n",
    "\t\t\tchild_node = self.expand(node)\n",
    "\t\t\tif child_node is None:\n",
    "\t\t\t\twhile len(node.children) == 0 and node.is_fully_expanded():\n",
    "\t\t\t\t\tnode.parent.children.pop(node.action)\n",
    "\t\t\t\t\tnode = node.parent\n",
    "\t\t\t\t\tprint('oooooooooooooooooooo laaaaaaaa laaaaaaaaaaaaa')\n",
    "\t\t\t\treturn 1\n",
    "\t\t\tnode = child_node\n",
    "\n",
    "\t\t# Simulation (Rollout)\n",
    "\t\tself.env.set_state(node.get_state())\n",
    "\t\tsteps = 0\n",
    "\t\tif self.env.is_terminal_state():\n",
    "\t\t\tvalue = 0\n",
    "\t\telse:\n",
    "\t\t\tif self.one_step:\n",
    "\t\t\t\tc_rollout, steps, feasible_plan, child_node = self.rollout_one(node)\n",
    "\t\t\telse:\n",
    "\t\t\t\tc_rollout, steps, feasible_plan, child_node = self.rollout(node)\n",
    "\n",
    "\t\t\tif feasible_plan is None:\n",
    "\t\t\t\tif node.parent is None:\n",
    "\t\t\t\t\treturn -1\n",
    "\t\t\t\tnode.parent.children.pop(node.action)\n",
    "\t\t\t\tnode = node.parent\n",
    "\t\t\t\twhile len(node.children) == 0 and node.is_fully_expanded():\n",
    "\t\t\t\t\tnode.parent.children.pop(node.action)\n",
    "\t\t\t\t\tnode = node.parent\n",
    "\t\t\t\t\tif node.parent is None:\n",
    "\t\t\t\t\t\treturn -1\n",
    "\t\t\t\treturn steps\n",
    "\n",
    "\t\t\tnew_cost = c_rollout + node.c_cost\n",
    "\t\t\tself.c_max = max(self.c_max, new_cost)\n",
    "\t\t\tif new_cost < self.c_min:\n",
    "\t\t\t\tself.best_plan = (node, feasible_plan)\n",
    "\t\t\t\tself.c_min = new_cost\n",
    "\t\t\t\n",
    "\t\t\tnode = child_node\n",
    "\t\t\tif self.one_step:\n",
    "\t\t\t\tvalue = c_rollout - node.cost\n",
    "\t\t\telse:\n",
    "\t\t\t\tvalue = 0\n",
    "\n",
    "\t\t# Backpropagation\n",
    "\t\tself.backup_search(node, value)\n",
    "\n",
    "\t\treturn steps\n",
    "\n",
    "\tdef solve(self, iterations=1000, num_buffers=3, c=1, verbose=0, one_step=True, moving_buff=True, time_limit=None):\n",
    "\t\tself.start_time = time.time()\n",
    "\t\tself.moving_buff = moving_buff\n",
    "\n",
    "\t\tMctsNode.node_counter = 0\n",
    "\t\tself.num_buffers = num_buffers\n",
    "\t\tself.time_limit = time_limit\n",
    "\t\tself.one_step = one_step\n",
    "\t\tself.c_max = -np.inf\n",
    "\t\tself.c_min = np.inf\n",
    "\t\tself.best_plan = None\n",
    "\t\twindow_last_values = []\n",
    "\t\tself.root_node = self.node_class(\n",
    "\t\t\tstate=self.env.get_state(), \n",
    "\t\t\tvalid_actions=self.get_valid_actions(self.env.get_state()), \n",
    "\t\t\tc=c\n",
    "\t\t)\n",
    "\t\t\n",
    "\t\tsteps, iteration = 0, 0\n",
    "\t\tif verbose > 0:\n",
    "\t\t\tpbar = tqdm(total=None, unit='iterations')\n",
    "\t\t\n",
    "\t\twhile iteration < iterations:\n",
    "\t\t\t# Check if the elapsed time has exceeded the limit\n",
    "\t\t\tif time_limit is not None and  time.time()-self.start_time > time_limit:\n",
    "\t\t\t\tif verbose > 0:\n",
    "\t\t\t\t\tpbar.close()\n",
    "\t\t\t\tprint('Time limit exceeded')\n",
    "\t\t\t\treturn self.find_best_path(), steps, time.time()-self.start_time\n",
    "\t\t\t\n",
    "\t\t\titeration += 1\n",
    "\t\t\tstep = self.loop()\n",
    "\t\t\tif step == -1:\n",
    "\t\t\t\treturn self.find_best_path(), steps, time.time()-self.start_time\n",
    "\t\t\t\n",
    "\t\t\tsteps += step\n",
    "\t\t\tif verbose > 0:\n",
    "\t\t\t\tpbar.update(1)\n",
    "\t\t\t\n",
    "\t\t\t# if iteration != 0 and iteration % 20 == 0:\n",
    "\t\t\t# \t# v_root = self.root_node.w\n",
    "\t\t\t# \t# print(f'v_root: {v_root:.3f} | c_min: {self.c_min:.3f} | c_max: {self.c_max:.3f}')\n",
    "\t\t\t# \t# self.print_tree(self.root_node, max_depth=3)\n",
    "\t\t\t# \twindow_last_values.append(self.c_min)\n",
    "\t\t\t# \tif len(window_last_values) > 5:\n",
    "\t\t\t# \t\twindow_last_values.pop(0)\n",
    "\t\t\t# \t\tif len(set(window_last_values)) == 1:\n",
    "\t\t\t# \t\t\tbreak\n",
    "\n",
    "\t\tif verbose > 0:\n",
    "\t\t\tpbar.close()\n",
    "\n",
    "\t\treturn self.find_best_path(), steps, time.time()-self.start_time\n",
    "\n",
    "# evaluate_alg_n_times(env, Sorp, initial_scene, target_scene, num_runs=1, iterations=1000, num_buffers=4, c=0.5, verbose=0, one_step=True, time_limit=10);\n",
    "# evaluate_alg_n_times(env, Sorp, initial_scene, target_scene, num_runs=5, iterations=1000, num_buffers=4, c=1, verbose=0, one_step=True, time_limit=20);\n",
    "# env.moving_buff = False\n",
    "# evaluate_alg(env, Sorp, initial_scene, target_scene, iterations=1000, num_buffers=4, c=0.5, verbose=1, one_step=True, moving_buff=env.moving_buff, time_limit=60);\n",
    "# env.moving_buff = True,\n",
    "# evaluate_alg(env, Sorp, initial_scene, target_scene, iterations=1000, num_buffers=4, c=0.5, verbose=1, one_step=True, moving_buff=env.moving_buff, time_limit=60);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Refinement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def refine_until_convergence(env, plan, initial_scene, target_scene, alg, verbose=0):\n",
    "\tstart_time = time.time()\n",
    "\tbest_plan = plan\n",
    "\tbest_cost = env_cost(env, plan, initial_scene, target_scene, log=False)\n",
    "\tif plan is None:\n",
    "\t\treturn best_plan, best_cost, time.time() - start_time\n",
    "\twhile True:\n",
    "\t\tif alg in ['Labbe', 'Strap', 'StrapGA']:\n",
    "\t\t\trefined_plan = plan_refinement(env, plan, initial_scene, target_scene, verbose=verbose)\n",
    "\t\telse:\n",
    "\t\t\trefined_plan = plan_refinement_stack(env, plan, initial_scene, target_scene, verbose=verbose)\n",
    "\n",
    "\t\tif plan == refined_plan:\n",
    "\t\t\tbreak\n",
    "\n",
    "\t\tcost = env_cost(env, refined_plan, initial_scene, target_scene, log=False)\n",
    "\t\tif cost < best_cost:\n",
    "\t\t\tif verbose > 0:\n",
    "\t\t\t\tprint(f'cost got better from {best_cost:.3f} to {cost:.3f}')\n",
    "\t\t\tbest_cost = cost\n",
    "\t\t\tbest_plan = refined_plan\n",
    "\n",
    "\t\tplan = refined_plan\n",
    "\n",
    "\treturn best_plan, best_cost, time.time() - start_time\n",
    "\n",
    "def plan_refinement(env, plan, initial_scene, target_scene, verbose=0):\n",
    "\taction_seq = []\n",
    "\tenv.reset(initial_scene, target_scene)\n",
    "\tfor action in plan:\n",
    "\t\ta_type, k, _, coordinates = env.decode_action(action)\n",
    "\t\tif a_type == 'stack':\n",
    "\t\t\tif verbose > 0:\n",
    "\t\t\t\tprint('there is a stack in the simple refinement')\n",
    "\t\t\treturn plan\n",
    "\t\tp_pick = get_obj_pos(env.state_graph, k)\n",
    "\t\tp_place = unflatten_pos(coordinates, env.grid_size)\n",
    "\t\t\n",
    "\t\t# Prevent the same object to be moved twice in a row\n",
    "\t\tif len(action_seq) > 0 and action_seq[-1]['k'] == k:\n",
    "\t\t\tpre_p_place = action_seq[-1]['p_place']\n",
    "\t\t\taction_seq[-1] = {\n",
    "\t\t\t\t'k': k,\n",
    "\t\t\t\t'p_pick': p_pick,\n",
    "\t\t\t\t'p_place': p_place\n",
    "\t\t\t}\n",
    "\t\t\tif verbose > 0:\n",
    "\t\t\t\tprint(f'Redundant moving of obj {k} to {pre_p_place} was removed')\n",
    "\t\telse:\n",
    "\t\t\taction_seq.append({\n",
    "\t\t\t\t'k': k,\n",
    "\t\t\t\t'p_pick': p_pick,\n",
    "\t\t\t\t'p_place': p_place\n",
    "\t\t\t})\n",
    "\n",
    "\t\tenv.step(action)\n",
    "\n",
    "\tenv.reset(initial_scene, target_scene)\n",
    "\tB = {}\n",
    "\tH = {0: {'state': env.get_state(), 'table': env.table}}\t\t# arrangement history\n",
    "\tfor i in range(len(action_seq)):\n",
    "\t\tk = action_seq[i]['k']\n",
    "\n",
    "\t\tif k in B:\t\t\t# if object k was moved\n",
    "\t\t\tbIdx = B[k]\t\t# previous action index on k\n",
    "\t\t\tsize_k = get_obj_size(env.state_graph, k)\n",
    "\n",
    "\t\t\t# Occupied possitions in the action index bIdx\n",
    "\t\t\tC = []\n",
    "\t\t\tfor position in get_all_positions_in_env(env.grid_size, size_k):\n",
    "\t\t\t\tposition = torch.tensor(position, dtype=torch.float32)\n",
    "\t\t\t\tif env.is_coor_occupied(position, k, H[bIdx]['table']):\n",
    "\t\t\t\t\tC.append(position)\n",
    "\t\t\t\n",
    "\t\t\t# Ocuupied buffers in the action index bIdx to i-1\n",
    "\t\t\tfor j in range(bIdx, i):\n",
    "\t\t\t\tif action_seq[j]['k'] != k:\n",
    "\t\t\t\t\tsize = env.get_obj_size(action_seq[j]['k'])\n",
    "\t\t\t\t\tsize = (size[0]+size_k[0]-1, size[1]+size_k[1]-1)\n",
    "\t\t\t\t\tfor position in get_all_positions_of_object(action_seq[j]['p_place'], size):\n",
    "\t\t\t\t\t\tC.append(torch.tensor(position, dtype=torch.float32))\n",
    "\n",
    "\t\t\t# Generate a buffer set under constraint C\n",
    "\t\t\tP = []\n",
    "\t\t\tfor position in get_all_positions_in_env(env.grid_size, size_k):\n",
    "\t\t\t\tposition = torch.tensor(position, dtype=torch.float32)\n",
    "\t\t\t\tif not any(torch.equal(position, c) for c in C):\n",
    "\t\t\t\t\tP.append(position)\n",
    "\t\t\tif len(P) == 0:\n",
    "\t\t\t\tif verbose > 0:\n",
    "\t\t\t\t\tprint(f'No feasible buffer set')\n",
    "\n",
    "\t\t\t# Distances\n",
    "\t\t\tp1 = action_seq[bIdx]['p_pick']\n",
    "\t\t\tp2 = action_seq[i-1]['p_place']\n",
    "\t\t\tp3 = action_seq[bIdx+1]['p_pick']\n",
    "\t\t\tp4 = action_seq[i]['p_place']\n",
    "\n",
    "\t\t\t# Current cost\n",
    "\t\t\tp = action_seq[bIdx]['p_place'].clone()\n",
    "\t\t\tmin_cost = env.cal_manipulator_movement(p1, p)\n",
    "\t\t\tmin_cost += env.cal_manipulator_movement(p, p3)\n",
    "\t\t\tmin_cost += env.cal_manipulator_movement(p2, p)\n",
    "\t\t\tmin_cost += env.cal_manipulator_movement(p, p4)\n",
    "\t\t\tmin_cost = min_cost * env.normalization_factor\n",
    "\n",
    "\t\t\t# Find the best buffer\n",
    "\t\t\tbest_p = None\n",
    "\t\t\tfor p in P:\n",
    "\t\t\t\tcost = env.cal_manipulator_movement(p1, p)\n",
    "\t\t\t\tcost += env.cal_manipulator_movement(p, p3)\n",
    "\t\t\t\tcost += env.cal_manipulator_movement(p2, p)\n",
    "\t\t\t\tcost += env.cal_manipulator_movement(p, p4)\n",
    "\t\t\t\tcost = cost * env.normalization_factor\n",
    "\t\t\t\tif cost < min_cost:\n",
    "\t\t\t\t\tbest_p = p.clone()\n",
    "\t\t\t\t\tmin_cost = cost\n",
    "\n",
    "\t\t\t# Update the best buffer\n",
    "\t\t\tif best_p is not None:\n",
    "\t\t\t\tif verbose > 0:\n",
    "\t\t\t\t\tlast_pos = action_seq[bIdx]['p_place']\n",
    "\t\t\t\t\tprint(f'Buffer of obj {k} changed from pos {last_pos.tolist()} to pos {best_p.tolist()}')\n",
    "\n",
    "\t\t\t\taction_seq[bIdx] = {\n",
    "\t\t\t\t\t'k': k,\n",
    "\t\t\t\t\t'p_pick': action_seq[bIdx]['p_pick'].clone(),\n",
    "\t\t\t\t\t'p_place': best_p\n",
    "\t\t\t\t}\n",
    "\t\t\t\tif torch.equal(best_p, action_seq[i]['p_place']):\n",
    "\t\t\t\t\tif verbose > 0:\n",
    "\t\t\t\t\t\tprint(f'New static buffer is the same as the current one, so the action {i} is removed')\n",
    "\t\t\t\t\tdel action_seq[i]\n",
    "\t\t\t\telse:\n",
    "\t\t\t\t\taction_seq[i] = {\n",
    "\t\t\t\t\t\t'k': k,\n",
    "\t\t\t\t\t\t'p_pick': best_p,\n",
    "\t\t\t\t\t\t'p_place': action_seq[i]['p_place'].clone()\n",
    "\t\t\t\t\t}\n",
    "\t\t\t\tbreak\n",
    "\n",
    "\t\tenv.step(plan[i])\n",
    "\t\tH[i+1] = {'state': env.get_state(), 'table': env.table}\n",
    "\t\tB[k] = i\n",
    "\n",
    "\trefined_plan = [env.encode_action('move', a['k'], a['k'], flatten_pos(a['p_place'], env.grid_size)) for a in action_seq]\n",
    "\n",
    "\treturn refined_plan\n",
    "\n",
    "def plan_refinement_stack(env, plan, initial_scene, target_scene, verbose=0):\n",
    "\taction_seq = []\n",
    "\tenv.reset(initial_scene, target_scene)\n",
    "\tfor action in plan:\n",
    "\t\ta_type, k, l, coordinates = env.decode_action(action)\n",
    "\t\tp_pick = get_obj_pos(env.state_graph, k)\n",
    "\t\tif a_type == 'move':\n",
    "\t\t\tp_place = unflatten_pos(coordinates, env.grid_size)\n",
    "\t\telif a_type == 'stack':\n",
    "\t\t\tp_place = get_obj_pos(env.state_graph, l)\n",
    "\t\telse:\n",
    "\t\t\traise ValueError('Invalid action type')\n",
    "\n",
    "\t\t# Prevent the same object to be moved twice in a row\n",
    "\t\tif len(action_seq) > 0 and action_seq[-1]['k'] == k:\n",
    "\t\t\tpre_p_place = action_seq[-1]['p_place']\n",
    "\t\t\tpre_l = action_seq[-1]['l']\n",
    "\t\t\taction_seq[-1] = {\n",
    "\t\t\t\t'type': a_type,\n",
    "\t\t\t\t'k': k,\n",
    "\t\t\t\t'l': l,\n",
    "\t\t\t\t'p_pick': p_pick,\n",
    "\t\t\t\t'p_place': p_place\n",
    "\t\t\t}\n",
    "\t\t\tif verbose > 0:\n",
    "\t\t\t\tif a_type == 'stack':\n",
    "\t\t\t\t\tprint(f'Redundant stacking of obj {k} to obj {pre_l} was removed')\n",
    "\t\t\t\telse:\n",
    "\t\t\t\t\tprint(f'Redundant moving of obj {k} to {pre_p_place} was removed')\n",
    "\t\telse:\n",
    "\t\t\taction_seq.append({\n",
    "\t\t\t\t'type': a_type,\n",
    "\t\t\t\t'k': k,\n",
    "\t\t\t\t'l': l,\n",
    "\t\t\t\t'p_pick': p_pick,\n",
    "\t\t\t\t'p_place': p_place\n",
    "\t\t\t})\n",
    "\n",
    "\t\tenv.step(action)\n",
    "\n",
    "\tenv.reset(initial_scene, target_scene)\n",
    "\tB = {}\n",
    "\tH = {0: {'state': env.get_state(), 'table': env.table}}\t\t# arrangement history\n",
    "\tfor i in range(len(action_seq)):\n",
    "\t\tk = action_seq[i]['k']\n",
    "\n",
    "\t\tif k in B:\t\t\t# if object k was moved\n",
    "\t\t\tbIdx = B[k]\t\t# previous action index on k\n",
    "\t\t\tsize_k = get_obj_size(env.state_graph, k)\n",
    "\n",
    "\t\t\t# Occupied possitions in the action index bIdx\n",
    "\t\t\tC = []\n",
    "\t\t\tfor position in get_all_positions_in_env(env.grid_size, size_k):\n",
    "\t\t\t\tposition = torch.tensor(position, dtype=torch.float32)\n",
    "\t\t\t\tif env.is_coor_occupied(position, k, H[bIdx]['table']):\n",
    "\t\t\t\t\tC.append(position)\n",
    "\n",
    "\t\t\t# Ocuupied static buffers in the action index bIdx to i-1\n",
    "\t\t\tfor j in range(bIdx, i):\n",
    "\t\t\t\t# If the action is stack, continue\n",
    "\t\t\t\tif action_seq[j]['type'] == 'stack':\n",
    "\t\t\t\t\tcontinue\n",
    "\t\t\t\tif action_seq[j]['k'] != k:\n",
    "\t\t\t\t\tsize = get_obj_size(env.state_graph, action_seq[j]['k'])\n",
    "\t\t\t\t\tsize = (size[0]+size_k[0]-1, size[1]+size_k[1]-1)\n",
    "\t\t\t\t\tfor position in get_all_positions_of_object(action_seq[j]['p_place'], size):\n",
    "\t\t\t\t\t\tC.append(torch.tensor(position, dtype=torch.float32))\n",
    "\n",
    "\t\t\t# Ocuupied moving buffers in the action index bIdx to i-1\n",
    "\t\t\tempty_objs = []\n",
    "\t\t\tfor obj in range(env.num_objects):\n",
    "\t\t\t\tif is_stable(H[0]['state']['graph'].x, k, obj):\n",
    "\t\t\t\t\tis_empty = True\n",
    "\t\t\t\t\tfor j in range(bIdx, i):\n",
    "\t\t\t\t\t\tif not is_empty_object(H[j]['state']['graph'], obj):\n",
    "\t\t\t\t\t\t\tis_empty = False\n",
    "\t\t\t\t\t\t\tbreak\n",
    "\t\t\t\t\tif is_empty:\n",
    "\t\t\t\t\t\tempty_objs.append(obj)\n",
    "\n",
    "\t\t\t# Generate a buffer set under constraint C\n",
    "\t\t\tP = []\n",
    "\t\t\tfor position in get_all_positions_in_env(env.grid_size, size_k):\n",
    "\t\t\t\tposition = torch.tensor(position, dtype=torch.float32)\n",
    "\t\t\t\tif not any(torch.equal(position, c) for c in C):\n",
    "\t\t\t\t\tP.append(position)\n",
    "\t\t\tif len(P) == 0:\n",
    "\t\t\t\tif verbose > 0:\n",
    "\t\t\t\t\tprint(f'No feasible buffer set')\n",
    "\n",
    "\t\t\t# Distances\n",
    "\t\t\tp1 = action_seq[bIdx]['p_pick']\n",
    "\t\t\tp2 = action_seq[i-1]['p_place']\n",
    "\t\t\tp3 = action_seq[bIdx+1]['p_pick']\n",
    "\t\t\tp4 = action_seq[i]['p_place']\n",
    "\n",
    "\t\t\t# Current cost\n",
    "\t\t\tif action_seq[bIdx]['type'] == 'stack':\n",
    "\t\t\t\tp_to_buff = action_seq[bIdx]['p_place'].clone()\n",
    "\t\t\t\tp_i = get_obj_pos(H[i]['state']['graph'], k)\n",
    "\t\t\t\tmin_cost = env.cal_manipulator_movement(p1, p_to_buff)\n",
    "\t\t\t\tmin_cost += env.cal_manipulator_movement(p_to_buff, p3)\n",
    "\t\t\t\tmin_cost += env.cal_manipulator_movement(p2, p_i)\n",
    "\t\t\t\tmin_cost += env.cal_manipulator_movement(p_i, p4)\n",
    "\t\t\t\tmin_cost = min_cost * env.normalization_factor\n",
    "\t\t\telse:\n",
    "\t\t\t\tp = action_seq[bIdx]['p_place'].clone()\n",
    "\t\t\t\tmin_cost = env.cal_manipulator_movement(p1, p)\n",
    "\t\t\t\tmin_cost += env.cal_manipulator_movement(p, p3)\n",
    "\t\t\t\tmin_cost += env.cal_manipulator_movement(p2, p)\n",
    "\t\t\t\tmin_cost += env.cal_manipulator_movement(p, p4)\n",
    "\t\t\t\tmin_cost = min_cost * env.normalization_factor\n",
    "\n",
    "\t\t\t# Find the best buffer\n",
    "\t\t\tbest_p = None\n",
    "\t\t\tfor p in P:\n",
    "\t\t\t\tcost = env.cal_manipulator_movement(p1, p)\n",
    "\t\t\t\tcost += env.cal_manipulator_movement(p, p3)\n",
    "\t\t\t\tcost += env.cal_manipulator_movement(p2, p)\n",
    "\t\t\t\tcost += env.cal_manipulator_movement(p, p4)\n",
    "\t\t\t\tcost = cost * env.normalization_factor\n",
    "\t\t\t\tif cost < min_cost:\n",
    "\t\t\t\t\tbest_p = p.clone()\n",
    "\t\t\t\t\tmin_cost = cost\n",
    "\n",
    "\t\t\tbest_obj = None\n",
    "\t\t\tfor empty_obj in empty_objs:\n",
    "\t\t\t\tp_to_buff = get_obj_pos(H[bIdx]['state']['graph'], empty_obj)\n",
    "\t\t\t\tp_i = get_obj_pos(H[i]['state']['graph'], empty_obj)\n",
    "\t\t\t\tcost = env.cal_manipulator_movement(p1, p_to_buff)\n",
    "\t\t\t\tcost += env.cal_manipulator_movement(p_to_buff, p3)\n",
    "\t\t\t\tcost += env.cal_manipulator_movement(p2, p_i)\n",
    "\t\t\t\tcost += env.cal_manipulator_movement(p_i, p4)\n",
    "\t\t\t\tcost = cost * env.normalization_factor\n",
    "\t\t\t\tif cost < min_cost:\n",
    "\t\t\t\t\tmin_cost = cost\n",
    "\t\t\t\t\tbest_obj = empty_obj\n",
    "\n",
    "\t\t\t# Update the best buffer\n",
    "\t\t\tif best_obj is not None:\n",
    "\t\t\t\tif verbose > 0:\n",
    "\t\t\t\t\tif action_seq[bIdx]['type'] == 'stack':\n",
    "\t\t\t\t\t\tlast_obj = action_seq[bIdx]['l']\n",
    "\t\t\t\t\t\tprint(f'Buffer of obj {k} changed from obj {last_obj} to obj {best_obj}')\n",
    "\t\t\t\t\telse:\n",
    "\t\t\t\t\t\tlast_pos = action_seq[bIdx]['p_place']\n",
    "\t\t\t\t\t\tprint(f'Buffer of obj {k} changed from pos {last_pos.tolist()} to obj {best_obj}')\n",
    "\n",
    "\t\t\t\taction_seq[bIdx] = {\n",
    "\t\t\t\t\t'type': 'stack',\n",
    "\t\t\t\t\t'k': k,\n",
    "\t\t\t\t\t'l': best_obj,\n",
    "\t\t\t\t\t'p_pick': action_seq[bIdx]['p_pick'].clone(),\n",
    "\t\t\t\t\t'p_place': get_obj_pos(H[bIdx]['state']['graph'], best_obj)\n",
    "\t\t\t\t}\n",
    "\t\t\t\tif action_seq[i]['type'] == 'stack' and action_seq[i]['l'] == best_obj:\n",
    "\t\t\t\t\tif verbose > 0:\n",
    "\t\t\t\t\t\tprint(f'New moving buffer is the same as the current one, so the action {i} is removed')\n",
    "\t\t\t\t\tdel action_seq[i]\n",
    "\t\t\t\telse:\n",
    "\t\t\t\t\taction_seq[i]['p_pick'] = get_obj_pos(H[i]['state']['graph'], best_obj)\n",
    "\t\t\t\tbreak\n",
    "\t\t\telif best_p is not None:\n",
    "\t\t\t\tif verbose > 0:\n",
    "\t\t\t\t\tif action_seq[bIdx]['type'] == 'stack':\n",
    "\t\t\t\t\t\tlast_obj = action_seq[bIdx]['l']\n",
    "\t\t\t\t\t\tprint(f'Buffer of obj {k} changed from obj {last_obj} to pos {best_p.tolist()}')\n",
    "\t\t\t\t\telse:\n",
    "\t\t\t\t\t\tlast_pos = action_seq[bIdx]['p_place']\n",
    "\t\t\t\t\t\tprint(f'Buffer of obj {k} changed from pos {last_pos.tolist()} to pos {best_p.tolist()}')\n",
    "\n",
    "\t\t\t\taction_seq[bIdx] = {\n",
    "\t\t\t\t\t'type': 'move',\n",
    "\t\t\t\t\t'k': k,\n",
    "\t\t\t\t\t'l': k,\n",
    "\t\t\t\t\t'p_pick': action_seq[bIdx]['p_pick'].clone(),\n",
    "\t\t\t\t\t'p_place': best_p\n",
    "\t\t\t\t}\n",
    "\t\t\t\tif action_seq[i]['type'] == 'move' and torch.equal(best_p, action_seq[i]['p_place']):\n",
    "\t\t\t\t\tif verbose > 0:\n",
    "\t\t\t\t\t\tprint(f'New static buffer is the same as the current one, so the action {i} is removed')\n",
    "\t\t\t\t\tdel action_seq[i]\n",
    "\t\t\t\telse:\n",
    "\t\t\t\t\taction_seq[i]['p_pick'] = best_p\n",
    "\t\t\t\tbreak\n",
    "\n",
    "\t\tenv.step(plan[i])\n",
    "\t\tH[i+1] = {'state': env.get_state(), 'table': env.table}\n",
    "\t\tB[k] = i\n",
    "\n",
    "\trefined_plan = []\n",
    "\tfor a in action_seq:\n",
    "\t\tif a['type'] == 'stack':\n",
    "\t\t\trefined_plan.append(env.encode_action('stack', a['k'], a['l'], 0))\n",
    "\t\telse:\n",
    "\t\t\trefined_plan.append(env.encode_action('move', a['k'], a['k'], flatten_pos(a['p_place'], env.grid_size)))\n",
    "\n",
    "\treturn refined_plan\n",
    "\n",
    "# plan = [1267, 1015, 299, 1518, 1203, 626]\n",
    "# refine_until_convergence(env, plan, initial_scene, target_scene, 'Labbe', verbose=1);\n",
    "# print('------')\n",
    "# refine_until_convergence(env, plan, initial_scene, target_scene, 'LabbeS', verbose=1);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def x_to_edge_index(x):\n",
    "\tedge_index = torch.tensor([], dtype=torch.long)\n",
    "\tfor i in range(len(x)):\n",
    "\t\tfor j in range(len(x)):\n",
    "\t\t\tif x[i][Indices.RELATION.start+j] == 1:\n",
    "\t\t\t\tedge_index = torch.cat((edge_index, torch.tensor([[i], [j]])), dim=1)\n",
    "\treturn edge_index\n",
    "\n",
    "def make_scenes(num_cases, num_objects, grid_size, phi):\n",
    "\tenv = ContinuousEnv(mode='stationary', num_objects=num_objects, grid_size=grid_size, phi=phi, verbose=1)\n",
    "\tscenes = []\n",
    "\tfor _ in range(num_cases):\n",
    "\t\tenv.reset(stack=False)\n",
    "\t\tscenes.append({\n",
    "\t\t\t'initial_scene': copy_graph(env.initial_graph),\n",
    "\t\t\t'target_scene': copy_graph(env.target_graph)\n",
    "\t\t})\n",
    "\t\n",
    "\treturn scenes\n",
    "\n",
    "def save_scenes(scenes, num_objects, grid_size, phi):\n",
    "\tif not os.path.exists(f'scenes'):\n",
    "\t\tos.makedirs(f'scenes')\n",
    "\n",
    "\tfor id, scene in enumerate(scenes):\n",
    "\t\tinitial_scene = scene['initial_scene']\n",
    "\t\ttarget_scene = scene['target_scene']\n",
    "\n",
    "\t\t# save the scene in a json file\n",
    "\t\tobjs = []\n",
    "\t\tfor obj in range(num_objects):\n",
    "\t\t\tobj_label = get_obj_label(initial_scene, obj)\n",
    "\t\t\tobjs.append({\n",
    "\t\t\t\t'label': int(obj_label),\n",
    "\t\t\t\t'initial_pos': get_obj_pos(initial_scene, obj).tolist(),\n",
    "\t\t\t\t'initial_relation': initial_scene.x[obj, Indices.RELATION].clone().tolist(),\n",
    "\t\t\t\t'target_pos': get_obj_pos(target_scene, obj).tolist(),\n",
    "\t\t\t\t'target_relation': target_scene.x[obj, Indices.RELATION].clone().tolist(), \n",
    "\t\t\t\t'size': get_obj_size(initial_scene, obj)\n",
    "\t\t\t})\n",
    "\t\t\n",
    "\t\tjson_scene = {\n",
    "\t\t\t'id': id,\n",
    "\t\t\t'phi': cal_density(initial_scene, grid_size),\n",
    "\t\t\t'num_objects': num_objects,\n",
    "\t\t\t'grid_size': grid_size,\n",
    "\t\t\t'objects': objs\n",
    "\t\t}\n",
    "\t\t\n",
    "\t\t# Create the directory if it doesn't exist\n",
    "\t\tif not os.path.exists(f'scenes/phi_{phi}/g{grid_size[0]}.{grid_size[1]}/n{num_objects}'):\n",
    "\t\t\tos.makedirs(f'scenes/phi_{phi}/g{grid_size[0]}.{grid_size[1]}/n{num_objects}')\n",
    "\n",
    "\t\t# Save the scene in a json file\n",
    "\t\twith open(f'scenes/phi_{phi}/g{grid_size[0]}.{grid_size[1]}/n{num_objects}/scene_{id}.json', 'w') as f:\n",
    "\t\t\tjson.dump(json_scene, f, indent=4)\n",
    "\n",
    "def load_json_scenes(num_objects, grid_size, phi):\n",
    "\tscenes = []\n",
    "\tdirectory = f'scenes/phi_{phi}/g{grid_size[0]}.{grid_size[1]}/n{num_objects}'\n",
    "\tfor filename in os.listdir(directory):\n",
    "\t\tif not filename.endswith('.json'):\n",
    "\t\t\tcontinue\n",
    "\t\t\n",
    "\t\twith open(os.path.join(directory, filename), 'r') as f:\n",
    "\t\t\tscene = json.load(f)\n",
    "\t\t\n",
    "\t\tscenes.append(scene)\n",
    "\t\n",
    "\treturn scenes\n",
    "\n",
    "def json_to_graph(json_scene):\n",
    "\tnum_nodes = json_scene['num_objects']\n",
    "\n",
    "\tx_initial = torch.tensor([\n",
    "\t\t[obj['label'], *obj['size'], *obj['initial_pos'], *obj['initial_relation']]\n",
    "\t\tfor obj in json_scene['objects']\n",
    "\t], dtype=torch.float32)\n",
    "\tedge_index = x_to_edge_index(x_initial)\n",
    "\tinitial_scene = Data(x=x_initial, edge_index=edge_index, pos=get_node_poses(num_nodes))\n",
    "\n",
    "\tx_target = torch.tensor([\n",
    "\t\t[obj['label'], *obj['size'], *obj['target_pos'], *obj['target_relation']]\n",
    "\t\tfor obj in json_scene['objects']\n",
    "\t], dtype=torch.float32)\n",
    "\tedge_index = x_to_edge_index(x_target)\n",
    "\ttarget_scene = Data(x=x_target, edge_index=edge_index, pos=get_node_poses(num_nodes))\n",
    "\n",
    "\treturn initial_scene, target_scene\n",
    "\n",
    "def load_scenes(num_objects, grid_size, phi):\n",
    "\tscenes = []\n",
    "\n",
    "\tjson_scenes = load_json_scenes(num_objects, grid_size, phi)\n",
    "\tfor json_scene in json_scenes:\n",
    "\t\tinitial_scene, target_scene = json_to_graph(json_scene)\n",
    "\t\tscenes.append({\n",
    "\t\t\t'initial_scene': initial_scene,\n",
    "\t\t\t'target_scene': target_scene\n",
    "\t\t})\n",
    "\n",
    "\treturn scenes\n",
    "\n",
    "def plot_characteristics(ax, runs, key, title=\"\"):\n",
    "\txtics = []\n",
    "\tfor run in runs:\n",
    "\t\tx_axis = range(1, len(run['runs'])+1)\n",
    "\t\ty_axis = [run[key] for run in run['runs']]\n",
    "\t\tax.plot(x_axis, y_axis, label=f\"{run['num_objects']}n_{run['grid_size']}g\")\n",
    "\t\tif len(xtics) < len(x_axis):\n",
    "\t\t\txtics = x_axis\n",
    "\t\n",
    "\tax.set_xticks(xtics)\n",
    "\tax.set_title(title)\n",
    "\tax.set_xlabel('Samples')\n",
    "\tif key == 'elapsed_time':\n",
    "\t\tax.set_ylabel(f'Time elapsed (s)')\n",
    "\telse:\n",
    "\t\tax.set_ylabel(f'{key}')\n",
    "\tax.legend()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create scenes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_complexities_kde(values: dict, title='', figsize=(8, 3)):\n",
    "\tplt.figure(figsize=figsize)\n",
    "\tfor key in values.keys():\n",
    "\t\tsns.kdeplot(values[key], label=f'n = {key}')\n",
    "\t\n",
    "\tplt.title(title)\n",
    "\tplt.xlabel('Density')\n",
    "\tplt.ylabel('Frequency')\n",
    "\tplt.xlim(0.0, 1)\n",
    "\tplt.legend()\n",
    "\tplt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "\tplt.tight_layout()\n",
    "\tplt.show()\n",
    "\n",
    "def plot_complexities_hist(values: dict, title='', figsize=(5, 2)):\n",
    "\tnum_plots = len(values)\n",
    "\tfig, axes = plt.subplots(num_plots, 1, figsize=(figsize[0], figsize[1] * num_plots)) # Adjust figure size\n",
    "\n",
    "\tfor i, key in enumerate(values.keys()):\n",
    "\t\tax = axes[i] if num_plots > 1 else axes # Handle single plot case\n",
    "\t\tsns.histplot(values[key], bins=30, kde=True, ax=ax)\n",
    "\t\t# sns.kdeplot(values[key], ax=ax)\n",
    "\t\tax.set_title(f'n = {key}')\n",
    "\t\tax.set_xlabel('Density')\n",
    "\t\tax.set_xlim(0.0, 0.6)\n",
    "\t\tax.set_ylabel('Frequency')\n",
    "\t\tax.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "\n",
    "\tplt.suptitle(title)\n",
    "\tplt.tight_layout() # Improves subplot spacing\n",
    "\tplt.show()\n",
    "\n",
    "num_cases = 20\n",
    "n_values = [3, 4, 5, 6, 7, 8]\n",
    "\n",
    "phi = 0.2\n",
    "grid_size = (101, 101)\n",
    "\n",
    "densities = {}\n",
    "for num_objects in n_values:\n",
    "\t# print(num_objects)\n",
    "\t# scenes = make_scenes(num_cases, num_objects, grid_size, phi)\n",
    "\t# save_scenes(scenes, num_objects, grid_size, phi)\n",
    "\tscenes = load_scenes(num_objects, grid_size, phi)\n",
    "\tdensities[num_objects] =[]\n",
    "\tfor i, scene in enumerate(scenes):\n",
    "\t\tdensities[num_objects].append(cal_density(scene['initial_scene'], grid_size))\n",
    "\n",
    "# plot_complexities_kde(densities, title=f'size = {grid_size} | φ = {phi}')\n",
    "# plot_complexities_hist(densities, title=f'size = {grid_size} | φ = {phi}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_runs(json_scenes, env, phi, alg, file_name, num_runs=1, **kwargs):\n",
    "\tfile_dir = f'runs/phi_{phi}/{env.mode}/g{env.grid_size[0]}.{env.grid_size[1]}/n{env.num_objects}'\n",
    "\tif not os.path.exists(file_dir):\n",
    "\t\tos.makedirs(file_dir)\n",
    "\t\n",
    "\tdata_path = os.path.join(file_dir, f'{file_name}.csv')\n",
    "\n",
    "\t# Remove the file if it already exists\n",
    "\tif os.path.exists(data_path):\n",
    "\t\tprint(f\"Existing file found at {data_path}, removing it.\")\n",
    "\t\tos.remove(data_path)\n",
    "\n",
    "\tprint(f'----{alg.__name__}:{file_name}----')\n",
    "\tpbar = tqdm(total=len(json_scenes), unit='scene')\n",
    "\tfirst_row = not os.path.exists(data_path)  # To include header only once\n",
    "\n",
    "\tfor json_scene in json_scenes:\n",
    "\t\tplans, steps, elapsed_times, costs = [], [], [], []\n",
    "\t\tfor _ in range(num_runs):\n",
    "\t\t\tinitial_scene, target_scene = json_to_graph(json_scene)\n",
    "\t\t\tenv.reset(initial_scene, target_scene)\n",
    "\t\t\tplan, step, elapsed_time = alg(env).solve(**kwargs)\n",
    "\t\t\tcost = env_cost(env, plan, initial_scene, target_scene, log=False)\n",
    "\n",
    "\t\t\tplans.append(plan)\n",
    "\t\t\tsteps.append(step)\n",
    "\t\t\telapsed_times.append(elapsed_time)\n",
    "\t\t\tcosts.append(cost)\n",
    "\t\t\n",
    "\t\t# Create a single-row DataFrame\n",
    "\t\trow = pd.DataFrame([{\n",
    "\t\t\t'scene_id': json_scene['id'],\n",
    "\t\t\t'mode': env.mode,\n",
    "\t\t\t'n': json_scene['num_objects'],\n",
    "\t\t\t'grid_size': json_scene['grid_size'],\n",
    "\t\t\t'alg': file_name,\n",
    "\t\t\t'plans': plans,\n",
    "\t\t\t'steps': steps,\n",
    "\t\t\t'elapsed_times': elapsed_times,\n",
    "\t\t\t'costs': costs,\n",
    "\t\t}])\n",
    "\n",
    "\t\t# Append to CSV\n",
    "\t\trow.to_csv(data_path, mode='a', header=first_row, index=False)\n",
    "\t\tfirst_row = False  # Only write header for the first row\n",
    "\n",
    "\t\tpbar.update(1)\n",
    "\tpbar.close()\n",
    "\n",
    "phi = 0.2\n",
    "time_limit = 500\n",
    "\n",
    "# grid_size = (36, 91)\n",
    "# mode = 'mobile'\n",
    "grid_size = (101, 101)\n",
    "mode = 'stationary'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Labbe Tunning\n",
    "num_runs = 3\n",
    "time_limit = 300\n",
    "for num_objects in [3, 4, 5]:\n",
    "\tenv = ContinuousEnv(mode=mode, num_objects=num_objects, grid_size=grid_size, verbose=0)\n",
    "\tjson_scenes, object_sizes = load_json_scenes(num_objects, grid_size, phi)\n",
    "\tenv.object_sizes = object_sizes\n",
    "\tsave_runs(json_scenes, env, phi, Labbe, \"Labbe\", num_runs=num_runs, c=0.5, time_limit=time_limit)\n",
    "\tsave_runs(json_scenes, env, phi, LabbeS, \"LabbeS\", num_runs=num_runs, c=0.5, time_limit=time_limit)\n",
    "\tsave_runs(json_scenes, env, phi, Labbe, \"Labbe-c.2\", num_runs=num_runs, c=0.2, time_limit=time_limit)\n",
    "\tsave_runs(json_scenes, env, phi, LabbeS, \"LabbeS-c.2\", num_runs=num_runs, c=0.2, time_limit=time_limit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_objects = 3\n",
    "env = ContinuousEnv(mode=mode, num_objects=num_objects, grid_size=grid_size, phi=phi, verbose=0)\n",
    "json_scenes, object_sizes = load_json_scenes(num_objects, grid_size, phi)\n",
    "env.object_sizes = object_sizes\n",
    "save_runs(json_scenes, env, phi, Labbe, \"Labbe\", c=0.5, time_limit=time_limit)\n",
    "save_runs(json_scenes, env, phi, LabbeS, \"LabbeS\", c=0.5, time_limit=time_limit)\n",
    "save_runs(json_scenes, env, phi, StrapGA, \"StrapGA\", num_buffers=4, time_limit=time_limit)\n",
    "save_runs(json_scenes, env, phi, A_starGA, \"A_starGA\", num_buffers=4, time_limit=time_limit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phi = 0.5\n",
    "time_limit = 500\n",
    "grid_size = (50, 50)\n",
    "mode = 'stationary'\n",
    "moving_buff = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_objects = 3\n",
    "env = ContinuousEnv(mode=mode, num_objects=num_objects, grid_size=grid_size, verbose=0)\n",
    "env.moving_buff = moving_buff\n",
    "json_scenes, object_sizes = load_json_scenes(num_objects, grid_size, phi)\n",
    "env.object_sizes = object_sizes\n",
    "save_runs(json_scenes, env, phi, LabbeS, \"LabbeS_MBoff\", c=0.5, time_limit=time_limit, moving_buff=moving_buff)\n",
    "save_runs(json_scenes, env, phi, A_starGA, \"A_starGA_MBoff\", num_buffers=4, time_limit=time_limit, moving_buff=moving_buff)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas.api.types import CategoricalDtype\n",
    "\n",
    "def load_runs(mode, grid_size, algs, n_values, phi):\n",
    "\tall_dfs = []\n",
    "\n",
    "\tfor num_objects in n_values:\n",
    "\t\tfor alg_name in algs:\n",
    "\t\t\tfilename = f'runs/phi_{phi}/{mode}/g{grid_size[0]}.{grid_size[1]}/n{num_objects}/{alg_name}.csv'\n",
    "\t\t\tif not os.path.isfile(filename):\n",
    "\t\t\t\tcontinue\n",
    "\t\t\t\n",
    "\t\t\t# Read CSV\n",
    "\t\t\tdf = pd.read_csv(filename)\n",
    "\n",
    "\t\t\t# calculate the mean not-None costs\n",
    "\t\t\tdf['cost'] = df['costs'].apply(lambda x: np.mean([cost for cost in eval(x) if cost is not None]) if isinstance(eval(x), list) else np.nan)\n",
    "\t\t\tdf['step'] = df['steps'].apply(lambda x: np.mean([step for step in eval(x)]))\n",
    "\t\t\tdf['elapsed_time'] = df['elapsed_times'].apply(lambda x: np.mean([time for time in eval(x)]))\n",
    "\n",
    "\t\t\tall_dfs.append(df)\n",
    "\n",
    "\t# Merge all into one big DataFrame\n",
    "\tif all_dfs:\n",
    "\t\tmerged_df = pd.concat(all_dfs, ignore_index=True)\n",
    "\t\treturn merged_df\n",
    "\telse:\n",
    "\t\tprint(\"No valid run files found.\")\n",
    "\t\treturn pd.DataFrame()  # Return empty DF if nothing was loaded\n",
    "\n",
    "def compare_algs(df, figsize=(10, 4), std=False, sr=False, step=False, title=''):\n",
    "\tif df.empty:\n",
    "\t\tprint(\"No data to compare.\")\n",
    "\n",
    "\t# Filter only valid rows (cost not null = successful run)\n",
    "\tdf['success'] = df['cost'].notna()\n",
    "\n",
    "\t# Preserve algorithm order as they appear in the dataframe\n",
    "\talg_order = df['alg'].drop_duplicates().tolist()\n",
    "\talg_dtype = CategoricalDtype(categories=alg_order, ordered=True)\n",
    "\tdf['alg'] = df['alg'].astype(alg_dtype)\n",
    "\t\n",
    "\t# Group by n and alg\n",
    "\tgrouped = df.groupby(['n', 'alg'])\n",
    "\n",
    "\t# Aggregated metrics\n",
    "\tagg_df = grouped.agg(\n",
    "\t\tcost_mean=('cost', 'mean'),\n",
    "\t\tcost_std=('cost', 'std'),\n",
    "\t\tstep_mean=('step', 'mean'),\n",
    "\t\tstep_std=('step', 'std'),\n",
    "\t\ttime_mean=('elapsed_time', 'mean'),\n",
    "\t\ttime_std=('elapsed_time', 'std'),\n",
    "\t\tsuccess_rate=('success', lambda x: 100 * x.sum() / len(x))\n",
    "\t).reset_index()\n",
    "\n",
    "\t# Ensure algorithm column stays ordered\n",
    "\tagg_df['alg'] = agg_df['alg'].astype(alg_dtype)\n",
    "\n",
    "\t# Pivot with ordered columns\n",
    "\tcost_mean_pivot = agg_df.pivot(index='n', columns='alg', values='cost_mean')[alg_order]\n",
    "\tstep_mean_pivot = agg_df.pivot(index='n', columns='alg', values='step_mean')[alg_order]\n",
    "\ttime_mean_pivot = agg_df.pivot(index='n', columns='alg', values='time_mean')[alg_order]\n",
    "\n",
    "\tcost_std_pivot = agg_df.pivot(index='n', columns='alg', values='cost_std')[alg_order] if std else None\n",
    "\tstep_std_pivot = agg_df.pivot(index='n', columns='alg', values='step_std')[alg_order] if std else None\n",
    "\ttime_std_pivot = agg_df.pivot(index='n', columns='alg', values='time_std')[alg_order] if std else None\n",
    "\n",
    "\t# Plot\n",
    "\tsns.set_style('whitegrid')\n",
    "\tif sr and step:\n",
    "\t\tfig, axs = plt.subplots(1, 4, figsize=figsize)\n",
    "\telif sr or step:\n",
    "\t\tfig, axs = plt.subplots(1, 3, figsize=figsize)\n",
    "\telse:\n",
    "\t\tfig, axs = plt.subplots(1, 2, figsize=figsize)\n",
    "\n",
    "\tplot_bars(cost_mean_pivot, 'Cost Comparison', 'Cost', std_data=cost_std_pivot, ax=axs[0], cmap=colormaps['tab20b'])\n",
    "\tplot_bars(time_mean_pivot, 'Time Comparison', 'Time (log scale)', std_data=time_std_pivot, log_scale=True, ax=axs[1], cmap=colormaps['tab20b'])\n",
    "\tif sr and step:\n",
    "\t\tsr_pivot = agg_df.pivot(index='n', columns='alg', values='success_rate') if sr else None\n",
    "\t\tplot_bars(step_mean_pivot, 'Step Comparison', 'Step', std_data=step_std_pivot, ax=axs[2], cmap=colormaps['tab20b'])\n",
    "\t\tplot_bars(sr_pivot, 'Success Rate', 'Success Rate (%)', ax=axs[3], cmap=colormaps['tab20b'])\n",
    "\telif sr:\n",
    "\t\tsr_pivot = agg_df.pivot(index='n', columns='alg', values='success_rate') if sr else None\n",
    "\t\tplot_bars(sr_pivot, 'Success Rate', 'Success Rate (%)', ax=axs[2], cmap=colormaps['tab20b'])\n",
    "\telif step:\n",
    "\t\tplot_bars(step_mean_pivot, 'Step Comparison', 'Step', std_data=step_std_pivot, ax=axs[2], cmap=colormaps['tab20b'])\n",
    "\t\n",
    "\tfig.suptitle(title, fontsize=16)\n",
    "\tplt.tight_layout()\n",
    "\tplt.show()\n",
    "\n",
    "def plot_bars(df, title, ylabel, std_data=None, log_scale=False, ax=None, cmap=colormaps['tab20b']):\n",
    "\tif ax is None:\n",
    "\t\tfig, ax = plt.subplots(figsize=(6, 4))\n",
    "\n",
    "\tn_values = df.index.tolist()\n",
    "\talgs = df.columns.tolist()\n",
    "\tx = np.arange(len(n_values))\n",
    "\tbar_width = 0.1\n",
    "\n",
    "\tcolors = [cmap(i / len(algs)) for i in range(len(algs))]\n",
    "\n",
    "\tfor i, alg in enumerate(algs):\n",
    "\t\tvalues = df[alg].values\n",
    "\t\terrors = std_data[alg].values if std_data is not None and alg in std_data.columns else None\n",
    "\t\t# if alg == 'Labbe':\n",
    "\t\t# \tlabel = 'MCTS'\n",
    "\t\t# elif alg == 'LabbeS':\n",
    "\t\t# \tlabel = 'MCTS+Stack'\n",
    "\t\t# elif alg == 'A_star':\n",
    "\t\t# \tlabel = 'Strap+Stack'\n",
    "\t\t# elif alg == 'A_starGA':\n",
    "\t\t# \tlabel = 'StrapGA+Stack'\n",
    "\t\t# else:\n",
    "\t\tlabel = alg\n",
    "\n",
    "\t\tax.bar(x + i * bar_width, values, width=bar_width, color=colors[i], label=label, yerr=errors, capsize=5 if errors is not None else 0)\n",
    "\n",
    "\tax.set_xlabel('Number of Objects (n)')\n",
    "\tax.set_ylabel(ylabel)\n",
    "\tax.set_title(title)\n",
    "\tax.set_xticks(x + bar_width * (len(algs) - 1) / 2)\n",
    "\tax.set_xticklabels(n_values)\n",
    "\tax.legend(title='Algorithm')\n",
    "\n",
    "\tif log_scale:\n",
    "\t\tax.set_yscale('log')\n",
    "\n",
    "\tax.grid(axis='y', linestyle='--', alpha=0.7)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phi = 0.2\n",
    "algs = [\"Labbe\", \"LabbeS\", \"StrapGA\", \"A_starGA\"]\n",
    "n_values = [3, 4, 5, 6, 7, 8]\n",
    "\n",
    "grid_size = (100, 100)\n",
    "mode = 'stationary'\n",
    "df = load_runs(mode, grid_size, algs, n_values, phi)\n",
    "compare_algs(df, figsize=(16, 5), sr=False, title=f'{mode} | size = {grid_size} | φ = {phi}')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
