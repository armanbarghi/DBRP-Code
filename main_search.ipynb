{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import json\n",
    "import heapq\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import colormaps\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "import seaborn as sns\n",
    "from torch_geometric.data import Data\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import Union\n",
    "import networkx as nx\n",
    "\n",
    "from utils.graph_env import set_objects\n",
    "set_objects('set1')\n",
    "\n",
    "from utils.graph_env import (\n",
    "    OBJECTS, create_graph,\n",
    "    plot_graph, copy_graph, cal_density,\n",
    "    Indices, get_obj_label, get_obj_pos, get_obj_size, get_obj_relation, \n",
    "    get_object_base, get_object_above, get_object_bellow,\n",
    "    in_table_index, is_empty_object, is_stable, is_stacked, is_in_env, is_stacked_on_object,\n",
    "    flatten_pos, unflatten_pos, get_node_poses, x_to_edge_index,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_occupying_objs(table, coor, size):\n",
    "\toccupying_objs = []\n",
    "\tunique_nums = np.unique(table[in_table_index(coor, size)])\n",
    "\n",
    "\tfor num in unique_nums:\n",
    "\t\tif num == 0:\n",
    "\t\t\tcontinue\n",
    "\t\toccupying_objs.append(num-1)\n",
    "\n",
    "\treturn occupying_objs\n",
    "\n",
    "def get_empty_objs(env, ref_node, n=1):\n",
    "\tall_objects = list(range(env.num_objects))\n",
    "\tnp.random.shuffle(all_objects)\n",
    "\n",
    "\tempty_objs = []\n",
    "\tfor obj in all_objects:\n",
    "\t\tif is_empty_object(env.state_graph.x, obj) and is_stable(env.state_graph.x, ref_node, obj):\n",
    "\t\t\tempty_objs.append(obj)\n",
    "\t\t\tif len(empty_objs) >= n:\n",
    "\t\t\t\tbreak\n",
    "\t\t\t\n",
    "\treturn empty_objs\n",
    "\n",
    "def get_all_positions_of_object(coord, size):\n",
    "    idx = in_table_index(coord, size)\n",
    "    x_range = np.arange(idx[0].start, idx[0].stop)\n",
    "    y_range = np.arange(idx[1].start, idx[1].stop)\n",
    "    x, y = np.meshgrid(x_range, y_range, indexing='ij')\n",
    "    return np.column_stack((x.ravel(), y.ravel()))\n",
    "\n",
    "def get_all_positions_in_env(grid_size, size):\n",
    "    x_range = np.arange(size[0] // 2, grid_size[0] - size[0] // 2)\n",
    "    y_range = np.arange(size[1] // 2, grid_size[1] - size[1] // 2)\n",
    "    x, y = np.meshgrid(x_range, y_range, indexing='ij')\n",
    "    return np.column_stack((x.ravel(), y.ravel()))\n",
    "\n",
    "def get_empty_positions(env, ref_node, n=1, sort=False):\n",
    "\tref_size = get_obj_size(env.state_graph.x, ref_node)\n",
    "\tall_positions = get_all_positions_in_env(env.grid_size, ref_size)\n",
    "\tif sort:\n",
    "\t\tall_positions = sorted(all_positions, key=lambda x: score(env, x, ref_node))\n",
    "\telse:\n",
    "\t\tnp.random.shuffle(all_positions)\n",
    "\n",
    "\tpositions = []\n",
    "\tfor position in all_positions:\n",
    "\t\tposition = torch.tensor(position, dtype=torch.float32)\n",
    "\t\tif not env.is_coor_occupied(position, ref_node):\n",
    "\t\t\tpositions.append(flatten_pos(position, env.grid_size))\n",
    "\t\t\tif len(positions) >= n:\n",
    "\t\t\t\tbreak\n",
    "\n",
    "\treturn positions\n",
    "\n",
    "def draw_dependency_graph(env, fig_size=(2.5, 2.5)):\n",
    "\tdependency_graph = nx.DiGraph()\n",
    "\tfor k in range(env.num_objects):\n",
    "\t\tdependency_graph.add_node(k)\n",
    "\t\ti = get_object_bellow(env.target_graph.x, k)\n",
    "\t\tif i is None:\n",
    "\t\t\tj = get_object_bellow(env.state_graph.x, k)\n",
    "\t\t\tCK = get_obj_pos(env.state_graph.x, k)\n",
    "\t\t\tTK = get_obj_pos(env.target_graph.x, k)\n",
    "\t\t\tif torch.equal(CK, TK):\n",
    "\t\t\t\twhile j is not None:\n",
    "\t\t\t\t\tif not dependency_graph.has_edge(k, j):\n",
    "\t\t\t\t\t\tdependency_graph.add_edge(k, j)\n",
    "\t\t\t\t\tj = get_object_bellow(env.state_graph.x, j)\n",
    "\t\t\telse:\n",
    "\t\t\t\tsize_k = get_obj_size(env.state_graph.x, k)\n",
    "\t\t\t\toccupying_nodes = find_occupying_objs(env.table, TK, size_k)\n",
    "\t\t\t\tfor j in occupying_nodes:\n",
    "\t\t\t\t\tif j != k:\n",
    "\t\t\t\t\t\tj = get_object_base(env.state_graph.x, j)\n",
    "\t\t\t\t\t\tif not dependency_graph.has_edge(k, j):\n",
    "\t\t\t\t\t\t\tdependency_graph.add_edge(k, j)\n",
    "\t\telse:\n",
    "\t\t\tj = get_object_above(env.state_graph.x, i)\n",
    "\t\t\tif j is not None and j != k:\n",
    "\t\t\t\tdependency_graph.add_edge(k, j)\n",
    "\n",
    "\tfig, ax = plt.subplots(1, 1, figsize=fig_size)\n",
    "\tnx.draw(dependency_graph, env.state_graph.pos, with_labels=True, node_size=400, ax=ax, node_color='skyblue')\n",
    "\tplt.title('Dependency Graph')\n",
    "\tplt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "phi: 0.212 | uniform size: (23, 23)\n",
      "Manipulator: [49.5 49.5]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def get_obj_sizes(num_objects, grid_size, phi, verbose=0):\n",
    "\tobject_sizes = {k: v[\"size\"] for k, v in OBJECTS.items()}\n",
    "\tnum_labels = len(object_sizes)\n",
    "\n",
    "\tif phi == 'mix':\n",
    "\t\tif verbose:\n",
    "\t\t\tprint('Using default object sizes')\n",
    "\t\treturn object_sizes\n",
    "\n",
    "\tbase_size = (1, 1)\n",
    "\tbest_phi = 0\n",
    "\tbest_sizes = {k: base_size for k in object_sizes}\n",
    "\n",
    "\tmax_iters = max(grid_size) // 3\n",
    "\n",
    "\tfor i in range(max_iters):\n",
    "\t\tcurrent_sizes = {k: (base_size[0] + 2*i, base_size[1] + 2*i) for k in object_sizes}\n",
    "\t\tgraph = create_graph(num_objects, grid_size, num_labels, current_sizes, stack_prob=0.0)\n",
    "\t\tnew_phi = cal_density(graph, grid_size)\n",
    "\n",
    "\t\tif abs(new_phi - phi) > abs(best_phi - phi):\n",
    "\t\t\tbreak\n",
    "\n",
    "\t\tbest_phi = new_phi\n",
    "\t\tbest_sizes = current_sizes\n",
    "\n",
    "\tif verbose:\n",
    "\t\tfirst_key = next(iter(best_sizes))\n",
    "\t\tprint(f'phi: {best_phi:.3f} | uniform size: {best_sizes[first_key]}')\n",
    "\n",
    "\treturn best_sizes\n",
    "\n",
    "class ContinuousEnv:\n",
    "\tdef __init__(\n",
    "\t\t\tself, mode, \n",
    "\t\t\tnum_objects, grid_size, \n",
    "\t\t\tstatic_stack=False, terminal_cost=False, \n",
    "\t\t\tphi='mix', verbose=1,\n",
    "\t\t):\n",
    "\t\tself.mode = mode\n",
    "\t\tself.num_objects = num_objects\n",
    "\t\tself.grid_size = grid_size\n",
    "\t\tself.static_stack = static_stack\n",
    "\t\tself.terminal_cost = terminal_cost\n",
    "\t\tself.verbose = verbose\n",
    "\t\tself.object_sizes = get_obj_sizes(num_objects, grid_size, phi, verbose=verbose)\n",
    "\n",
    "\t\tif self.mode == 'mobile':\n",
    "\t\t\tself.manipulator_initial_pos = torch.tensor([0, (self.grid_size[1]-1)/2], dtype=torch.float32)\n",
    "\t\telif self.mode == 'stationary':\n",
    "\t\t\tself.manipulator_initial_pos = torch.tensor([(self.grid_size[0]-1)/2, (self.grid_size[1]-1)/2], dtype=torch.float32)\n",
    "\t\telse:\n",
    "\t\t\traise ValueError('Invalid mode')\n",
    "\t\t\n",
    "\t\tself.normalization_factor = 1 / min(self.grid_size)\n",
    "\t\tself.manipulator = self.manipulator_initial_pos.clone()\n",
    "\t\tself.pp_cost = 0.2\n",
    "\t\tself.punish_cost = 100\n",
    "\t\tself.num_labels = len(self.object_sizes)\n",
    "\n",
    "\tdef is_terminal_state(self):\n",
    "\t\treturn torch.equal(self.state_graph.x, self.target_graph.x)\n",
    "\n",
    "\tdef remove_edge(self, node1, node2):\n",
    "\t\tmask = ~((self.state_graph.edge_index[0] == node1) & (self.state_graph.edge_index[1] == node2))\n",
    "\t\tself.state_graph.edge_index = self.state_graph.edge_index[:, mask]\n",
    "\t\tself.state_graph.x[node1][Indices.RELATION.start+node2] = 0\n",
    "\n",
    "\tdef add_edge(self, node1, node2):\n",
    "\t\tnew_edge = torch.tensor([[node1], [node2]], dtype=torch.long)\n",
    "\t\tself.state_graph.edge_index = torch.cat([self.state_graph.edge_index, new_edge], dim=1)\n",
    "\t\tself.state_graph.x[node1][Indices.RELATION.start+node2] = 1\n",
    "\n",
    "\tdef decode_action(self, action: int):\n",
    "\t\tn = self.num_objects\n",
    "\t\tm = self.grid_size[0] * self.grid_size[1]\n",
    "\t\tnum_edge_actions = n * (n - 1)\n",
    "\t\tcoordinates = 0\n",
    "\n",
    "\t\tif action < num_edge_actions:\n",
    "\t\t\taction_type = 'stack'\n",
    "\t\t\tstart_node = action // (n - 1)\n",
    "\t\t\ttarget_node = action % (n - 1)\n",
    "\t\t\tif target_node >= start_node:\n",
    "\t\t\t\ttarget_node += 1\n",
    "\t\telse:\n",
    "\t\t\taction_type = 'move'\n",
    "\t\t\tadjusted_action = action - num_edge_actions\n",
    "\t\t\tstart_node = adjusted_action // m\n",
    "\t\t\tcoordinates = adjusted_action % m\n",
    "\t\t\ttarget_node = start_node\n",
    "\n",
    "\t\treturn action_type, start_node, target_node, coordinates\n",
    "\n",
    "\tdef encode_action(self, action_type: str, start_node: int, target_node: int, coordinates: Union[int, list, np.ndarray, torch.Tensor])-> int:\n",
    "\t\t# Convert coordinate pair to flattened index if needed\n",
    "\t\tif isinstance(coordinates, torch.Tensor):\n",
    "\t\t\tcoordinates = int(flatten_pos(coordinates, self.grid_size).item())\n",
    "\t\telif isinstance(coordinates, list) or isinstance(coordinates, np.ndarray):\n",
    "\t\t\tcoordinates = int(flatten_pos(coordinates, self.grid_size))\n",
    "\n",
    "\t\tn = self.num_objects\n",
    "\t\tm = self.grid_size[0] * self.grid_size[1]\n",
    "\t\tnum_edge_actions = n * (n - 1)\n",
    "\n",
    "\t\tif action_type == 'stack':\n",
    "\t\t\tif target_node >= start_node:\n",
    "\t\t\t\ttarget_node -= 1\n",
    "\t\t\taction = start_node * (n - 1) + target_node\n",
    "\t\telif action_type == 'move':\n",
    "\t\t\taction = num_edge_actions + start_node * m + coordinates\n",
    "\t\telse:\n",
    "\t\t\traise ValueError('Invalid action type')\n",
    "\n",
    "\t\treturn action\n",
    "\n",
    "\tdef create_graph(self, labels=None, use_stack=True, use_sides=False, prev_sides=None):\n",
    "\t\tstack_prob = 0.9 if use_stack else 0.0\n",
    "\t\treturn create_graph(\n",
    "\t\t\tself.num_objects, self.grid_size, self.num_labels, \n",
    "\t\t\tself.object_sizes, labels, stack_prob=stack_prob, \n",
    "\t\t\tuse_sides=use_sides, prev_sides=prev_sides,\n",
    "\t\t\tswitch_prob=0.5,\n",
    "\t\t)\n",
    "\n",
    "\tdef get_state(self):\n",
    "\t\treturn {'graph': copy_graph(self.state_graph), 'manipulator': self.manipulator.clone()}\n",
    "\n",
    "\tdef set_state(self, state):\n",
    "\t\tself.state_graph = copy_graph(state['graph'])\n",
    "\t\tself.manipulator = state['manipulator'].clone()\n",
    "\t\tself.make_table()\n",
    "\n",
    "\tdef make_table(self, state_graph=None):\n",
    "\t\tif state_graph is None:\n",
    "\t\t\tstate_graph = self.state_graph\n",
    "\n",
    "\t\tself.table = np.zeros(self.grid_size, dtype=int)\n",
    "\t\tfor i in range(self.num_objects):\n",
    "\t\t\tif is_stacked(state_graph.x, i):\n",
    "\t\t\t\tcontinue\n",
    "\t\t\tcoor_i = get_obj_pos(state_graph.x, i).numpy()\n",
    "\t\t\tsize_i = get_obj_size(state_graph.x, i)\n",
    "\t\t\tself.table[in_table_index(coor_i, size_i)] = i+1\n",
    "\n",
    "\tdef make_target_table(self):\n",
    "\t\tself.target_table = np.zeros(self.grid_size, dtype=int)\n",
    "\t\tfor i in range(self.num_objects):\n",
    "\t\t\tif is_stacked(self.target_graph.x, i):\n",
    "\t\t\t\tcontinue\n",
    "\t\t\tcoor_i = get_obj_pos(self.target_graph.x, i).numpy()\n",
    "\t\t\tsize_i = get_obj_size(self.target_graph.x, i)\n",
    "\t\t\tself.target_table[in_table_index(coor_i, size_i)] = i+1\n",
    "\n",
    "\tdef reset(self, state_graph=None, target_graph=None, use_stack=True, use_sides=False):\n",
    "\t\tself.steps = 0\n",
    "\t\tif state_graph is None:\n",
    "\t\t\tself.state_graph = self.create_graph(use_stack=use_stack, use_sides=use_sides)\n",
    "\t\telse:\n",
    "\t\t\tself.state_graph = copy_graph(state_graph)\n",
    "\t\t\tfor i in range(self.num_objects):\n",
    "\t\t\t\tlabel_i = get_obj_label(self.state_graph.x, i)\n",
    "\t\t\t\tself.object_sizes[label_i] = get_obj_size(self.state_graph.x, i)\n",
    "\n",
    "\t\tprev_sides = None\n",
    "\t\t# if use_sides:\n",
    "\t\t# \tprev_sides = []\n",
    "\t\t# \tfor i in range(self.state_graph.num_nodes):\n",
    "\t\t# \t\tif get_obj_pos(self.state_graph.x, i)[1] < self.grid_size[1] // 2:\n",
    "\t\t# \t\t\tprev_sides.append('left')\n",
    "\t\t# \t\telse:\n",
    "\t\t# \t\t\tprev_sides.append('right')\n",
    "\n",
    "\t\tself.initial_graph = copy_graph(self.state_graph)\n",
    "\t\tlabels = list(self.state_graph.x[:, Indices.LABEL].reshape(-1).numpy())\n",
    "\t\tlabels = list(map(int, labels))\n",
    "\t\tif target_graph is None:\n",
    "\t\t\tself.target_graph = self.create_graph(labels, use_stack=use_stack, use_sides=use_sides, prev_sides=prev_sides)\n",
    "\t\t\twhile torch.equal(self.state_graph.x, self.target_graph.x):\n",
    "\t\t\t\tself.target_graph = self.create_graph(labels, use_stack=use_stack, use_sides=use_sides, prev_sides=prev_sides)\n",
    "\t\telse:\n",
    "\t\t\tself.target_graph = copy_graph(target_graph)\n",
    "\t\t\ttarget_labels = list(self.target_graph.x[:, Indices.LABEL].reshape(-1).numpy())\n",
    "\t\t\ttarget_labels = list(map(int, target_labels))\n",
    "\t\t\t# check whether the target graph has the same labels as the state graph\n",
    "\t\t\tif labels != target_labels:\n",
    "\t\t\t\traise ValueError('Target graph has different labels than the state graph')\n",
    "\t\t\n",
    "\t\tif use_stack is False:\n",
    "\t\t\tif torch.sum(self.state_graph.x[:, Indices.RELATION]) > 0:\n",
    "\t\t\t\traise ValueError('Initial graph has edges in Non-stack mode')\n",
    "\t\t\tif torch.sum(self.target_graph.x[:, Indices.RELATION]) > 0:\n",
    "\t\t\t\traise ValueError('Target graph has edges in Non-stack mode')\n",
    "\n",
    "\t\tself.manipulator = self.manipulator_initial_pos.clone()\n",
    "\t\tself.make_table()\n",
    "\t\tself.make_target_table()\n",
    "\t\treturn self.get_state(), {}\n",
    "\n",
    "\tdef render(self, with_target=True, fig_size=2.5, return_fig=False, manipulator=False):\n",
    "\t\tif self.verbose > 0:\n",
    "\t\t\tprint(f'Manipulator: {self.manipulator.numpy()}')\n",
    "\t\tconstraints = get_all_positions_of_object(self.manipulator, (5, 5)) if manipulator else []\n",
    "\t\t\n",
    "\t\t# Apply mask to filter the points\n",
    "\t\tmask = (constraints[:, 0] >= 0) & (constraints[:, 0] < self.grid_size[0]) & (constraints[:, 1] >= 0) & (constraints[:, 1] < self.grid_size[1])\n",
    "\t\tconstraints = constraints[mask]\n",
    "\n",
    "\t\tif with_target:\n",
    "\t\t\tscale = max(self.grid_size) / min(self.grid_size)\n",
    "\t\t\tfig, ax = plt.subplots(1, 2, figsize=(fig_size*2*scale, fig_size))\n",
    "\t\t\tplot_graph(self.state_graph, self.grid_size, ax=ax[0], fig_size=fig_size, title='State Scene', constraints=constraints)\t\n",
    "\t\t\tplot_graph(self.target_graph, self.grid_size, ax=ax[1], fig_size=fig_size, title='Target Scene')\n",
    "\t\t\tplt.suptitle(f\"Density: {cal_density(self.state_graph, self.grid_size):.2f}\")\n",
    "\t\telse:\n",
    "\t\t\tfig, ax = plt.subplots(1, 1, figsize=(fig_size, fig_size))\n",
    "\t\t\tplot_graph(self.state_graph, self.grid_size, ax=ax, fig_size=fig_size, title='State Scene', constraints=constraints)\t\t\t\n",
    "\n",
    "\t\tif return_fig:\n",
    "\t\t\tplt.close()\n",
    "\t\t\treturn fig\n",
    "\t\telse:\n",
    "\t\t\tplt.show()\n",
    "\n",
    "\tdef get_valid_stacks(self):\n",
    "\t\tvalid_stacks = []\n",
    "\n",
    "\t\tfor k in range(self.num_objects):\n",
    "\t\t\tif self.static_stack and not is_empty_object(self.state_graph.x, k):\n",
    "\t\t\t\tcontinue\n",
    "\t\t\tfor i in get_empty_objs(self, ref_node=k, n=np.inf):\n",
    "\t\t\t\tvalid_stacks.append(self.encode_action('stack', k, i, 0))\n",
    "\n",
    "\t\treturn valid_stacks\n",
    "\t\n",
    "\tdef get_valid_moves(self, max_num=10):\n",
    "\t\tvalid_moves = []\n",
    "\n",
    "\t\tfor k in range(self.num_objects):\n",
    "\t\t\tif self.static_stack and not is_empty_object(self.state_graph.x, k):\n",
    "\t\t\t\tcontinue\n",
    "\t\t\tfor position in get_empty_positions(self, ref_node=k, n=max_num):\n",
    "\t\t\t\tvalid_moves.append(self.encode_action('move', k, k, position))\n",
    "\n",
    "\t\treturn valid_moves\n",
    "\n",
    "\tdef get_valid_actions(self):\n",
    "\t\treturn self.get_valid_stacks() + self.get_valid_moves()\n",
    "\n",
    "\tdef move_obj_with_stacked_ones(self, node, coordinates):\n",
    "\t\tvisited = [False] * self.num_objects\n",
    "\t\tvisited[node] = True\n",
    "\t\tstack = [node]\n",
    "\t\twhile len(stack) > 0:\n",
    "\t\t\tnode = stack.pop()\n",
    "\t\t\tself.state_graph.x[node, Indices.COORD] = coordinates.clone()\n",
    "\t\t\ti = get_object_above(self.state_graph.x, node)\n",
    "\t\t\tif i is not None and not visited[i]:\n",
    "\t\t\t\tstack.append(i)\n",
    "\t\t\t\tvisited[i] = True\n",
    "\n",
    "\tdef is_coor_occupied(self, coor, node, table=None):\n",
    "\t\tif table is None:\n",
    "\t\t\ttable = self.table\n",
    "\t\t\n",
    "\t\tsize = get_obj_size(self.state_graph.x, node)\n",
    "\t\tif torch.equal(coor, get_obj_pos(self.state_graph.x, node)):\n",
    "\t\t\treturn True\n",
    "\t\tif not is_in_env(coor, size, self.grid_size):\n",
    "\t\t\treturn True\n",
    "\t\tif np.any((table[in_table_index(coor, size)] != 0) & (table[in_table_index(coor, size)] != node+1)):\n",
    "\t\t\treturn True\n",
    "\t\t\n",
    "\t\treturn False\n",
    "\n",
    "\tdef occupied_score(self, coor, node, table=None):\n",
    "\t\tif table is None:\n",
    "\t\t\ttable = self.target_table\n",
    "\t\t\n",
    "\t\tsize = get_obj_size(self.state_graph.x, node)\n",
    "\t\toccupied = np.sum((table[in_table_index(coor, size)] != 0) & (table[in_table_index(coor, size)] != node+1))\n",
    "\t\treturn occupied / (size[0] * size[1])\n",
    "\n",
    "\tdef manipulator_decode(self, coord):\n",
    "\t\tx, y = coord.tolist()\n",
    "\t\theight, width = self.grid_size\n",
    "\t\td_t, d_l, d_b, d_r = x, y, height-1-x, width-1-y\n",
    "\t\tmin_d = min(d_t, d_l, d_b, d_r)\n",
    "\n",
    "\t\tif min_d == d_t:\n",
    "\t\t\treturn 0, y, width-1-y\n",
    "\t\telif min_d == d_r:\n",
    "\t\t\treturn 1, x, height-1-x\n",
    "\t\telif min_d == d_b:\n",
    "\t\t\treturn 2, width-1-y, y\n",
    "\t\telse:\n",
    "\t\t\treturn 3, height-1-x, x\n",
    "\n",
    "\tdef cal_manipulator_movement(self, pre_coord, new_coord):\n",
    "\t\tif self.mode == 'mobile':\n",
    "\t\t\tpre_s, pre_cc, pre_cw = self.manipulator_decode(pre_coord)\n",
    "\t\t\tnew_s, new_cc, new_cw = self.manipulator_decode(new_coord)\n",
    "\t\t\tif pre_s == new_s:\n",
    "\t\t\t\tif pre_s == 0 or pre_s == 2:\n",
    "\t\t\t\t\treturn torch.norm(pre_coord[1] - new_coord[1]).item()\n",
    "\t\t\t\telse:\n",
    "\t\t\t\t\treturn torch.norm(pre_coord[0] - new_coord[0]).item()\n",
    "\t\t\telif (new_s==1 and pre_s==3) or (new_s==3 and pre_s==1):\n",
    "\t\t\t\treturn min(pre_cw + new_cc, pre_cc + new_cw) + self.grid_size[1]\n",
    "\t\t\telif (new_s==2 and pre_s==0) or (new_s==0 and pre_s==2):\n",
    "\t\t\t\treturn min(pre_cw + new_cc, pre_cc + new_cw) + self.grid_size[0]\n",
    "\t\t\telif new_s == pre_s+1 or (new_s == 0 and pre_s == 3):\n",
    "\t\t\t\treturn pre_cw + new_cc + 1\n",
    "\t\t\telse:\n",
    "\t\t\t\treturn pre_cc + new_cw + 1\n",
    "\t\telif self.mode == 'stationary':\n",
    "\t\t\treturn torch.norm(pre_coord - new_coord).item()\n",
    "\n",
    "\tdef cal_movement(self, pre_coord, new_coord):\n",
    "\t\ttotal_movement = 0\n",
    "\t\ttotal_movement += self.cal_manipulator_movement(self.manipulator, pre_coord)\n",
    "\t\ttotal_movement += self.cal_manipulator_movement(pre_coord, new_coord)\n",
    "\t\tif self.mode == 'mobile':\n",
    "\t\t\tnew_s = self.manipulator_decode(new_coord)[0]\n",
    "\t\t\tif new_s == 0:\n",
    "\t\t\t\tself.manipulator = torch.tensor([0, new_coord[1]], dtype=torch.float32)\n",
    "\t\t\telif new_s == 1:\n",
    "\t\t\t\tself.manipulator = torch.tensor([new_coord[0], self.grid_size[1]-1], dtype=torch.float32)\n",
    "\t\t\telif new_s == 2:\n",
    "\t\t\t\tself.manipulator = torch.tensor([self.grid_size[0]-1, new_coord[1]], dtype=torch.float32)\n",
    "\t\t\telse:\n",
    "\t\t\t\tself.manipulator = torch.tensor([new_coord[0], 0], dtype=torch.float32)\n",
    "\t\telif self.mode == 'stationary':\n",
    "\t\t\tself.manipulator = new_coord.clone()\n",
    "\n",
    "\t\treturn total_movement * self.normalization_factor\n",
    "\n",
    "\tdef move_func(self, start_node, coordinates):\n",
    "\t\tif self.is_coor_occupied(coordinates, start_node):\n",
    "\t\t\tprint(f'occupied {coordinates.numpy()}')\n",
    "\t\t\tcost = self.punish_cost\n",
    "\t\telse:\n",
    "\t\t\tprev_target = get_object_bellow(self.state_graph.x, start_node)\n",
    "\t\t\tif prev_target is not None:\n",
    "\t\t\t\tself.remove_edge(start_node, prev_target)\n",
    "\t\t\tprev_coord = get_obj_pos(self.state_graph.x, start_node)\n",
    "\t\t\tself.move_obj_with_stacked_ones(start_node, coordinates)\n",
    "\t\t\tcost = self.cal_movement(prev_coord, coordinates)\n",
    "\t\t\n",
    "\t\treturn cost\n",
    "\n",
    "\tdef stack_func(self, start_node, target_node):\n",
    "\t\tif not is_stable(self.state_graph.x, start_node, target_node):\n",
    "\t\t\tprint(f'not stable {start_node} -> {target_node}')\n",
    "\t\t\tcost = self.punish_cost\n",
    "\t\telif not is_empty_object(self.state_graph.x, target_node):\n",
    "\t\t\tprint(f'obj {target_node} is not empty')\n",
    "\t\t\tcost = self.punish_cost\n",
    "\t\telse:\n",
    "\t\t\tprev_target = get_object_bellow(self.state_graph.x, start_node)\n",
    "\t\t\tif prev_target == target_node:\n",
    "\t\t\t\tprint(f'already stacked {start_node} -> {target_node}')\n",
    "\t\t\t\tcost = self.punish_cost\n",
    "\t\t\telif prev_target is None:\n",
    "\t\t\t\tprev_coord = get_obj_pos(self.state_graph.x, start_node)\n",
    "\t\t\t\tdestination = get_obj_pos(self.state_graph.x, target_node)\n",
    "\t\t\t\tself.add_edge(start_node, target_node)\n",
    "\t\t\t\tself.move_obj_with_stacked_ones(start_node, destination)\n",
    "\t\t\t\tcost = self.cal_movement(prev_coord, destination)\n",
    "\t\t\telse:\n",
    "\t\t\t\tprev_coord = get_obj_pos(self.state_graph.x, start_node)\n",
    "\t\t\t\tdestination = get_obj_pos(self.state_graph.x, target_node)\n",
    "\t\t\t\tself.remove_edge(start_node, prev_target)\n",
    "\t\t\t\tself.add_edge(start_node, target_node)\n",
    "\t\t\t\tself.move_obj_with_stacked_ones(start_node, destination)\n",
    "\t\t\t\tcost = self.cal_movement(prev_coord, destination)\n",
    "\t\t\n",
    "\t\treturn cost\n",
    "\n",
    "\tdef step_move(self, node, coordinates, log=True):\n",
    "\t\taction = self.encode_action('move', node, node, flatten_pos(coordinates, self.grid_size))\n",
    "\t\treturn self.step(action, log)\n",
    "\n",
    "\tdef step_stack(self, start_node, target_node, log=True):\n",
    "\t\taction = self.encode_action('stack', start_node, target_node, 0)\n",
    "\t\treturn self.step(action, log)\n",
    "\n",
    "\tdef step(self, action, log=False):\n",
    "\t\taction_type, start_node, target_node, coordinates = self.decode_action(action)\n",
    "\t\treturn self._step(action_type, start_node, target_node, coordinates, log=log)\n",
    "\n",
    "\tdef _step(self, action_type, start_node, target_node, coordinates, log=False):\n",
    "\t\tcoordinates = unflatten_pos(coordinates, self.grid_size)\n",
    "\t\tcost, truncated, terminated = 0.0, False, False\n",
    "\n",
    "\t\tif action_type == 'move':\n",
    "\t\t\tif self.static_stack and not is_empty_object(self.state_graph.x, start_node):\n",
    "\t\t\t\tprint(f'can not move non-empty objects')\n",
    "\t\t\t\tcost += self.punish_cost\n",
    "\t\t\telse:\n",
    "\t\t\t\tcost += self.move_func(start_node, coordinates)\n",
    "\t\telif action_type == 'stack':\n",
    "\t\t\tif self.static_stack and not is_empty_object(self.state_graph.x, start_node):\n",
    "\t\t\t\tprint(f'can not stack non-empty objects')\n",
    "\t\t\t\tcost += self.punish_cost\n",
    "\t\t\telse:\n",
    "\t\t\t\tcost += self.stack_func(start_node, target_node)\n",
    "\n",
    "\t\tcost += self.pp_cost\n",
    "\n",
    "\t\tif self.is_terminal_state():\n",
    "\t\t\tif self.terminal_cost:\n",
    "\t\t\t\tcost += self.cal_manipulator_movement(self.manipulator, self.manipulator_initial_pos) * self.normalization_factor\n",
    "\t\t\tself.manipulator = self.manipulator_initial_pos.clone()\n",
    "\t\t\tterminated = True\n",
    "\n",
    "\t\tif log:\n",
    "\t\t\tif action_type == 'move':\n",
    "\t\t\t\tprint(f'Moved {start_node} to: {coordinates.numpy()} | cost: {cost:.3f} | done: {terminated or truncated}')\n",
    "\t\t\telse:\n",
    "\t\t\t\tprint(f'Stacked {start_node} -> {target_node} | cost: {cost:.3f} | done: {terminated or truncated}')\n",
    "\n",
    "\t\tself.make_table()\n",
    "\t\treturn cost, self.get_state()\n",
    "\n",
    "phi = 0.2\n",
    "num_objects = 4\n",
    "grid_size = (100, 100)\n",
    "\n",
    "env = ContinuousEnv(mode='stationary', num_objects=num_objects, grid_size=grid_size, phi=phi, verbose=1, static_stack=True)\n",
    "env.reset(use_stack=False, use_sides=True)\n",
    "initial_scene, target_scene = copy_graph(env.initial_graph), copy_graph(env.target_graph)\n",
    "env.reset(initial_scene, target_scene)\n",
    "env.render(fig_size=3, manipulator=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Algs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def copy_state(state):\n",
    "\treturn {'graph': copy_graph(state['graph']), 'manipulator': state['manipulator'].clone()}\n",
    "\n",
    "def env_cost(env, actions, initial_scene, target_scene, log=True):\n",
    "\tenv.reset(initial_scene, target_scene)\n",
    "\tif actions is None:\n",
    "\t\treturn None\n",
    "\t\n",
    "\tep_cost = 0\n",
    "\tfor action in actions:\n",
    "\t\tep_cost += env.step(action, log=log)[0]\n",
    "\tif log:\n",
    "\t\tprint(f'episode cost: {ep_cost:.3f}')\n",
    "\tenv.reset(initial_scene, target_scene)\n",
    "\treturn ep_cost\n",
    "\n",
    "def evaluate_alg(env, alg, initial_scene, target_scene, num_runs=1, **kwargs):\n",
    "\tplan = None\n",
    "\tsteps, costs, elapsed_time = [], [], []\n",
    "\tbest_cost = np.inf\n",
    "\n",
    "\tprint(f\"--------{alg.__name__}--------\")\n",
    "\tif num_runs > 1:\n",
    "\t\tpbar = tqdm(total=num_runs, desc=f\"Evaluating {alg.__name__}\", unit=\"run\")\n",
    "\t\n",
    "\tfor _ in range(num_runs):\n",
    "\t\tenv.reset(initial_scene, target_scene)\n",
    "\t\tcost = None\n",
    "\t\tplan_i, steps_i, elapsed_time_i = alg(env).solve(**kwargs)\n",
    "\t\tif plan_i:\n",
    "\t\t\tcost = env_cost(env, plan_i, initial_scene, target_scene, log=False)\n",
    "\t\t\tif cost < best_cost:\n",
    "\t\t\t\tplan = plan_i\n",
    "\t\t\tcosts.append(cost)\n",
    "\t\t\tsteps.append(steps_i)\n",
    "\t\t\telapsed_time.append(elapsed_time_i)\n",
    "\n",
    "\t\tif num_runs > 1:\n",
    "\t\t\tpbar.update(1)\n",
    "\t\t\tpbar.set_postfix(cost=cost, steps=steps_i, elapsed_time=elapsed_time_i)\n",
    "\t\n",
    "\tif num_runs > 1:\n",
    "\t\tpbar.close()\n",
    "\t\tprint(f'mean cost: {np.mean(costs):.2f} | mean elapsed_time: {np.mean(elapsed_time):.2f}s | mean steps: {np.mean(steps):.2f}')\n",
    "\telse:\n",
    "\t\tprint(f'plan: {plan}')\n",
    "\t\tif plan is not None:\n",
    "\t\t\tenv_cost(env, plan, initial_scene, target_scene)\n",
    "\n",
    "\tenv.reset(initial_scene, target_scene)\n",
    "\treturn plan\n",
    "\n",
    "def positional_encode(one_hot_position):\n",
    "\tpositions = torch.argmax(one_hot_position, dim=1)\n",
    "\tencodings = torch.zeros((len(positions), 1))\n",
    "\n",
    "\tfor i, position in enumerate(positions):\n",
    "\t\tif torch.sum(one_hot_position[i]) == 0:\n",
    "\t\t\tencodings[i] = -1\n",
    "\t\telse:\n",
    "\t\t\tencodings[i] = position\n",
    "\n",
    "\treturn encodings\n",
    "\n",
    "def state_to_hashable(state):\n",
    "\tnew_state = torch.cat([\n",
    "\t\tstate['graph'].x[:, Indices.LABEL], \n",
    "\t\tstate['graph'].x[:, Indices.SIZE],\n",
    "\t\tstate['graph'].x[:, Indices.COORD], \n",
    "\t\tpositional_encode(state['graph'].x[:, Indices.RELATION])], \n",
    "\t\tdim=1\n",
    "\t)\n",
    "\treturn tuple(state['manipulator'].numpy().tolist() + new_state.view(-1).tolist())\n",
    "\n",
    "def reconstruct_path(node):\n",
    "    path = []\n",
    "    while node.parent is not None:\n",
    "        path.append(node.action)\n",
    "        node = node.parent\n",
    "    path.reverse()\n",
    "    return path\n",
    "\n",
    "def score(env, coor, obj):\n",
    "\tdis_obj = torch.norm(get_obj_pos(env.target_graph.x, obj) - coor).item()\n",
    "\treturn env.occupied_score(coor, obj) + dis_obj * env.normalization_factor\n",
    "\n",
    "def get_empty_positions_with_target(env, ref_node, n=1, sort=False):\n",
    "\tpositions = []\n",
    "\ttarget_pos = get_obj_pos(env.target_graph.x, ref_node)\n",
    "\tif not env.is_coor_occupied(target_pos, ref_node):\n",
    "\t\t# TK is free\n",
    "\t\tpositions.append(flatten_pos(target_pos, env.grid_size))\n",
    "\telse:\n",
    "\t\tif n == 0:\n",
    "\t\t\treturn positions\n",
    "\t\t# Choose random buffer position\n",
    "\t\tfor position in get_empty_positions(env, ref_node=ref_node, n=n+1, sort=sort):\n",
    "\t\t\tif position != flatten_pos(target_pos, env.grid_size):\n",
    "\t\t\t\tpositions.append(position)\n",
    "\t\t\t\tif len(positions) >= n:\n",
    "\t\t\t\t\tbreak\n",
    "\treturn positions\n",
    "\n",
    "class BaseSearch:\n",
    "\tdef __init__(self, env, node_class):\n",
    "\t\t\"\"\"\n",
    "\t\tBase class for search algorithms.\n",
    "\t\t:param env: The environment in which the search is performed.\n",
    "\t\t:param node_class: The class used for representing nodes in the search.\n",
    "\t\t\"\"\"\n",
    "\t\tself.env = env\n",
    "\t\tself.node_class = node_class  # Generalized node class\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------Labbe--------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Labbe: 100%|██████████| 20/20 [00:32<00:00,  1.61s/run, cost=14.5, elapsed_time=1.5, steps=68]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean cost: 15.29 | mean elapsed_time: 1.57s | mean steps: 69.35\n",
      "--------LabbeS--------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating LabbeS: 100%|██████████| 20/20 [00:34<00:00,  1.73s/run, cost=15.6, elapsed_time=1.49, steps=62]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean cost: 15.45 | mean elapsed_time: 1.69s | mean steps: 69.15\n",
      "--------LabbeS--------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating LabbeS: 100%|██████████| 20/20 [00:35<00:00,  1.76s/run, cost=15.4, elapsed_time=1.71, steps=68]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean cost: 15.43 | mean elapsed_time: 1.72s | mean steps: 70.00\n",
      "--------Labbe--------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Labbe: 100%|██████████| 20/20 [00:31<00:00,  1.59s/run, cost=14.5, elapsed_time=1.5, steps=68]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean cost: 14.99 | mean elapsed_time: 1.55s | mean steps: 69.45\n",
      "--------LabbeS--------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating LabbeS: 100%|██████████| 20/20 [00:36<00:00,  1.81s/run, cost=17.4, elapsed_time=1.95, steps=76]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean cost: 15.52 | mean elapsed_time: 1.77s | mean steps: 71.90\n",
      "--------LabbeS--------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating LabbeS: 100%|██████████| 20/20 [00:35<00:00,  1.78s/run, cost=16.3, elapsed_time=1.69, steps=68]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean cost: 14.70 | mean elapsed_time: 1.74s | mean steps: 70.55\n"
     ]
    }
   ],
   "source": [
    "class LabbeNode:\n",
    "\tnode_counter = 0  # Static variable to assign unique IDs to each node\n",
    "\n",
    "\tdef __init__(self, state, remaining_objs, obj=None, parent=None, action=None, c=1, depth=0):\n",
    "\t\tself.state = state\n",
    "\t\tself.obj = obj\n",
    "\t\tself.parent = parent\n",
    "\t\tself.action = action\n",
    "\t\tself.children = {}\n",
    "\t\tself.n = 0\n",
    "\t\tself.w = 0.0\n",
    "\t\tself.c = c\n",
    "\t\tself.terminal_flag = False\n",
    "\t\tself.remaining_objs = remaining_objs\n",
    "\t\tself.depth = depth\n",
    "\t\t\n",
    "\t\t# Assign a unique ID to each node\n",
    "\t\tself.id = LabbeNode.node_counter\n",
    "\t\tLabbeNode.node_counter += 1\n",
    "\n",
    "\tdef get_state(self):\n",
    "\t\treturn copy_state(self.state)\n",
    "\n",
    "\tdef is_fully_expanded(self):\n",
    "\t\treturn len(self.remaining_objs) == 0\n",
    "\n",
    "\tdef ucb(self):\n",
    "\t\texpected_value = self.w / self.n\n",
    "\t\texploration_term = self.c * np.sqrt(2 * np.log(self.parent.n) / self.n)\n",
    "\n",
    "\t\treturn expected_value + exploration_term\n",
    "\n",
    "class Labbe(BaseSearch):\n",
    "\t\"\"\"\n",
    "\tChildren are states and actions are the objects to move.\n",
    "\tGiving birth to a child means manipulating an object which is non-stationary\n",
    "\tbacause of the random sampling of buffers durring the birth. \n",
    "\tIf choosing an object leads to non-expandable node, we assign different buffer to the object.\n",
    "\tIf after max_rebuffering times still it leads to non-expandable node, we give up on that object\n",
    "\tand remove that object and try rebuffering on its parent if all of its brothers are non-expandable too.\n",
    "\t\"\"\"\n",
    "\tdef __init__(self, env):\n",
    "\t\tsuper().__init__(env, LabbeNode)\n",
    "\n",
    "\tdef get_remaining_objs(self, state):\n",
    "\t\tstate_graph = state['graph']\n",
    "\n",
    "\t\tremaining_objs = []\n",
    "\t\tfor k in range(state_graph.num_nodes):\n",
    "\t\t\tif not torch.equal(get_obj_pos(state_graph.x, k), get_obj_pos(self.env.target_graph.x, k)):\n",
    "\t\t\t\tremaining_objs.append(k)\n",
    "\n",
    "\t\t# shuffle remaining nodes\n",
    "\t\tnp.random.shuffle(remaining_objs)\n",
    "\t\t\n",
    "\t\treturn remaining_objs\n",
    "\n",
    "\tdef get_action_move_obj_away(self, k):\n",
    "\t\tTK = get_obj_pos(self.env.target_graph.x, k)\n",
    "\t\tif not self.env.is_coor_occupied(TK, k):\n",
    "\t\t\tposition = flatten_pos(TK, self.env.grid_size)\n",
    "\t\t\treturn self.env.encode_action('move', k, k, position)\n",
    "\t\tfree_positions = get_empty_positions(self.env, ref_node=k, n=1)\n",
    "\t\tif len(free_positions) > 0:\n",
    "\t\t\t# move the node to a random position\n",
    "\t\t\treturn self.env.encode_action('move', k, k, free_positions[0])\n",
    "\t\treturn None\n",
    "\n",
    "\tdef get_motion(self, k):\n",
    "\t\tCK = get_obj_pos(self.env.state_graph.x, k)\n",
    "\t\tTK = get_obj_pos(self.env.target_graph.x, k)\n",
    "\t\tif torch.equal(TK, CK):\n",
    "\t\t\traise ValueError(f'The node {k} is already in its target position')\n",
    "\t\telif not self.env.is_coor_occupied(TK, k):\n",
    "\t\t\t# TK is free\n",
    "\t\t\tposition = flatten_pos(TK, self.env.grid_size)\n",
    "\t\t\treturn self.env.encode_action('move', k, k, position)\n",
    "\t\telse:\n",
    "\t\t\t# find which node is occupying TK\n",
    "\t\t\tsize_k = get_obj_size(self.env.state_graph.x, k)\n",
    "\t\t\toccupying_nodes = find_occupying_objs(self.env.table, TK, size_k)\n",
    "\t\t\tif len(occupying_nodes) == 0:\n",
    "\t\t\t\traise ValueError('No node is occupying the target position')\n",
    "\t\t\tfor j in occupying_nodes:\n",
    "\t\t\t\tif j != k:\n",
    "\t\t\t\t\taction_away = self.get_action_move_obj_away(j)\n",
    "\t\t\t\t\tif action_away is not None:\n",
    "\t\t\t\t\t\treturn action_away\n",
    "\t\t\treturn None\n",
    "\n",
    "\tdef evaluate_state(self, state):\n",
    "\t\tstate_graph = state['graph']\n",
    "\t\treward = 0\n",
    "\t\t\n",
    "\t\tfor k in range(state_graph.num_nodes):\n",
    "\t\t\tif torch.equal(get_obj_pos(state_graph.x, k), get_obj_pos(self.env.target_graph.x, k)):\n",
    "\t\t\t\treward += 1\n",
    "\n",
    "\t\treturn reward / state_graph.num_nodes\n",
    "\n",
    "\tdef select(self, node):\n",
    "\t\t# Accesses child nodes for best selection\n",
    "\t\treturn max(node.children.values(), key=lambda child: child.ucb())\n",
    "\n",
    "\tdef expand(self, node):\n",
    "\t\tif node.is_fully_expanded():\n",
    "\t\t\treturn None  # Prevents further expansion if no actions remain\n",
    "\n",
    "\t\tself.env.set_state(node.get_state())\n",
    "\t\taction = self.get_motion(node.remaining_objs.pop())\n",
    "\t\tif action is None:\n",
    "\t\t\treturn self.expand(node)\n",
    "\t\t\n",
    "\t\t# Continue expanding if this action has already been taken\n",
    "\t\t# if action in node.children:\n",
    "\t\t# \treturn self.expand(node)\n",
    "\t\t\n",
    "\t\taction_type, start_obj, target_obj, coordinates = self.env.decode_action(action)\n",
    "\t\t\n",
    "\t\t# Continue expanding if the last changed obj is the same as the current obj\n",
    "\t\tif node.obj == start_obj:\n",
    "\t\t\treturn self.expand(node)\n",
    "\t\t\n",
    "\t\t_, child_state = self.env._step(action_type, start_obj, target_obj, coordinates)\n",
    "\n",
    "\t\tif torch.equal(child_state['graph'].x, node.state['graph'].x):\n",
    "\t\t\traise ValueError('State has not changed')\n",
    "\n",
    "\t\tchild_node = self.node_class(\n",
    "\t\t\tstate=child_state, \n",
    "\t\t\tremaining_objs=self.get_remaining_objs(self.env.get_state()), \n",
    "\t\t\tobj=start_obj, \n",
    "\t\t\tparent=node, \n",
    "\t\t\taction=action, \n",
    "\t\t\tc=node.c,\n",
    "\t\t\tdepth=node.depth+1\n",
    "\t\t)\n",
    "\t\tnode.children[action] = child_node\n",
    "\n",
    "\t\treturn child_node\n",
    "\n",
    "\tdef backup_search(self, node, value, terminal_flag):\n",
    "\t\twhile node is not None:\n",
    "\t\t\tnode.n += 1\n",
    "\t\t\tnode.w += value\n",
    "\t\t\tnode.terminal_flag = terminal_flag or node.terminal_flag\n",
    "\t\t\tnode = node.parent\n",
    "\n",
    "\tdef print_tree(self, node, depth=0, ter=False):\n",
    "\t\t# Print the current node with indentation to show its depth in the tree\n",
    "\t\tindent = \"    \" * depth  # Four spaces per level of depth\n",
    "\t\tif node.id == 0:\n",
    "\t\t\tprint(f\"Root | Visits: {node.n} | Value: {node.w:.2f} | Terminal: {node.terminal_flag}\")\n",
    "\t\telse:\n",
    "\t\t\tprint(f\"{indent}ID: {node.id} | Action: {node.action} | \"\n",
    "\t\t\t\t\tf\"Visits: {node.n} | Value: {node.w:.2f} | Terminal: {node.terminal_flag}\")\n",
    "\n",
    "\t\t# Sort children by value estimate\n",
    "\t\tif ter:\n",
    "\t\t\taccepted_children = [child for child in node.children.values() if child.terminal_flag]\n",
    "\t\t\tchildren = sorted(accepted_children, key=lambda child: child.w / child.n if child.n > 0 else float('inf'))\n",
    "\t\telse:\n",
    "\t\t\tchildren = sorted(node.children.values(), key=lambda child: child.w / child.n if child.n > 0 else float('inf'))\n",
    "\n",
    "\t\t# Recurse on children\n",
    "\t\tfor child in children:\n",
    "\t\t\tself.print_tree(child, depth + 1, ter)\n",
    "\n",
    "\tdef find_plan(self):\n",
    "\t\tplan = []\n",
    "\t\tcurrent_node = self.root_node\n",
    "\n",
    "\t\twhile current_node.children:\n",
    "\t\t\tfor child in current_node.children.values():\n",
    "\t\t\t\tif child.terminal_flag:\n",
    "\t\t\t\t\tbreak\n",
    "\n",
    "\t\t\tplan.append(child.action)\n",
    "\t\t\tcurrent_node = child\n",
    "\n",
    "\t\treturn plan\n",
    "\n",
    "\tdef loop(self):\n",
    "\t\tnode = self.root_node\n",
    "\n",
    "\t\t# Selection\n",
    "\t\tself.env.set_state(node.get_state())\n",
    "\t\twhile node.is_fully_expanded() and not self.env.is_terminal_state():\n",
    "\t\t\tnode = self.select(node)\n",
    "\t\t\tself.env.set_state(node.get_state())\n",
    "\n",
    "\t\t# Expansion\n",
    "\t\tchild_node = None\n",
    "\t\tif not self.env.is_terminal_state():\n",
    "\t\t\tchild_node = self.expand(node)\n",
    "\t\t\tif child_node is not None:\n",
    "\t\t\t\tnode = child_node\n",
    "\t\t\telse:\n",
    "\t\t\t\t# It means it fully expanded\n",
    "\t\t\t\twhile len(node.children) == 0 and node.parent:\n",
    "\t\t\t\t\tnode.parent.children.pop(node.action)\n",
    "\t\t\t\t\tnode = node.parent\n",
    "\n",
    "\t\t# Simulation (Rollout)\n",
    "\t\tself.env.set_state(node.get_state())\n",
    "\t\tterminal_flag = self.env.is_terminal_state()\n",
    "\t\tif child_node is None:\n",
    "\t\t\tvalue = 0\n",
    "\t\telse:\n",
    "\t\t\tvalue = self.evaluate_state(node.get_state())\n",
    "\t\t\n",
    "\t\t# Backpropagation\n",
    "\t\tself.backup_search(node, value, terminal_flag)\n",
    "\n",
    "\tdef solve(self, c=0.5, verbose=0, time_limit=None):\n",
    "\t\tif torch.sum(self.env.state_graph.x[:, Indices.RELATION]) > 0:\n",
    "\t\t\traise ValueError('Initial graph has edges in Non-stack mode')\n",
    "\t\tif torch.sum(self.env.target_graph.x[:, Indices.RELATION]) > 0:\n",
    "\t\t\traise ValueError('Target graph has edges in Non-stack mode')\n",
    "\t\treturn self._solve(c, verbose, time_limit)\n",
    "\n",
    "\tdef _solve(self, c=0.5, verbose=0, time_limit=None):\n",
    "\t\tstart_time = time.time()\n",
    "\t\tLabbeNode.node_counter = 0\n",
    "\t\tself.root_node = self.node_class(\n",
    "\t\t\tstate=self.env.get_state(), \n",
    "\t\t\tremaining_objs=self.get_remaining_objs(self.env.get_state()), \n",
    "\t\t\tc=c\n",
    "\t\t)\n",
    "\t\t\n",
    "\t\tsteps = 0\n",
    "\t\tif verbose > 0:\n",
    "\t\t\tpbar = tqdm(total=None, unit='iterations')\n",
    "\n",
    "\t\twhile self.root_node.terminal_flag is False:\n",
    "\t\t\t# Check if the elapsed time has exceeded the limit\n",
    "\t\t\tif time_limit is not None and  time.time()-start_time > time_limit:\n",
    "\t\t\t\tif verbose > 0:\n",
    "\t\t\t\t\tpbar.close()\n",
    "\t\t\t\treturn None, steps, time.time()-start_time\n",
    "\t\t\n",
    "\t\t\tsteps += 1\n",
    "\t\t\tself.loop()\n",
    "\t\t\tif verbose > 0:\n",
    "\t\t\t\tpbar.update(1)\n",
    "\n",
    "\t\tif verbose > 0:\n",
    "\t\t\tpbar.close()\n",
    "\n",
    "\t\treturn self.find_plan(), steps, time.time()-start_time\n",
    "\n",
    "class LabbeS(Labbe):\n",
    "\tdef get_remaining_objs(self, state):\n",
    "\t\tstate_graph = state['graph']\n",
    "\n",
    "\t\tremaining_objs = []\n",
    "\t\tfor k in range(state_graph.num_nodes):\n",
    "\t\t\ti = get_object_bellow(self.env.target_graph.x, k)\n",
    "\t\t\tif i is not None:\n",
    "\t\t\t\tif not is_stacked_on_object(state_graph.x, k, i):\n",
    "\t\t\t\t\tremaining_objs.append(k)\n",
    "\t\t\telif get_object_bellow(state_graph.x, k) is not None:\n",
    "\t\t\t\tremaining_objs.append(k)\n",
    "\t\t\telse:\n",
    "\t\t\t\tif not torch.equal(get_obj_pos(state_graph.x, k), get_obj_pos(self.env.target_graph.x, k)):\n",
    "\t\t\t\t\tremaining_objs.append(k)\n",
    "\n",
    "\t\t# shuffle remaining nodes\n",
    "\t\tnp.random.shuffle(remaining_objs)\n",
    "\n",
    "\t\treturn remaining_objs\n",
    "\n",
    "\tdef get_action_move_obj_away(self, k):\n",
    "\t\tif self.static_stack:\n",
    "\t\t\tj = get_object_above(self.env.state_graph.x, k)\n",
    "\t\t\tif j is not None:\n",
    "\t\t\t\treturn None\n",
    "\n",
    "\t\ti = get_object_bellow(self.env.target_graph.x, k)\n",
    "\t\tif i is not None:\n",
    "\t\t\tif is_empty_object(env.state_graph.x, i):\n",
    "\t\t\t\treturn self.env.encode_action('stack', k, i, 0)\n",
    "\t\telse:\n",
    "\t\t\tTK = get_obj_pos(self.env.target_graph.x, k)\n",
    "\t\t\tif not self.env.is_coor_occupied(TK, k):\n",
    "\t\t\t\tposition = flatten_pos(TK, self.env.grid_size)\n",
    "\t\t\t\treturn self.env.encode_action('move', k, k, position)\n",
    "\t\t\n",
    "\t\tfree_positions = get_empty_positions(self.env, ref_node=k, n=1)\n",
    "\t\tfree_objects = get_empty_objs(self.env, ref_node=k, n=1)\n",
    "\t\tif len(free_objects) > 0 and len(free_positions) > 0:\n",
    "\t\t\tif np.random.rand() < 0.5:\n",
    "\t\t\t\t# move the node to a random position\n",
    "\t\t\t\treturn self.env.encode_action('move', k, k, free_positions[0])\n",
    "\t\t\telse:\n",
    "\t\t\t\t# stack on a random node\n",
    "\t\t\t\treturn self.env.encode_action('stack', k, free_objects[0], 0)\n",
    "\t\telif len(free_objects) == 0 and len(free_positions) > 0:\n",
    "\t\t\t# move the node to a random position\n",
    "\t\t\treturn self.env.encode_action('move', k, k, free_positions[0])\n",
    "\t\telif len(free_positions) == 0 and len(free_objects) > 0:\n",
    "\t\t\t# stack on a random node\n",
    "\t\t\treturn self.env.encode_action('stack', k, free_objects[0], 0)\n",
    "\t\treturn None\n",
    "\t\n",
    "\tdef get_motion(self, k):\n",
    "\t\tif self.static_stack:\n",
    "\t\t\tj = get_object_above(self.env.state_graph.x, k)\n",
    "\t\t\tif j is not None:\n",
    "\t\t\t\treturn self.get_action_move_obj_away(j)\n",
    "\n",
    "\t\ti = get_object_bellow(self.env.target_graph.x, k)\n",
    "\t\tif i is not None:\n",
    "\t\t\tj = get_object_above(self.env.state_graph.x, i)\n",
    "\t\t\tif j is not None:\n",
    "\t\t\t\treturn self.get_action_move_obj_away(j)\n",
    "\t\t\telse:\n",
    "\t\t\t\treturn self.env.encode_action('stack', k, i, 0)\n",
    "\t\telse:\n",
    "\t\t\tCK = get_obj_pos(self.env.state_graph.x, k)\n",
    "\t\t\tTK = get_obj_pos(self.env.target_graph.x, k)\n",
    "\t\t\tif torch.equal(TK, CK):\n",
    "\t\t\t\tj = get_object_bellow(self.env.state_graph.x, k)\n",
    "\t\t\t\tif j is not None:\n",
    "\t\t\t\t\tj = get_object_base(self.env.state_graph.x, j)\n",
    "\t\t\t\t\treturn self.get_action_move_obj_away(j)\n",
    "\t\t\telse:\n",
    "\t\t\t\tif not self.env.is_coor_occupied(TK, k):\n",
    "\t\t\t\t\t# TK is free\n",
    "\t\t\t\t\tposition = flatten_pos(TK, self.env.grid_size)\n",
    "\t\t\t\t\treturn self.env.encode_action('move', k, k, position)\n",
    "\t\t\t\telse:\n",
    "\t\t\t\t\t# find which nodes are occupying TK\n",
    "\t\t\t\t\tsize_k = get_obj_size(self.env.state_graph.x, k)\n",
    "\t\t\t\t\toccupying_nodes = find_occupying_objs(self.env.table, TK, size_k)\n",
    "\t\t\t\t\tif len(occupying_nodes) == 0:\n",
    "\t\t\t\t\t\traise ValueError('No node is occupying the target position')\n",
    "\t\t\t\t\tfor j in occupying_nodes:\n",
    "\t\t\t\t\t\tif j != k:\n",
    "\t\t\t\t\t\t\taction_away = self.get_action_move_obj_away(j)\n",
    "\t\t\t\t\t\t\tif action_away is not None:\n",
    "\t\t\t\t\t\t\t\treturn action_away\n",
    "\t\treturn None\n",
    "\n",
    "\tdef evaluate_state(self, state):\n",
    "\t\tstate_graph = state['graph']\n",
    "\t\treward = 0\n",
    "\n",
    "\t\tfor k in range(state_graph.num_nodes):\n",
    "\t\t\ti = get_object_bellow(self.env.target_graph.x, k)\n",
    "\t\t\tif i is not None:\n",
    "\t\t\t\tif is_stacked_on_object(state_graph.x, k, i):\n",
    "\t\t\t\t\treward += 1\n",
    "\t\t\telif get_object_bellow(state_graph.x, k) is None:\n",
    "\t\t\t\tif torch.equal(get_obj_pos(state_graph.x, k), get_obj_pos(self.env.target_graph.x, k)):\n",
    "\t\t\t\t\treward += 1\n",
    "\n",
    "\t\treturn reward / state_graph.num_nodes\n",
    "\n",
    "\tdef solve(self, c=0.5, static_stack=False, verbose=0, time_limit=None):\n",
    "\t\tself.static_stack = static_stack\n",
    "\t\treturn self._solve(c, verbose, time_limit)\n",
    "\n",
    "num_runs = 20\n",
    "env.terminal_cost = True\n",
    "evaluate_alg(env, Labbe, initial_scene, target_scene, num_runs=num_runs, c=0, time_limit=20);\n",
    "env.static_stack = True\n",
    "evaluate_alg(env, LabbeS, initial_scene, target_scene, num_runs=num_runs, c=0, time_limit=20, static_stack=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------StrapGA--------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time limit exceeded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating StrapGA: 100%|██████████| 3/3 [02:35<00:00, 51.98s/run, cost=5.88, elapsed_time=46.3, steps=6109]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean cost: 5.88 | mean elapsed_time: 51.95s | mean steps: 6868.67\n",
      "--------A_starGA--------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time limit exceeded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time limit exceeded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating A_starGA: 100%|██████████| 3/3 [03:00<00:00, 60.12s/run, cost=5.88, elapsed_time=60.1, steps=5609]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time limit exceeded\n",
      "mean cost: 5.88 | mean elapsed_time: 60.08s | mean steps: 6450.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "class SearchNode:\n",
    "\tdef __init__(self, state, parent=None, action=None, cost_to_come=0, heuristic=0, depth=0):\n",
    "\t\tself.state = state\n",
    "\t\tself.parent = parent\n",
    "\t\tself.action = action\n",
    "\t\tself.c_cost = cost_to_come\t  \t# cost-to-come\n",
    "\t\tself.h_cost = heuristic\t\t\t# cost-to-go\n",
    "\t\tself.total_cost = self.c_cost + self.h_cost\n",
    "\t\tself.depth = depth\n",
    "\n",
    "\tdef __lt__(self, other):\n",
    "\t\treturn self.total_cost < other.total_cost  # Lower cost first\n",
    "\n",
    "\tdef get_state(self):\n",
    "\t\treturn copy_state(self.state)\n",
    "\n",
    "class A_star(BaseSearch):\n",
    "\tdef __init__(self, env):\n",
    "\t\tsuper().__init__(env, SearchNode)\n",
    "\n",
    "\tdef get_remaining_objects(self, state):\n",
    "\t\tstate_graph = state['graph']\n",
    "\n",
    "\t\tremaining_objs = []\n",
    "\t\tfor k in range(state_graph.num_nodes):\n",
    "\t\t\ti = get_object_bellow(self.env.target_graph.x, k)\n",
    "\t\t\tif i is not None:\n",
    "\t\t\t\tif not is_stacked_on_object(state_graph.x, k, i):\n",
    "\t\t\t\t\tremaining_objs.append(k)\n",
    "\t\t\telif get_object_bellow(state_graph.x, k) is not None:\n",
    "\t\t\t\tremaining_objs.append(k)\n",
    "\t\t\telse:\n",
    "\t\t\t\tif not torch.equal(get_obj_pos(state_graph.x, k), get_obj_pos(self.env.target_graph.x, k)):\n",
    "\t\t\t\t\tremaining_objs.append(k)\n",
    "\n",
    "\t\t# shuffle remaining objs\n",
    "\t\tnp.random.shuffle(remaining_objs)\n",
    "\n",
    "\t\treturn remaining_objs\n",
    "\n",
    "\tdef get_valid_actions(self, state):\n",
    "\t\tself.env.set_state(state)\n",
    "\n",
    "\t\tstack_nums = max(int(0.6 * self.num_buffers), 1)\n",
    "\n",
    "\t\tobjects = list(range(self.env.num_objects))\n",
    "\t\tnp.random.shuffle(objects)\n",
    "\n",
    "\t\tvalid_actions = []\n",
    "\t\tfor k in self.get_remaining_objects(state):\n",
    "\t\t\tif self.static_stack and get_object_above(self.env.state_graph.x, k) is not None:\n",
    "\t\t\t\tcontinue\n",
    "\t\t\t\n",
    "\t\t\tvalid_stacks = []\n",
    "\t\t\tfor obj in objects:\n",
    "\t\t\t\tif k != obj and not is_stacked_on_object(self.env.state_graph.x, k, obj):\n",
    "\t\t\t\t\tif is_stable(self.env.state_graph.x, k, obj):\n",
    "\t\t\t\t\t\tif is_empty_object(self.env.state_graph.x, obj):\n",
    "\t\t\t\t\t\t\tvalid_stacks.append(self.env.encode_action('stack', k, obj, 0))\n",
    "\t\t\t\t\t\t\tif len(valid_stacks) >= stack_nums:\n",
    "\t\t\t\t\t\t\t\tbreak\n",
    "\n",
    "\t\t\tvalid_moves = []\n",
    "\t\t\tfor position in get_empty_positions_with_target(self.env, ref_node=k, n=self.num_buffers-len(valid_stacks)):\n",
    "\t\t\t\tvalid_moves.append(self.env.encode_action('move', k, k, position))\n",
    "\n",
    "\t\t\tvalid_actions += valid_stacks + valid_moves\n",
    "\n",
    "\t\treturn valid_actions\n",
    "\n",
    "\tdef evaluate_state(self, state):\n",
    "\t\tstate_graph = state['graph']\n",
    "\t\theuristic = 0\n",
    "\t\t# init_pos_dis = []\n",
    "\n",
    "\t\tfor k in self.get_remaining_objects(state):\n",
    "\t\t\tCK = get_obj_pos(state_graph.x, k)\n",
    "\t\t\tTK = get_obj_pos(self.env.target_graph.x, k)\n",
    "\t\t\tmin_dis = torch.norm(CK - TK)\n",
    "\t\t\t# init_pos_dis.append(torch.norm(TK - self.env.manipulator_initial_pos.clone()).item())\n",
    "\n",
    "\t\t\ti = get_object_bellow(self.env.target_graph.x, k)\n",
    "\t\t\tif i is not None:\n",
    "\t\t\t\tif not is_stacked_on_object(state_graph.x, k, i):\n",
    "\t\t\t\t\tCI = get_obj_pos(state_graph.x, i)\n",
    "\t\t\t\t\tnew_dis = torch.norm(CK - CI)\n",
    "\t\t\t\t\tif new_dis < min_dis:\n",
    "\t\t\t\t\t\tmin_dis = new_dis\n",
    "\t\t\t\t\t\t# if get_object_above(state_graph, i) is not None:\n",
    "\t\t\t\t\t\t# \theuristic += self.env.pp_cost\n",
    "\t\t\t\t\theuristic += self.env.pp_cost\n",
    "\t\t\telse:\n",
    "\t\t\t\tif min_dis == 0:\n",
    "\t\t\t\t\tif get_object_bellow(state_graph.x, k) is not None:\n",
    "\t\t\t\t\t\theuristic += self.env.pp_cost\n",
    "\t\t\t\tif min_dis != 0:\n",
    "\t\t\t\t\tstack = False\n",
    "\t\t\t\t\tfor j in range(state_graph.num_nodes):\n",
    "\t\t\t\t\t\tif k != j and is_stable(state_graph.x, k, j):\n",
    "\t\t\t\t\t\t\tCJ = get_obj_pos(state_graph.x, j)\n",
    "\t\t\t\t\t\t\tTJ = get_obj_pos(self.env.target_graph.x, j)\n",
    "\t\t\t\t\t\t\tnew_dis = torch.norm(CK - CJ) + torch.norm(TK - TJ)\n",
    "\t\t\t\t\t\t\tif new_dis < min_dis:\n",
    "\t\t\t\t\t\t\t\tmin_dis = new_dis\n",
    "\t\t\t\t\t\t\t\tstack = True\n",
    "\t\t\t\t\tif stack:\n",
    "\t\t\t\t\t\theuristic += self.env.pp_cost\n",
    "\t\t\t\t\theuristic += self.env.pp_cost\n",
    "\t\t\t\n",
    "\t\t\theuristic += min_dis * self.env.normalization_factor\n",
    "\t\t\n",
    "\t\t# heuristic += min(init_pos_dis) * self.env.normalization_factor\n",
    "\t\treturn heuristic\n",
    "\n",
    "\tdef solve(self, max_depth=100, num_buffers=3, score_sorting=False, time_limit=None, static_stack=False):\n",
    "\t\tself.score_sorting = score_sorting\n",
    "\t\tself.num_buffers = num_buffers\n",
    "\t\tself.static_stack = static_stack\n",
    "\t\treturn self._solve(max_depth, time_limit)\n",
    "\n",
    "\tdef _solve(self, max_depth=100, time_limit=None):\n",
    "\t\tstart_time = time.time()\n",
    "\n",
    "\t\tsteps = 0\n",
    "\t\troot_node = self.node_class(\n",
    "\t\t\tstate=self.env.get_state(), \n",
    "\t\t\tcost_to_come=0, \n",
    "\t\t\theuristic=self.evaluate_state(self.env.get_state())\n",
    "\t\t)\n",
    "\n",
    "\t\tqueue = []\n",
    "\t\theapq.heappush(queue, root_node)\n",
    "\t\tvisited = {}\n",
    "\n",
    "\t\twhile queue:\n",
    "\t\t\tcurrent_node = heapq.heappop(queue)\n",
    "\n",
    "\t\t\t# Check if the current node's state matches the target state\n",
    "\t\t\tself.env.set_state(current_node.get_state())\n",
    "\t\t\tif self.env.is_terminal_state():\n",
    "\t\t\t\treturn reconstruct_path(current_node), steps, time.time()-start_time\n",
    "\n",
    "\t\t\tif current_node.depth >= max_depth:\n",
    "\t\t\t\tcontinue\n",
    "\n",
    "\t\t\tif time_limit is not None and time.time() - start_time > time_limit:\n",
    "\t\t\t\tprint('Time limit exceeded')\n",
    "\t\t\t\treturn None, steps, time.time()-start_time\n",
    "\n",
    "\t\t\tlast_obj = self.env.decode_action(current_node.action)[1] if current_node.action is not None else None\n",
    "\t\t\tfor action in self.get_valid_actions(current_node.get_state()):\n",
    "\t\t\t\taction_type, start_obj, target_obj, coordinates = self.env.decode_action(action)\n",
    "\n",
    "\t\t\t\tif start_obj == last_obj:\n",
    "\t\t\t\t\t# If the last changed node is the same as the current node, continue\n",
    "\t\t\t\t\tcontinue\n",
    "\n",
    "\t\t\t\tsteps += 1\n",
    "\t\t\t\tself.env.set_state(current_node.get_state())\n",
    "\t\t\t\tcost, child_state = self.env._step(action_type, start_obj, target_obj, coordinates)\n",
    "\n",
    "\t\t\t\tif torch.equal(child_state['graph'].x, current_node.get_state()['graph'].x):\n",
    "\t\t\t\t\t# if state hasn't changed, continue\n",
    "\t\t\t\t\traise ValueError('State has not changed')\n",
    "\n",
    "\t\t\t\tchild_hash = state_to_hashable(child_state)\n",
    "\n",
    "\t\t\t\t# Calculate the accumulated cost for the current path\n",
    "\t\t\t\tnew_c_cost = current_node.c_cost + cost\n",
    "\t\t\t\th_cost = self.evaluate_state(child_state)\n",
    "\t\t\t\tnew_total_cost = new_c_cost + h_cost\n",
    "\n",
    "\t\t\t\t# Retain the node with better cost\n",
    "\t\t\t\tif child_hash not in visited or visited[child_hash] > new_total_cost:\n",
    "\t\t\t\t\tvisited[child_hash] = new_total_cost\n",
    "\t\t\t\t\tchild_node = self.node_class(\n",
    "\t\t\t\t\t\tstate=child_state, \n",
    "\t\t\t\t\t\tparent=current_node, \n",
    "\t\t\t\t\t\taction=action, \n",
    "\t\t\t\t\t\tcost_to_come=new_c_cost, \n",
    "\t\t\t\t\t\theuristic=h_cost,\n",
    "\t\t\t\t\t\tdepth=current_node.depth+1\n",
    "\t\t\t\t\t)\n",
    "\n",
    "\t\t\t\t\theapq.heappush(queue, child_node)\n",
    "\n",
    "\t\treturn None, steps, time.time()-start_time\n",
    "\n",
    "class A_starGA(A_star):\n",
    "\tdef _solve(self, max_depth=100, time_limit=None):\n",
    "\t\tstart_time = time.time()\n",
    "\t\tbest_plan = None\n",
    "\t\tbest_cost = float('inf')\n",
    "\n",
    "\t\tsteps = 0\n",
    "\t\troot_node = self.node_class(\n",
    "\t\t\tstate=self.env.get_state(), \n",
    "\t\t\tcost_to_come=0, \n",
    "\t\t\theuristic=self.evaluate_state(self.env.get_state())\n",
    "\t\t)\n",
    "\n",
    "\t\tqueue = []\n",
    "\t\theapq.heappush(queue, root_node)\n",
    "\t\tvisited = {}\n",
    "\n",
    "\t\twhile queue:\n",
    "\t\t\tcurrent_node = heapq.heappop(queue)\n",
    "\n",
    "\t\t\t# Check if the current node's state matches the target state\n",
    "\t\t\tself.env.set_state(current_node.get_state())\n",
    "\t\t\tif self.env.is_terminal_state():\n",
    "\t\t\t\tif best_plan is not None and current_node.total_cost < best_cost:\n",
    "\t\t\t\t\treturn reconstruct_path(current_node), steps, time.time()-start_time\n",
    "\t\t\t\telse:\n",
    "\t\t\t\t\treturn best_plan, steps, time.time()-start_time\n",
    "\n",
    "\t\t\tif current_node.depth >= max_depth:\n",
    "\t\t\t\tcontinue\n",
    "\n",
    "\t\t\tif time_limit is not None and time.time() - start_time > time_limit:\n",
    "\t\t\t\tprint('Time limit exceeded')\n",
    "\t\t\t\treturn best_plan, steps, time.time()-start_time\n",
    "\n",
    "\t\t\tlast_obj = self.env.decode_action(current_node.action)[1] if current_node.action is not None else None\n",
    "\t\t\tfor action in self.get_valid_actions(current_node.get_state()):\n",
    "\t\t\t\taction_type, start_obj, target_obj, coordinates = self.env.decode_action(action)\n",
    "\n",
    "\t\t\t\t# If the last changed node is the same as the current node, continue\n",
    "\t\t\t\tif start_obj == last_obj:\n",
    "\t\t\t\t\tcontinue\n",
    "\n",
    "\t\t\t\tsteps += 1\n",
    "\t\t\t\tself.env.set_state(current_node.get_state())\n",
    "\t\t\t\tcost, child_state = self.env._step(action_type, start_obj, target_obj, coordinates)\n",
    "\n",
    "\t\t\t\t# If state hasn't changed, continue\n",
    "\t\t\t\tif torch.equal(child_state['graph'].x, current_node.get_state()['graph'].x):\n",
    "\t\t\t\t\traise ValueError('State has not changed')\n",
    "\n",
    "\t\t\t\tchild_hash = state_to_hashable(child_state)\n",
    "\n",
    "\t\t\t\t# Calculate the accumulated cost for the current path\n",
    "\t\t\t\tnew_c_cost = current_node.c_cost + cost\n",
    "\t\t\t\th_cost = self.evaluate_state(child_state)\n",
    "\t\t\t\tnew_total_cost = new_c_cost + h_cost\n",
    "\n",
    "\t\t\t\t# Retain the node with better cost\n",
    "\t\t\t\tif child_hash not in visited or visited[child_hash] > new_total_cost:\n",
    "\t\t\t\t\tvisited[child_hash] = new_total_cost\n",
    "\t\t\t\t\tchild_node = self.node_class(\n",
    "\t\t\t\t\t\tstate=child_state, \n",
    "\t\t\t\t\t\tparent=current_node, \n",
    "\t\t\t\t\t\taction=action, \n",
    "\t\t\t\t\t\tcost_to_come=new_c_cost, \n",
    "\t\t\t\t\t\theuristic=h_cost,\n",
    "\t\t\t\t\t\tdepth=current_node.depth+1\n",
    "\t\t\t\t\t)\n",
    "\n",
    "\t\t\t\t\theapq.heappush(queue, child_node)\n",
    "\n",
    "\t\t\tif time_limit is not None and time.time() - start_time > time_limit:\n",
    "\t\t\t\tprint('Time limit exceeded')\n",
    "\t\t\t\treturn best_plan, steps, time.time()-start_time\n",
    "\n",
    "\t\t\t# Goal Attempting\n",
    "\t\t\tself.env.set_state(current_node.get_state())\n",
    "\t\t\tsim_time_limit = (time_limit - time.time() + start_time) / 4\n",
    "\t\t\tpath_to_go, labbe_steps, _ = LabbeS(self.env).solve(time_limit=sim_time_limit, static_stack=self.static_stack, c=0)\n",
    "\t\t\tsteps += labbe_steps\n",
    "\t\t\tself.env.set_state(current_node.get_state())\n",
    "\t\t\t\n",
    "\t\t\tif path_to_go is None:\n",
    "\t\t\t\tcontinue\n",
    "\t\t\t\n",
    "\t\t\tfeasible_path_cost = current_node.c_cost\n",
    "\t\t\tfor i, action in enumerate(path_to_go):\n",
    "\t\t\t\tcost, child_state = self.env.step(action)\n",
    "\t\t\t\tfeasible_path_cost += cost\n",
    "\t\t\t\tif i == 0:\n",
    "\t\t\t\t\tfirst_child = child_state\n",
    "\t\t\t\t\tfist_action = action\n",
    "\t\t\t\t\tfirst_cost = feasible_path_cost\n",
    "\n",
    "\t\t\tif feasible_path_cost < best_cost:\n",
    "\t\t\t\tbest_plan = reconstruct_path(current_node) + path_to_go\n",
    "\t\t\t\tbest_cost = feasible_path_cost\n",
    "\t\t\t\tchild_node = self.node_class(\n",
    "\t\t\t\t\tstate=first_child,\n",
    "\t\t\t\t\tparent=current_node,\n",
    "\t\t\t\t\taction=fist_action,\n",
    "\t\t\t\t\tcost_to_come=first_cost,\n",
    "\t\t\t\t\theuristic=self.evaluate_state(first_child),\n",
    "\t\t\t\t\tdepth=current_node.depth+1\n",
    "\t\t\t\t)\n",
    "\t\t\t\theapq.heappush(queue, child_node)\n",
    "\n",
    "\t\t\t# Remove all the nodes with their total cost is greater than the feasible path cost\n",
    "\t\t\tfor node in queue:\n",
    "\t\t\t\tif node.total_cost > feasible_path_cost:\n",
    "\t\t\t\t\tqueue.remove(node)\n",
    "\n",
    "\t\treturn best_plan, steps, time.time()-start_time\n",
    "\n",
    "class Strap(A_star):\n",
    "\tdef get_remaining_objects(self, state):\n",
    "\t\tstate_graph = state['graph']\n",
    "\n",
    "\t\tremaining_objs = []\n",
    "\t\tfor k in range(state_graph.num_nodes):\n",
    "\t\t\tif not torch.equal(get_obj_pos(state_graph.x, k), get_obj_pos(self.env.target_graph.x, k)):\n",
    "\t\t\t\tremaining_objs.append(k)\n",
    "\n",
    "\t\t# shuffle remaining objs\n",
    "\t\tnp.random.shuffle(remaining_objs)\n",
    "\t\t\n",
    "\t\treturn remaining_objs\n",
    "\n",
    "\tdef get_valid_actions(self, state):\n",
    "\t\tself.env.set_state(copy_state(state))\n",
    "\n",
    "\t\tvalid_actions = []\n",
    "\t\tfor k in self.get_remaining_objects(state):\n",
    "\t\t\tfor position in get_empty_positions_with_target(self.env, ref_node=k, n=self.num_buffers):\n",
    "\t\t\t\tvalid_actions.append(self.env.encode_action('move', k, k, position))\n",
    "\t\t\n",
    "\t\treturn valid_actions\n",
    "\n",
    "\tdef evaluate_state(self, state):\n",
    "\t\tstate_graph = state['graph']\n",
    "\t\theuristic = 0\n",
    "\n",
    "\t\tfor k in self.get_remaining_objects(state):\n",
    "\t\t\tCK = get_obj_pos(state_graph.x, k)\n",
    "\t\t\tTK = get_obj_pos(self.env.target_graph.x, k)\n",
    "\t\t\theuristic += self.env.pp_cost\n",
    "\t\t\theuristic += torch.norm(CK - TK).item() * self.env.normalization_factor\n",
    "\t\t\n",
    "\t\treturn heuristic\n",
    "\n",
    "\tdef solve(self, max_depth=100, num_buffers=3, score_sorting=False, time_limit=None):\n",
    "\t\tif torch.sum(self.env.state_graph.x[:, Indices.RELATION]) > 0:\n",
    "\t\t\traise ValueError('Initial graph has edges in Non-stack mode')\n",
    "\t\tif torch.sum(self.env.target_graph.x[:, Indices.RELATION]) > 0:\n",
    "\t\t\traise ValueError('Target graph has edges in Non-stack mode')\n",
    "\t\treturn super().solve(max_depth, num_buffers, score_sorting, time_limit)\n",
    "\n",
    "class StrapGA(Strap):\n",
    "\tdef _solve(self, max_depth=100, time_limit=None):\n",
    "\t\tstart_time = time.time()\n",
    "\t\tbest_plan = None\n",
    "\t\tbest_cost = float('inf')\n",
    "\n",
    "\t\tsteps = 0\n",
    "\t\troot_node = self.node_class(\n",
    "\t\t\tstate=self.env.get_state(), \n",
    "\t\t\tcost_to_come=0, \n",
    "\t\t\theuristic=self.evaluate_state(self.env.get_state())\n",
    "\t\t)\n",
    "\n",
    "\t\tqueue = []\n",
    "\t\theapq.heappush(queue, root_node)\n",
    "\t\tvisited = {}\n",
    "\n",
    "\t\twhile queue:\n",
    "\t\t\tcurrent_node = heapq.heappop(queue)\n",
    "\n",
    "\t\t\t# Check if the current node's state matches the target state\n",
    "\t\t\tself.env.set_state(current_node.get_state())\n",
    "\t\t\tif self.env.is_terminal_state():\n",
    "\t\t\t\tif best_plan is not None and current_node.total_cost < best_cost:\n",
    "\t\t\t\t\treturn reconstruct_path(current_node), steps, time.time()-start_time\n",
    "\t\t\t\telse:\n",
    "\t\t\t\t\treturn best_plan, steps, time.time()-start_time\n",
    "\n",
    "\t\t\tif current_node.depth >= max_depth:\n",
    "\t\t\t\tcontinue\n",
    "\n",
    "\t\t\tif time_limit is not None and time.time()-start_time > time_limit:\n",
    "\t\t\t\tprint('Time limit exceeded')\n",
    "\t\t\t\treturn best_plan, steps, time.time()-start_time\n",
    "\n",
    "\t\t\tlast_obj = self.env.decode_action(current_node.action)[1] if current_node.action is not None else None\n",
    "\t\t\tfor action in self.get_valid_actions(current_node.get_state()):\n",
    "\t\t\t\taction_type, start_obj, target_obj, coordinates = self.env.decode_action(action)\n",
    "\n",
    "\t\t\t\t# If the last changed node is the same as the current node, continue\n",
    "\t\t\t\tif start_obj == last_obj:\n",
    "\t\t\t\t\tcontinue\n",
    "\n",
    "\t\t\t\tsteps += 1\n",
    "\t\t\t\tself.env.set_state(current_node.get_state())\n",
    "\t\t\t\tcost, child_state = self.env._step(action_type, start_obj, target_obj, coordinates)\n",
    "\n",
    "\t\t\t\t# If state hasn't changed, continue\n",
    "\t\t\t\tif torch.equal(child_state['graph'].x, current_node.get_state()['graph'].x):\n",
    "\t\t\t\t\traise ValueError('State has not changed')\n",
    "\n",
    "\t\t\t\tchild_hash = state_to_hashable(child_state)\n",
    "\n",
    "\t\t\t\t# Calculate the accumulated cost for the current path\n",
    "\t\t\t\tnew_c_cost = current_node.c_cost + cost\n",
    "\t\t\t\th_cost = self.evaluate_state(child_state)\n",
    "\t\t\t\tnew_total_cost = new_c_cost + h_cost\n",
    "\n",
    "\t\t\t\t# Retain the node with better cost\n",
    "\t\t\t\tif child_hash not in visited or visited[child_hash] > new_total_cost:\n",
    "\t\t\t\t\tvisited[child_hash] = new_total_cost\n",
    "\t\t\t\t\tchild_node = self.node_class(\n",
    "\t\t\t\t\t\tstate=child_state, \n",
    "\t\t\t\t\t\tparent=current_node, \n",
    "\t\t\t\t\t\taction=action, \n",
    "\t\t\t\t\t\tcost_to_come=new_c_cost, \n",
    "\t\t\t\t\t\theuristic=h_cost,\n",
    "\t\t\t\t\t\tdepth=current_node.depth+1\n",
    "\t\t\t\t\t)\n",
    "\n",
    "\t\t\t\t\theapq.heappush(queue, child_node)\n",
    "\n",
    "\t\t\tif time_limit is not None and time.time()-start_time > time_limit:\n",
    "\t\t\t\tprint('Time limit exceeded')\n",
    "\t\t\t\treturn best_plan, steps, time.time()-start_time\n",
    "\n",
    "\t\t\t# Goal Attempting\n",
    "\t\t\tself.env.set_state(current_node.get_state())\n",
    "\t\t\tsim_time_limit = (time_limit - time.time() + start_time) / 4\n",
    "\t\t\tpath_to_go, labbe_steps, _ = Labbe(self.env).solve(time_limit=sim_time_limit, c=0)\n",
    "\t\t\tsteps += labbe_steps\n",
    "\t\t\tself.env.set_state(current_node.get_state())\n",
    "\n",
    "\t\t\tif path_to_go is None:\n",
    "\t\t\t\tcontinue\n",
    "\n",
    "\t\t\tfeasible_path_cost = current_node.c_cost\n",
    "\t\t\tfor i, action in enumerate(path_to_go):\n",
    "\t\t\t\tcost, child_state = self.env.step(action)\n",
    "\t\t\t\tfeasible_path_cost += cost\n",
    "\t\t\t\tif i == 0:\n",
    "\t\t\t\t\tfirst_child = child_state\n",
    "\t\t\t\t\tfist_action = action\n",
    "\t\t\t\t\tfirst_cost = feasible_path_cost\n",
    "\n",
    "\t\t\tif feasible_path_cost < best_cost:\n",
    "\t\t\t\tbest_plan = reconstruct_path(current_node) + path_to_go\n",
    "\t\t\t\tbest_cost = feasible_path_cost\n",
    "\t\t\t\tchild_node = self.node_class(\n",
    "\t\t\t\t\tstate=first_child,\n",
    "\t\t\t\t\tparent=current_node,\n",
    "\t\t\t\t\taction=fist_action,\n",
    "\t\t\t\t\tcost_to_come=first_cost,\n",
    "\t\t\t\t\theuristic=self.evaluate_state(first_child),\n",
    "\t\t\t\t\tdepth=current_node.depth+1\n",
    "\t\t\t\t)\n",
    "\t\t\t\theapq.heappush(queue, child_node)\n",
    "\n",
    "\t\t\t# Remove all the nodes with their total cost is greater than the feasible path cost\n",
    "\t\t\tfor node in queue:\n",
    "\t\t\t\tif node.total_cost > feasible_path_cost:\n",
    "\t\t\t\t\tqueue.remove(node)\n",
    "\n",
    "\t\treturn best_plan, steps, time.time()-start_time\n",
    "\n",
    "num_runs = 3\n",
    "env.terminal_cost = True\n",
    "env.static_stack = False\n",
    "evaluate_alg(env, StrapGA, initial_scene, target_scene, num_runs=num_runs, num_buffers=4, time_limit=60);\n",
    "evaluate_alg(env, A_starGA, initial_scene, target_scene, num_runs=num_runs, num_buffers=4, time_limit=60);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MctsNode:\n",
    "\tnode_counter = 0  # Static variable to assign unique IDs to each node\n",
    "\n",
    "\tdef __init__(self, state, valid_actions, parent=None, action=None, cost=0.0, cost_to_come=0.0, c=1, depth=0):\n",
    "\t\tself.state = state\n",
    "\t\tself.parent = parent\n",
    "\t\tself.action = action\n",
    "\t\tself.children = {}\n",
    "\t\tself.n = 0\n",
    "\t\t# self.w = 0\n",
    "\t\tself.w = np.inf\n",
    "\t\tself.c = c\n",
    "\t\tself.cost = cost\n",
    "\t\tself.c_cost = cost_to_come\n",
    "\t\tself.unexpanded_actions = valid_actions\n",
    "\t\tself.depth = depth\n",
    "\t\t\n",
    "\t\t# Assign a unique ID to each node\n",
    "\t\tself.id = MctsNode.node_counter\n",
    "\t\tMctsNode.node_counter += 1\n",
    "\n",
    "\tdef get_state(self):\n",
    "\t\treturn copy_state(self.state)\n",
    "\n",
    "\tdef is_fully_expanded(self):\n",
    "\t\treturn len(self.unexpanded_actions) == 0\n",
    "\n",
    "\tdef uct(self, c_min=0, c_max=1):\n",
    "\t\tn = self.n\n",
    "\n",
    "\t\t# expected_value = ( (self.c_cost + self.w / n) - c_min ) / (c_max - c_min)\n",
    "\t\texpected_value = ( (self.c_cost + self.w) - c_min ) / (c_max - c_min)\n",
    "\t\texploration_term = np.sqrt(2 * np.log(self.parent.n) / n)\n",
    "\n",
    "\t\treturn expected_value - self.c * exploration_term  # Minimization form\n",
    "\n",
    "class Sorp(BaseSearch):\n",
    "\tdef __init__(self, env):\n",
    "\t\tsuper().__init__(env, MctsNode)\n",
    "\t\n",
    "\tdef get_remaining_objects(self, state):\n",
    "\t\tstate_graph = state['graph']\n",
    "\n",
    "\t\tremaining_objs = []\n",
    "\t\tfor k in range(state_graph.num_nodes):\n",
    "\t\t\ti = get_object_bellow(self.env.target_graph.x, k)\n",
    "\t\t\tif i is not None:\n",
    "\t\t\t\tif not is_stacked_on_object(state_graph.x, k, i):\n",
    "\t\t\t\t\tremaining_objs.append(k)\n",
    "\t\t\telif get_object_bellow(state_graph.x, k) is not None:\n",
    "\t\t\t\tremaining_objs.append(k)\n",
    "\t\t\telse:\n",
    "\t\t\t\tif not torch.equal(get_obj_pos(state_graph.x, k), get_obj_pos(self.env.target_graph.x, k)):\n",
    "\t\t\t\t\tremaining_objs.append(k)\n",
    "\n",
    "\t\t# shuffle remaining objs\n",
    "\t\tnp.random.shuffle(remaining_objs)\n",
    "\n",
    "\t\treturn remaining_objs\n",
    "\n",
    "\tdef get_valid_actions(self, state):\n",
    "\t\tself.env.set_state(state)\n",
    "\n",
    "\t\tstack_nums = max(int(0.6 * self.num_buffers), 1)\n",
    "\n",
    "\t\tobjects = list(range(self.env.num_objects))\n",
    "\t\tnp.random.shuffle(objects)\n",
    "\n",
    "\t\tvalid_actions = []\n",
    "\t\tfor k in self.get_remaining_objects(state):\n",
    "\t\t\tif self.static_stack and get_object_above(self.env.state_graph.x, k) is not None:\n",
    "\t\t\t\tcontinue\n",
    "\t\t\t\n",
    "\t\t\tvalid_stacks = []\n",
    "\t\t\tfor j in objects:\n",
    "\t\t\t\tif k != j and not is_stacked_on_object(self.env.state_graph.x, k, j):\n",
    "\t\t\t\t\tif is_stable(self.env.state_graph.x, k, j):\n",
    "\t\t\t\t\t\tif is_empty_object(self.env.state_graph.x, j):\n",
    "\t\t\t\t\t\t\tvalid_stacks.append(self.env.encode_action('stack', k, j, 0))\n",
    "\t\t\t\t\t\t\tif len(valid_stacks) >= stack_nums:\n",
    "\t\t\t\t\t\t\t\tbreak\n",
    "\n",
    "\t\t\tvalid_moves = []\n",
    "\t\t\tfor position in get_empty_positions_with_target(self.env, ref_node=k, n=self.num_buffers-len(valid_stacks)):\n",
    "\t\t\t\tvalid_moves.append(self.env.encode_action('move', k, k, position))\n",
    "\n",
    "\t\t\tvalid_actions += valid_stacks + valid_moves\n",
    "\n",
    "\t\treturn valid_actions\n",
    "\n",
    "\tdef select(self, node):\n",
    "\t\t# Accesses child nodes for best selection\n",
    "\t\tif self.c_min == np.inf or self.c_max == self.c_min:\n",
    "\t\t\treturn min(node.children.values(), key=lambda child: child.uct())\n",
    "\t\telse:\n",
    "\t\t\treturn min(node.children.values(), key=lambda child: child.uct(self.c_min, self.c_max))\n",
    "\n",
    "\tdef expand(self, node):\n",
    "\t\tif node.is_fully_expanded():\n",
    "\t\t\treturn None  # Prevents further expansion if no actions remain\n",
    "\n",
    "\t\taction = node.unexpanded_actions.pop()\n",
    "\t\tself.env.set_state(node.get_state())\n",
    "\t\taction_type, start_obj, target_obj, coordinates = self.env.decode_action(action)\n",
    "\n",
    "\t\t# Continue expanding if the last changed node is the same as the current node\n",
    "\t\tif node.action is not None:\n",
    "\t\t\t_, last_obj, _, _ = self.env.decode_action(node.action)\n",
    "\t\t\tif last_obj == start_obj:\n",
    "\t\t\t\treturn self.expand(node)\n",
    "\n",
    "\t\tcost, child_state = self.env._step(action_type, start_obj, target_obj, coordinates)\n",
    "\n",
    "\t\t# Continue expanding if the state hasn't changed\n",
    "\t\tif torch.equal(child_state['graph'].x, node.state['graph'].x):\n",
    "\t\t\traise ValueError('State has not changed')\n",
    "\n",
    "\t\tchild_node = self.node_class(\n",
    "\t\t\tstate=child_state, \n",
    "\t\t\tvalid_actions=self.get_valid_actions(self.env.get_state()), \n",
    "\t\t\tparent=node, \n",
    "\t\t\taction=action, \n",
    "\t\t\tcost=cost, \n",
    "\t\t\tcost_to_come=cost+node.c_cost,\n",
    "\t\t\tc=node.c, \n",
    "\t\t\tdepth=node.depth+1\n",
    "\t\t)\n",
    "\t\tnode.children[action] = child_node\n",
    "\n",
    "\t\treturn child_node\n",
    "\n",
    "\tdef rollout_one(self, node):\n",
    "\t\tcosts = 0\n",
    "\n",
    "\t\tself.env.set_state(node.get_state())\n",
    "\t\tsim_time_limit = (self.time_limit - time.time() + self.start_time) / 4\n",
    "\t\tfeasible_path, steps, _ = LabbeS(self.env).solve(time_limit=sim_time_limit, static_stack=self.static_stack)\n",
    "\t\tself.env.set_state(node.get_state())\n",
    "\n",
    "\t\tif feasible_path:\t\t\n",
    "\t\t\tfor i, action in enumerate(feasible_path):\n",
    "\t\t\t\tcost, child_state = self.env.step(action)\n",
    "\t\t\t\tcosts += cost\n",
    "\t\t\t\tif i == 0:\n",
    "\t\t\t\t\t# remove action from the node's unexpanded actions\n",
    "\t\t\t\t\tif action in node.unexpanded_actions:\n",
    "\t\t\t\t\t\tnode.unexpanded_actions.remove(action)\n",
    "\t\t\t\t\t# add the new child to the node\n",
    "\t\t\t\t\tchild_node = self.node_class(\n",
    "\t\t\t\t\t\tstate=child_state, \n",
    "\t\t\t\t\t\tvalid_actions=self.get_valid_actions(self.env.get_state()), \n",
    "\t\t\t\t\t\tparent=node, \n",
    "\t\t\t\t\t\taction=action, \n",
    "\t\t\t\t\t\tcost=cost, \n",
    "\t\t\t\t\t\tcost_to_come=cost+node.c_cost,\n",
    "\t\t\t\t\t\tc=node.c, \n",
    "\t\t\t\t\t\tdepth=node.depth+1\n",
    "\t\t\t\t\t)\n",
    "\t\t\t\t\tnode.children[action] = child_node\n",
    "\t\t\t\t\tnode = child_node\n",
    "\n",
    "\t\treturn costs, steps, feasible_path, node\n",
    "\n",
    "\tdef rollout(self, node):\n",
    "\t\tcosts = 0\n",
    "\n",
    "\t\tself.env.set_state(node.get_state())\n",
    "\t\tsim_time_limit = (self.time_limit - time.time() + self.start_time) / 4\n",
    "\t\tfeasible_path, steps, _ = LabbeS(self.env).solve(time_limit=sim_time_limit, static_stack=self.static_stack)\n",
    "\t\tself.env.set_state(node.get_state())\n",
    "\n",
    "\t\tif feasible_path:\n",
    "\t\t\tfor action in feasible_path:\n",
    "\t\t\t\tcost, child_state = self.env.step(action)\n",
    "\t\t\t\tcosts += cost\n",
    "\t\t\t\t# remove action from the node's unexpanded actions\n",
    "\t\t\t\tif action in node.unexpanded_actions:\n",
    "\t\t\t\t\tnode.unexpanded_actions.remove(action)\n",
    "\t\t\t\t# add the new child to the node\n",
    "\t\t\t\tchild_node = self.node_class(\n",
    "\t\t\t\t\tstate=child_state, \n",
    "\t\t\t\t\tvalid_actions=self.get_valid_actions(self.env.get_state()), \n",
    "\t\t\t\t\tparent=node, \n",
    "\t\t\t\t\taction=action, \n",
    "\t\t\t\t\tcost=cost, \n",
    "\t\t\t\t\tcost_to_come=cost+node.c_cost,\n",
    "\t\t\t\t\tc=node.c, \n",
    "\t\t\t\t\tdepth=node.depth+1\n",
    "\t\t\t\t)\n",
    "\t\t\t\tnode.children[action] = child_node\n",
    "\t\t\t\tnode = child_node\n",
    "\n",
    "\t\treturn costs, steps, feasible_path, node\n",
    "\n",
    "\tdef backup_search(self, node, value):\n",
    "\t\twhile node is not None:\n",
    "\t\t\tnode.n += 1\n",
    "\t\t\t# node.w += value\n",
    "\t\t\tnode.w = min(node.w, value)\n",
    "\t\t\tvalue += node.cost\n",
    "\t\t\tnode = node.parent\n",
    "\n",
    "\tdef print_tree(self, node, depth=0, max_depth=float('inf'), ter=False):\n",
    "\t\tif depth >= max_depth:\n",
    "\t\t\treturn\n",
    "\n",
    "\t\t# Print the current node with indentation to show its depth in the tree\n",
    "\t\tindent = \"    \" * depth  # Four spaces per level of depth\n",
    "\t\tif node.id == 0:\n",
    "\t\t\tprint(f\"Root | n: {node.n} | w: {node.w:.2f}\")\n",
    "\t\telse:\n",
    "\t\t\tn = node.n\n",
    "\t\t\tif self.c_max == self.c_min:\n",
    "\t\t\t\t# expected_value = node.c_cost + node.w / n\n",
    "\t\t\t\texpected_value = node.c_cost + node.w\n",
    "\t\t\telse:\n",
    "\t\t\t\t# expected_value = ( (node.c_cost + node.w / n) - self.c_min ) / (self.c_max - self.c_min)\n",
    "\t\t\t\texpected_value = ( (node.c_cost + node.w) - self.c_min ) / (self.c_max - self.c_min)\n",
    "\t\t\texploration_term = np.sqrt(2 * np.log(node.parent.n) / n)\n",
    "\n",
    "\t\t\tprint(f\"{indent}ID: {node.id} | a: {node.action} | c: {node.cost:.2f} | ctc: {node.c_cost:.2f} | \"\n",
    "\t\t\t\t\tf\"n: {node.n} | w: {node.w:.2f} | expe: {expected_value:.4f} | expl: {exploration_term:.4f}\")\n",
    "\n",
    "\t\t# Sort children by w estimate\n",
    "\t\tif ter:\n",
    "\t\t\taccepted_children = [child for child in node.children.values()]\n",
    "\t\t\tchildren = sorted(accepted_children, key=lambda child: child.w)\n",
    "\t\telse:\n",
    "\t\t\tchildren = sorted(node.children.values(), key=lambda child: child.w)\n",
    "\n",
    "\t\t# Recurse on children\n",
    "\t\tfor child in children:\n",
    "\t\t\tself.print_tree(child, depth + 1, max_depth, ter)\n",
    "\n",
    "\tdef find_best_path(self):\n",
    "\t\t# self.print_tree(self.root_node, max_depth=5)\n",
    "\t\tif self.best_plan is None or self.best_plan[1] is None:\n",
    "\t\t\treturn None\n",
    "\t\treturn reconstruct_path(self.best_plan[0]) + self.best_plan[1]\n",
    "\n",
    "\tdef loop(self):\n",
    "\t\tnode = self.root_node\n",
    "\n",
    "\t\t# Selection\n",
    "\t\tself.env.set_state(node.get_state())\n",
    "\t\twhile node.is_fully_expanded() and not self.env.is_terminal_state():\n",
    "\t\t\tnode = self.select(node)\n",
    "\t\t\tself.env.set_state(node.get_state())\n",
    "\n",
    "\t\t# Expansion\n",
    "\t\tif not self.env.is_terminal_state():\n",
    "\t\t\tchild_node = self.expand(node)\n",
    "\t\t\tif child_node is None:\n",
    "\t\t\t\twhile len(node.children) == 0 and node.is_fully_expanded():\n",
    "\t\t\t\t\tnode.parent.children.pop(node.action)\n",
    "\t\t\t\t\tnode = node.parent\n",
    "\t\t\t\t\tprint('oooooooooooooooooooo laaaaaaaa laaaaaaaaaaaaa')\n",
    "\t\t\t\treturn 1\n",
    "\t\t\tnode = child_node\n",
    "\n",
    "\t\t# Simulation (Rollout)\n",
    "\t\tself.env.set_state(node.get_state())\n",
    "\t\tsteps = 0\n",
    "\t\tif self.env.is_terminal_state():\n",
    "\t\t\tvalue = 0\n",
    "\t\telse:\n",
    "\t\t\tif self.one_step:\n",
    "\t\t\t\tc_rollout, steps, feasible_plan, child_node = self.rollout_one(node)\n",
    "\t\t\telse:\n",
    "\t\t\t\tc_rollout, steps, feasible_plan, child_node = self.rollout(node)\n",
    "\n",
    "\t\t\tif feasible_plan is None:\n",
    "\t\t\t\tif node.parent is None:\n",
    "\t\t\t\t\treturn -1\n",
    "\t\t\t\tnode.parent.children.pop(node.action)\n",
    "\t\t\t\tnode = node.parent\n",
    "\t\t\t\twhile len(node.children) == 0 and node.is_fully_expanded():\n",
    "\t\t\t\t\tnode.parent.children.pop(node.action)\n",
    "\t\t\t\t\tnode = node.parent\n",
    "\t\t\t\t\tif node.parent is None:\n",
    "\t\t\t\t\t\treturn -1\n",
    "\t\t\t\treturn steps\n",
    "\n",
    "\t\t\tnew_cost = c_rollout + node.c_cost\n",
    "\t\t\tself.c_max = max(self.c_max, new_cost)\n",
    "\t\t\tif new_cost < self.c_min:\n",
    "\t\t\t\tself.best_plan = (node, feasible_plan)\n",
    "\t\t\t\tself.c_min = new_cost\n",
    "\t\t\t\n",
    "\t\t\tnode = child_node\n",
    "\t\t\tif self.one_step:\n",
    "\t\t\t\tvalue = c_rollout - node.cost\n",
    "\t\t\telse:\n",
    "\t\t\t\tvalue = 0\n",
    "\n",
    "\t\t# Backpropagation\n",
    "\t\tself.backup_search(node, value)\n",
    "\n",
    "\t\treturn steps\n",
    "\n",
    "\tdef solve(self, iterations=1000, num_buffers=3, c=1, verbose=0, one_step=True, static_stack=False, time_limit=None):\n",
    "\t\tself.start_time = time.time()\n",
    "\t\tself.static_stack = static_stack\n",
    "\n",
    "\t\tMctsNode.node_counter = 0\n",
    "\t\tself.num_buffers = num_buffers\n",
    "\t\tself.time_limit = time_limit\n",
    "\t\tself.one_step = one_step\n",
    "\t\tself.c_max = -np.inf\n",
    "\t\tself.c_min = np.inf\n",
    "\t\tself.best_plan = None\n",
    "\t\twindow_last_values = []\n",
    "\t\tself.root_node = self.node_class(\n",
    "\t\t\tstate=self.env.get_state(), \n",
    "\t\t\tvalid_actions=self.get_valid_actions(self.env.get_state()), \n",
    "\t\t\tc=c\n",
    "\t\t)\n",
    "\t\t\n",
    "\t\tsteps, iteration = 0, 0\n",
    "\t\tif verbose > 0:\n",
    "\t\t\tpbar = tqdm(total=None, unit='iterations')\n",
    "\t\t\n",
    "\t\twhile iteration < iterations:\n",
    "\t\t\t# Check if the elapsed time has exceeded the limit\n",
    "\t\t\tif time_limit is not None and  time.time()-self.start_time > time_limit:\n",
    "\t\t\t\tif verbose > 0:\n",
    "\t\t\t\t\tpbar.close()\n",
    "\t\t\t\tprint('Time limit exceeded')\n",
    "\t\t\t\treturn self.find_best_path(), steps, time.time()-self.start_time\n",
    "\t\t\t\n",
    "\t\t\titeration += 1\n",
    "\t\t\tstep = self.loop()\n",
    "\t\t\tif step == -1:\n",
    "\t\t\t\treturn self.find_best_path(), steps, time.time()-self.start_time\n",
    "\t\t\t\n",
    "\t\t\tsteps += step\n",
    "\t\t\tif verbose > 0:\n",
    "\t\t\t\tpbar.update(1)\n",
    "\t\t\t\n",
    "\t\t\t# if iteration != 0 and iteration % 20 == 0:\n",
    "\t\t\t# \t# v_root = self.root_node.w\n",
    "\t\t\t# \t# print(f'v_root: {v_root:.3f} | c_min: {self.c_min:.3f} | c_max: {self.c_max:.3f}')\n",
    "\t\t\t# \t# self.print_tree(self.root_node, max_depth=3)\n",
    "\t\t\t# \twindow_last_values.append(self.c_min)\n",
    "\t\t\t# \tif len(window_last_values) > 5:\n",
    "\t\t\t# \t\twindow_last_values.pop(0)\n",
    "\t\t\t# \t\tif len(set(window_last_values)) == 1:\n",
    "\t\t\t# \t\t\tbreak\n",
    "\n",
    "\t\tif verbose > 0:\n",
    "\t\t\tpbar.close()\n",
    "\n",
    "\t\treturn self.find_best_path(), steps, time.time()-self.start_time\n",
    "\n",
    "# evaluate_alg(env, Sorp, initial_scene, target_scene, num_runs=3, iterations=1000, num_buffers=4, c=0.5, verbose=1, one_step=True, time_limit=60);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Refinement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def refine_until_convergence(env, plan, initial_scene, target_scene, alg, verbose=0):\n",
    "\tstart_time = time.time()\n",
    "\tbest_plan = plan\n",
    "\tbest_cost = env_cost(env, plan, initial_scene, target_scene, log=False)\n",
    "\tif plan is None:\n",
    "\t\treturn best_plan, best_cost, time.time() - start_time\n",
    "\twhile True:\n",
    "\t\tif alg in ['Labbe', 'Strap', 'StrapGA']:\n",
    "\t\t\trefined_plan = plan_refinement(env, plan, initial_scene, target_scene, verbose=verbose)\n",
    "\t\telse:\n",
    "\t\t\trefined_plan = plan_refinement_stack(env, plan, initial_scene, target_scene, verbose=verbose)\n",
    "\n",
    "\t\tif plan == refined_plan:\n",
    "\t\t\tbreak\n",
    "\n",
    "\t\tcost = env_cost(env, refined_plan, initial_scene, target_scene, log=False)\n",
    "\t\tif cost < best_cost:\n",
    "\t\t\tif verbose > 0:\n",
    "\t\t\t\tprint(f'cost got better from {best_cost:.3f} to {cost:.3f}')\n",
    "\t\t\tbest_cost = cost\n",
    "\t\t\tbest_plan = refined_plan\n",
    "\n",
    "\t\tplan = refined_plan\n",
    "\n",
    "\treturn best_plan, best_cost, time.time() - start_time\n",
    "\n",
    "def plan_refinement(env, plan, initial_scene, target_scene, verbose=0):\n",
    "\taction_seq = []\n",
    "\tenv.reset(initial_scene, target_scene)\n",
    "\tfor action in plan:\n",
    "\t\ta_type, k, _, coordinates = env.decode_action(action)\n",
    "\t\tif a_type == 'stack':\n",
    "\t\t\tif verbose > 0:\n",
    "\t\t\t\tprint('there is a stack in the simple refinement')\n",
    "\t\t\treturn plan\n",
    "\t\tp_pick = get_obj_pos(env.state_graph.x, k)\n",
    "\t\tp_place = unflatten_pos(coordinates, env.grid_size)\n",
    "\t\t\n",
    "\t\t# Prevent the same object to be moved twice in a row\n",
    "\t\tif len(action_seq) > 0 and action_seq[-1]['k'] == k:\n",
    "\t\t\tpre_p_place = action_seq[-1]['p_place']\n",
    "\t\t\taction_seq[-1] = {\n",
    "\t\t\t\t'k': k,\n",
    "\t\t\t\t'p_pick': p_pick,\n",
    "\t\t\t\t'p_place': p_place\n",
    "\t\t\t}\n",
    "\t\t\tif verbose > 0:\n",
    "\t\t\t\tprint(f'Redundant moving of obj {k} to {pre_p_place} was removed')\n",
    "\t\telse:\n",
    "\t\t\taction_seq.append({\n",
    "\t\t\t\t'k': k,\n",
    "\t\t\t\t'p_pick': p_pick,\n",
    "\t\t\t\t'p_place': p_place\n",
    "\t\t\t})\n",
    "\n",
    "\t\tenv.step(action)\n",
    "\n",
    "\tenv.reset(initial_scene, target_scene)\n",
    "\tB = {}\n",
    "\tH = {0: {'state': env.get_state(), 'table': env.table}}\t\t# arrangement history\n",
    "\tfor i in range(len(action_seq)):\n",
    "\t\tk = action_seq[i]['k']\n",
    "\n",
    "\t\tif k in B:\t\t\t# if object k was moved\n",
    "\t\t\tbIdx = B[k]\t\t# previous action index on k\n",
    "\t\t\tsize_k = get_obj_size(env.state_graph.x, k)\n",
    "\n",
    "\t\t\t# Occupied possitions in the action index bIdx\n",
    "\t\t\tC = []\n",
    "\t\t\tfor position in get_all_positions_in_env(env.grid_size, size_k):\n",
    "\t\t\t\tposition = torch.tensor(position, dtype=torch.float32)\n",
    "\t\t\t\tif env.is_coor_occupied(position, k, H[bIdx]['table']):\n",
    "\t\t\t\t\tC.append(position)\n",
    "\t\t\t\n",
    "\t\t\t# Ocuupied buffers in the action index bIdx to i-1\n",
    "\t\t\tfor j in range(bIdx, i):\n",
    "\t\t\t\tif action_seq[j]['k'] != k:\n",
    "\t\t\t\t\tsize = env.get_obj_size(action_seq[j]['k'])\n",
    "\t\t\t\t\tsize = (size[0]+size_k[0]-1, size[1]+size_k[1]-1)\n",
    "\t\t\t\t\tfor position in get_all_positions_of_object(action_seq[j]['p_place'], size):\n",
    "\t\t\t\t\t\tC.append(torch.tensor(position, dtype=torch.float32))\n",
    "\n",
    "\t\t\t# Generate a buffer set under constraint C\n",
    "\t\t\tP = []\n",
    "\t\t\tfor position in get_all_positions_in_env(env.grid_size, size_k):\n",
    "\t\t\t\tposition = torch.tensor(position, dtype=torch.float32)\n",
    "\t\t\t\tif not any(torch.equal(position, c) for c in C):\n",
    "\t\t\t\t\tP.append(position)\n",
    "\t\t\tif len(P) == 0:\n",
    "\t\t\t\tif verbose > 0:\n",
    "\t\t\t\t\tprint(f'No feasible buffer set')\n",
    "\n",
    "\t\t\t# Distances\n",
    "\t\t\tp1 = action_seq[bIdx]['p_pick']\n",
    "\t\t\tp2 = action_seq[i-1]['p_place']\n",
    "\t\t\tp3 = action_seq[bIdx+1]['p_pick']\n",
    "\t\t\tp4 = action_seq[i]['p_place']\n",
    "\n",
    "\t\t\t# Current cost\n",
    "\t\t\tp = action_seq[bIdx]['p_place'].clone()\n",
    "\t\t\tmin_cost = env.cal_manipulator_movement(p1, p)\n",
    "\t\t\tmin_cost += env.cal_manipulator_movement(p, p3)\n",
    "\t\t\tmin_cost += env.cal_manipulator_movement(p2, p)\n",
    "\t\t\tmin_cost += env.cal_manipulator_movement(p, p4)\n",
    "\t\t\tmin_cost = min_cost * env.normalization_factor\n",
    "\n",
    "\t\t\t# Find the best buffer\n",
    "\t\t\tbest_p = None\n",
    "\t\t\tfor p in P:\n",
    "\t\t\t\tcost = env.cal_manipulator_movement(p1, p)\n",
    "\t\t\t\tcost += env.cal_manipulator_movement(p, p3)\n",
    "\t\t\t\tcost += env.cal_manipulator_movement(p2, p)\n",
    "\t\t\t\tcost += env.cal_manipulator_movement(p, p4)\n",
    "\t\t\t\tcost = cost * env.normalization_factor\n",
    "\t\t\t\tif cost < min_cost:\n",
    "\t\t\t\t\tbest_p = p.clone()\n",
    "\t\t\t\t\tmin_cost = cost\n",
    "\n",
    "\t\t\t# Update the best buffer\n",
    "\t\t\tif best_p is not None:\n",
    "\t\t\t\tif verbose > 0:\n",
    "\t\t\t\t\tlast_pos = action_seq[bIdx]['p_place']\n",
    "\t\t\t\t\tprint(f'Buffer of obj {k} changed from pos {last_pos.tolist()} to pos {best_p.tolist()}')\n",
    "\n",
    "\t\t\t\taction_seq[bIdx] = {\n",
    "\t\t\t\t\t'k': k,\n",
    "\t\t\t\t\t'p_pick': action_seq[bIdx]['p_pick'].clone(),\n",
    "\t\t\t\t\t'p_place': best_p\n",
    "\t\t\t\t}\n",
    "\t\t\t\tif torch.equal(best_p, action_seq[i]['p_place']):\n",
    "\t\t\t\t\tif verbose > 0:\n",
    "\t\t\t\t\t\tprint(f'New static buffer is the same as the current one, so the action {i} is removed')\n",
    "\t\t\t\t\tdel action_seq[i]\n",
    "\t\t\t\telse:\n",
    "\t\t\t\t\taction_seq[i] = {\n",
    "\t\t\t\t\t\t'k': k,\n",
    "\t\t\t\t\t\t'p_pick': best_p,\n",
    "\t\t\t\t\t\t'p_place': action_seq[i]['p_place'].clone()\n",
    "\t\t\t\t\t}\n",
    "\t\t\t\tbreak\n",
    "\n",
    "\t\tenv.step(plan[i])\n",
    "\t\tH[i+1] = {'state': env.get_state(), 'table': env.table}\n",
    "\t\tB[k] = i\n",
    "\n",
    "\trefined_plan = [env.encode_action('move', a['k'], a['k'], flatten_pos(a['p_place'], env.grid_size)) for a in action_seq]\n",
    "\n",
    "\treturn refined_plan\n",
    "\n",
    "def plan_refinement_stack(env, plan, initial_scene, target_scene, verbose=0):\n",
    "\taction_seq = []\n",
    "\tenv.reset(initial_scene, target_scene)\n",
    "\tfor action in plan:\n",
    "\t\ta_type, k, l, coordinates = env.decode_action(action)\n",
    "\t\tp_pick = get_obj_pos(env.state_graph.x, k)\n",
    "\t\tif a_type == 'move':\n",
    "\t\t\tp_place = unflatten_pos(coordinates, env.grid_size)\n",
    "\t\telif a_type == 'stack':\n",
    "\t\t\tp_place = get_obj_pos(env.state_graph.x, l)\n",
    "\t\telse:\n",
    "\t\t\traise ValueError('Invalid action type')\n",
    "\n",
    "\t\t# Prevent the same object to be moved twice in a row\n",
    "\t\tif len(action_seq) > 0 and action_seq[-1]['k'] == k:\n",
    "\t\t\tpre_p_place = action_seq[-1]['p_place']\n",
    "\t\t\tpre_l = action_seq[-1]['l']\n",
    "\t\t\taction_seq[-1] = {\n",
    "\t\t\t\t'type': a_type,\n",
    "\t\t\t\t'k': k,\n",
    "\t\t\t\t'l': l,\n",
    "\t\t\t\t'p_pick': p_pick,\n",
    "\t\t\t\t'p_place': p_place\n",
    "\t\t\t}\n",
    "\t\t\tif verbose > 0:\n",
    "\t\t\t\tif a_type == 'stack':\n",
    "\t\t\t\t\tprint(f'Redundant stacking of obj {k} to obj {pre_l} was removed')\n",
    "\t\t\t\telse:\n",
    "\t\t\t\t\tprint(f'Redundant moving of obj {k} to {pre_p_place} was removed')\n",
    "\t\telse:\n",
    "\t\t\taction_seq.append({\n",
    "\t\t\t\t'type': a_type,\n",
    "\t\t\t\t'k': k,\n",
    "\t\t\t\t'l': l,\n",
    "\t\t\t\t'p_pick': p_pick,\n",
    "\t\t\t\t'p_place': p_place\n",
    "\t\t\t})\n",
    "\n",
    "\t\tenv.step(action)\n",
    "\n",
    "\tenv.reset(initial_scene, target_scene)\n",
    "\tB = {}\n",
    "\tH = {0: {'state': env.get_state(), 'table': env.table}}\t\t# arrangement history\n",
    "\tfor i in range(len(action_seq)):\n",
    "\t\tk = action_seq[i]['k']\n",
    "\n",
    "\t\tif k in B:\t\t\t# if object k was moved\n",
    "\t\t\tbIdx = B[k]\t\t# previous action index on k\n",
    "\t\t\tsize_k = get_obj_size(env.state_graph.x, k)\n",
    "\n",
    "\t\t\t# Occupied possitions in the action index bIdx\n",
    "\t\t\tC = []\n",
    "\t\t\tfor position in get_all_positions_in_env(env.grid_size, size_k):\n",
    "\t\t\t\tposition = torch.tensor(position, dtype=torch.float32)\n",
    "\t\t\t\tif env.is_coor_occupied(position, k, H[bIdx]['table']):\n",
    "\t\t\t\t\tC.append(position)\n",
    "\n",
    "\t\t\t# Ocuupied static buffers in the action index bIdx to i-1\n",
    "\t\t\tfor j in range(bIdx, i):\n",
    "\t\t\t\t# If the action is stack, continue\n",
    "\t\t\t\tif action_seq[j]['type'] == 'stack':\n",
    "\t\t\t\t\tcontinue\n",
    "\t\t\t\tif action_seq[j]['k'] != k:\n",
    "\t\t\t\t\tsize = get_obj_size(env.state_graph.x, action_seq[j]['k'])\n",
    "\t\t\t\t\tsize = (size[0]+size_k[0]-1, size[1]+size_k[1]-1)\n",
    "\t\t\t\t\tfor position in get_all_positions_of_object(action_seq[j]['p_place'], size):\n",
    "\t\t\t\t\t\tC.append(torch.tensor(position, dtype=torch.float32))\n",
    "\n",
    "\t\t\t# Ocuupied moving buffers in the action index bIdx to i-1\n",
    "\t\t\tempty_objs = []\n",
    "\t\t\tfor obj in range(env.num_objects):\n",
    "\t\t\t\tif is_stable(H[0]['state']['graph'].x, k, obj):\n",
    "\t\t\t\t\tis_empty = True\n",
    "\t\t\t\t\tfor j in range(bIdx, i):\n",
    "\t\t\t\t\t\tif not is_empty_object(H[j]['state']['graph'].x, obj):\n",
    "\t\t\t\t\t\t\tis_empty = False\n",
    "\t\t\t\t\t\t\tbreak\n",
    "\t\t\t\t\tif is_empty:\n",
    "\t\t\t\t\t\tempty_objs.append(obj)\n",
    "\n",
    "\t\t\t# Generate a buffer set under constraint C\n",
    "\t\t\tP = []\n",
    "\t\t\tfor position in get_all_positions_in_env(env.grid_size, size_k):\n",
    "\t\t\t\tposition = torch.tensor(position, dtype=torch.float32)\n",
    "\t\t\t\tif not any(torch.equal(position, c) for c in C):\n",
    "\t\t\t\t\tP.append(position)\n",
    "\t\t\tif len(P) == 0:\n",
    "\t\t\t\tif verbose > 0:\n",
    "\t\t\t\t\tprint(f'No feasible buffer set')\n",
    "\n",
    "\t\t\t# Distances\n",
    "\t\t\tp1 = action_seq[bIdx]['p_pick']\n",
    "\t\t\tp2 = action_seq[i-1]['p_place']\n",
    "\t\t\tp3 = action_seq[bIdx+1]['p_pick']\n",
    "\t\t\tp4 = action_seq[i]['p_place']\n",
    "\n",
    "\t\t\t# Current cost\n",
    "\t\t\tif action_seq[bIdx]['type'] == 'stack':\n",
    "\t\t\t\tp_to_buff = action_seq[bIdx]['p_place'].clone()\n",
    "\t\t\t\tp_i = get_obj_pos(H[i]['state']['graph'].x, k)\n",
    "\t\t\t\tmin_cost = env.cal_manipulator_movement(p1, p_to_buff)\n",
    "\t\t\t\tmin_cost += env.cal_manipulator_movement(p_to_buff, p3)\n",
    "\t\t\t\tmin_cost += env.cal_manipulator_movement(p2, p_i)\n",
    "\t\t\t\tmin_cost += env.cal_manipulator_movement(p_i, p4)\n",
    "\t\t\t\tmin_cost = min_cost * env.normalization_factor\n",
    "\t\t\telse:\n",
    "\t\t\t\tp = action_seq[bIdx]['p_place'].clone()\n",
    "\t\t\t\tmin_cost = env.cal_manipulator_movement(p1, p)\n",
    "\t\t\t\tmin_cost += env.cal_manipulator_movement(p, p3)\n",
    "\t\t\t\tmin_cost += env.cal_manipulator_movement(p2, p)\n",
    "\t\t\t\tmin_cost += env.cal_manipulator_movement(p, p4)\n",
    "\t\t\t\tmin_cost = min_cost * env.normalization_factor\n",
    "\n",
    "\t\t\t# Find the best buffer\n",
    "\t\t\tbest_p = None\n",
    "\t\t\tfor p in P:\n",
    "\t\t\t\tcost = env.cal_manipulator_movement(p1, p)\n",
    "\t\t\t\tcost += env.cal_manipulator_movement(p, p3)\n",
    "\t\t\t\tcost += env.cal_manipulator_movement(p2, p)\n",
    "\t\t\t\tcost += env.cal_manipulator_movement(p, p4)\n",
    "\t\t\t\tcost = cost * env.normalization_factor\n",
    "\t\t\t\tif cost < min_cost:\n",
    "\t\t\t\t\tbest_p = p.clone()\n",
    "\t\t\t\t\tmin_cost = cost\n",
    "\n",
    "\t\t\tbest_obj = None\n",
    "\t\t\tfor empty_obj in empty_objs:\n",
    "\t\t\t\tp_to_buff = get_obj_pos(H[bIdx]['state']['graph'].x, empty_obj)\n",
    "\t\t\t\tp_i = get_obj_pos(H[i]['state']['graph'].x, empty_obj)\n",
    "\t\t\t\tcost = env.cal_manipulator_movement(p1, p_to_buff)\n",
    "\t\t\t\tcost += env.cal_manipulator_movement(p_to_buff, p3)\n",
    "\t\t\t\tcost += env.cal_manipulator_movement(p2, p_i)\n",
    "\t\t\t\tcost += env.cal_manipulator_movement(p_i, p4)\n",
    "\t\t\t\tcost = cost * env.normalization_factor\n",
    "\t\t\t\tif cost < min_cost:\n",
    "\t\t\t\t\tmin_cost = cost\n",
    "\t\t\t\t\tbest_obj = empty_obj\n",
    "\n",
    "\t\t\t# Update the best buffer\n",
    "\t\t\tif best_obj is not None:\n",
    "\t\t\t\tif verbose > 0:\n",
    "\t\t\t\t\tif action_seq[bIdx]['type'] == 'stack':\n",
    "\t\t\t\t\t\tlast_obj = action_seq[bIdx]['l']\n",
    "\t\t\t\t\t\tprint(f'Buffer of obj {k} changed from obj {last_obj} to obj {best_obj}')\n",
    "\t\t\t\t\telse:\n",
    "\t\t\t\t\t\tlast_pos = action_seq[bIdx]['p_place']\n",
    "\t\t\t\t\t\tprint(f'Buffer of obj {k} changed from pos {last_pos.tolist()} to obj {best_obj}')\n",
    "\n",
    "\t\t\t\taction_seq[bIdx] = {\n",
    "\t\t\t\t\t'type': 'stack',\n",
    "\t\t\t\t\t'k': k,\n",
    "\t\t\t\t\t'l': best_obj,\n",
    "\t\t\t\t\t'p_pick': action_seq[bIdx]['p_pick'].clone(),\n",
    "\t\t\t\t\t'p_place': get_obj_pos(H[bIdx]['state']['graph'].x, best_obj)\n",
    "\t\t\t\t}\n",
    "\t\t\t\tif action_seq[i]['type'] == 'stack' and action_seq[i]['l'] == best_obj:\n",
    "\t\t\t\t\tif verbose > 0:\n",
    "\t\t\t\t\t\tprint(f'New moving buffer is the same as the current one, so the action {i} is removed')\n",
    "\t\t\t\t\tdel action_seq[i]\n",
    "\t\t\t\telse:\n",
    "\t\t\t\t\taction_seq[i]['p_pick'] = get_obj_pos(H[i]['state']['graph'].x, best_obj)\n",
    "\t\t\t\tbreak\n",
    "\t\t\telif best_p is not None:\n",
    "\t\t\t\tif verbose > 0:\n",
    "\t\t\t\t\tif action_seq[bIdx]['type'] == 'stack':\n",
    "\t\t\t\t\t\tlast_obj = action_seq[bIdx]['l']\n",
    "\t\t\t\t\t\tprint(f'Buffer of obj {k} changed from obj {last_obj} to pos {best_p.tolist()}')\n",
    "\t\t\t\t\telse:\n",
    "\t\t\t\t\t\tlast_pos = action_seq[bIdx]['p_place']\n",
    "\t\t\t\t\t\tprint(f'Buffer of obj {k} changed from pos {last_pos.tolist()} to pos {best_p.tolist()}')\n",
    "\n",
    "\t\t\t\taction_seq[bIdx] = {\n",
    "\t\t\t\t\t'type': 'move',\n",
    "\t\t\t\t\t'k': k,\n",
    "\t\t\t\t\t'l': k,\n",
    "\t\t\t\t\t'p_pick': action_seq[bIdx]['p_pick'].clone(),\n",
    "\t\t\t\t\t'p_place': best_p\n",
    "\t\t\t\t}\n",
    "\t\t\t\tif action_seq[i]['type'] == 'move' and torch.equal(best_p, action_seq[i]['p_place']):\n",
    "\t\t\t\t\tif verbose > 0:\n",
    "\t\t\t\t\t\tprint(f'New static buffer is the same as the current one, so the action {i} is removed')\n",
    "\t\t\t\t\tdel action_seq[i]\n",
    "\t\t\t\telse:\n",
    "\t\t\t\t\taction_seq[i]['p_pick'] = best_p\n",
    "\t\t\t\tbreak\n",
    "\n",
    "\t\tenv.step(plan[i])\n",
    "\t\tH[i+1] = {'state': env.get_state(), 'table': env.table}\n",
    "\t\tB[k] = i\n",
    "\n",
    "\trefined_plan = []\n",
    "\tfor a in action_seq:\n",
    "\t\tif a['type'] == 'stack':\n",
    "\t\t\trefined_plan.append(env.encode_action('stack', a['k'], a['l'], 0))\n",
    "\t\telse:\n",
    "\t\t\trefined_plan.append(env.encode_action('move', a['k'], a['k'], flatten_pos(a['p_place'], env.grid_size)))\n",
    "\n",
    "\treturn refined_plan\n",
    "\n",
    "# plan = [1267, 1015, 299, 1518, 1203, 626]\n",
    "# refine_until_convergence(env, plan, initial_scene, target_scene, 'Labbe', verbose=1);\n",
    "# print('------')\n",
    "# refine_until_convergence(env, plan, initial_scene, target_scene, 'LabbeS', verbose=1);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_scenes(num_cases, num_objects, grid_size, phi, ratio=0.5):\n",
    "\tenv = ContinuousEnv(mode='stationary', num_objects=num_objects, grid_size=grid_size, phi=phi, verbose=1)\n",
    "\tscenes = []\n",
    "\tfor _ in range(num_cases):\n",
    "\t\tenv.reset(use_stack=False, ratio=ratio)\n",
    "\t\tscenes.append({\n",
    "\t\t\t'initial_scene': copy_graph(env.initial_graph),\n",
    "\t\t\t'target_scene': copy_graph(env.target_graph)\n",
    "\t\t})\n",
    "\t\n",
    "\treturn scenes\n",
    "\n",
    "def save_scenes(scenes, num_objects, grid_size, phi, ratio=0.5, verbose=0):\n",
    "\tif ratio == 0.5:\n",
    "\t\tdir_path = f'scenes/phi_{phi}/g{grid_size[0]}.{grid_size[1]}/n{num_objects}'\n",
    "\telse:\n",
    "\t\tdir_path = f'scenes/phi_{phi}/r_{ratio}/g{grid_size[0]}.{grid_size[1]}/n{num_objects}'\n",
    "\tos.makedirs(dir_path, exist_ok=True)\n",
    "\t\n",
    "\tfor scene in scenes:\n",
    "\t\tinitial_scene = scene['initial_scene']\n",
    "\t\ttarget_scene = scene['target_scene']\n",
    "\n",
    "\t\t# save the scene in a json file\n",
    "\t\tobjs = []\n",
    "\t\tfor obj in range(num_objects):\n",
    "\t\t\tobjs.append({\n",
    "\t\t\t\t'object_id': obj,\n",
    "\t\t\t\t'label': get_obj_label(initial_scene.x, obj),\n",
    "\t\t\t\t'size': get_obj_size(initial_scene.x, obj),\n",
    "\t\t\t\t'initial_pos': get_obj_pos(initial_scene.x, obj).tolist(),\n",
    "\t\t\t\t'initial_relation': get_obj_relation(initial_scene.x, obj),\n",
    "\t\t\t\t'target_pos': get_obj_pos(target_scene.x, obj).tolist(),\n",
    "\t\t\t\t'target_relation': get_obj_relation(target_scene.x, obj), \n",
    "\t\t\t})\n",
    "\t\t\n",
    "\t\t# Find the id of the current .json files in the dir_path\n",
    "\t\tfiles = os.listdir(dir_path)\n",
    "\t\tscene_id = 0\n",
    "\t\twhile f'scene_{scene_id}.json' in files:\n",
    "\t\t\tscene_id += 1\n",
    "\n",
    "\t\t# create the json scene\n",
    "\t\tif ratio == 0.5:\n",
    "\t\t\tjson_scene = {\n",
    "\t\t\t\t'scene_id': scene_id,\n",
    "\t\t\t\t'phi': cal_density(initial_scene, grid_size),\n",
    "\t\t\t\t'num_objects': num_objects,\n",
    "\t\t\t\t'grid_size': grid_size,\n",
    "\t\t\t\t'objects': objs\n",
    "\t\t\t}\n",
    "\t\telse:\n",
    "\t\t\tjson_scene = {\n",
    "\t\t\t\t'scene_id': scene_id,\n",
    "\t\t\t\t'phi': cal_density(initial_scene, grid_size),\n",
    "\t\t\t\t'ratio': ratio,\n",
    "\t\t\t\t'num_objects': num_objects,\n",
    "\t\t\t\t'grid_size': grid_size,\n",
    "\t\t\t\t'objects': objs\n",
    "\t\t\t}\n",
    "\n",
    "\t\t# Save the scene in a json file\n",
    "\t\twith open(f'{dir_path}/scene_{scene_id}.json', 'w') as f:\n",
    "\t\t\tjson.dump(json_scene, f, indent=4)\n",
    "\t\t\n",
    "\t\tif verbose > 0:\n",
    "\t\t\tprint(f'Saved {dir_path}/scene_{scene_id}.json')\n",
    "\n",
    "def scene_json_to_graph(json_scene):\n",
    "\tnum_nodes = json_scene['num_objects']\n",
    "\n",
    "\tx_initial = torch.tensor([\n",
    "\t\t[obj['label'], *obj['size'], *obj['initial_pos'], *obj['initial_relation']]\n",
    "\t\tfor obj in json_scene['objects']\n",
    "\t], dtype=torch.float32)\n",
    "\tedge_index = x_to_edge_index(x_initial)\n",
    "\tinitial_graph = Data(x=x_initial, edge_index=edge_index, pos=get_node_poses(num_nodes))\n",
    "\n",
    "\tx_target = torch.tensor([\n",
    "\t\t[obj['label'], *obj['size'], *obj['target_pos'], *obj['target_relation']]\n",
    "\t\tfor obj in json_scene['objects']\n",
    "\t], dtype=torch.float32)\n",
    "\tedge_index = x_to_edge_index(x_target)\n",
    "\ttarget_graph = Data(x=x_target, edge_index=edge_index, pos=get_node_poses(num_nodes))\n",
    "\n",
    "\treturn initial_graph, target_graph\n",
    "\n",
    "def load_json_scenes(num_objects, grid_size, phi, ratio=0.5):\n",
    "\tscenes = []\n",
    "\tif ratio == 0.5:\n",
    "\t\tdir_path = f'scenes/phi_{phi}/g{grid_size[0]}.{grid_size[1]}/n{num_objects}'\n",
    "\telse:\n",
    "\t\tdir_path = f'scenes/phi_{phi}/r_{ratio}/g{grid_size[0]}.{grid_size[1]}/n{num_objects}'\n",
    "\n",
    "\tfor filename in os.listdir(dir_path):\n",
    "\t\tif not filename.endswith('.json'):\n",
    "\t\t\tcontinue\n",
    "\t\t\n",
    "\t\twith open(os.path.join(dir_path, filename), 'r') as f:\n",
    "\t\t\tscene = json.load(f)\n",
    "\t\t\n",
    "\t\tscenes.append(scene)\n",
    "\t\n",
    "\t# Sort the scenes by id\n",
    "\tscenes.sort(key=lambda x: x['scene_id'])\n",
    "\t\n",
    "\treturn scenes\n",
    "\n",
    "def load_scenes(num_objects, grid_size, phi, ratio=0.5):\n",
    "\tscenes = []\n",
    "\n",
    "\tjson_scenes = load_json_scenes(num_objects, grid_size, phi, ratio=ratio)\n",
    "\tfor json_scene in json_scenes:\n",
    "\t\tinitial_graph, target_graph = scene_json_to_graph(json_scene)\n",
    "\t\tscenes.append({\n",
    "\t\t\t'initial_scene': initial_graph,\n",
    "\t\t\t'target_scene': target_graph\n",
    "\t\t})\n",
    "\n",
    "\treturn scenes\n",
    "\n",
    "def plot_characteristics(ax, runs, key, title=\"\"):\n",
    "\txtics = []\n",
    "\tfor run in runs:\n",
    "\t\tx_axis = range(1, len(run['runs'])+1)\n",
    "\t\ty_axis = [run[key] for run in run['runs']]\n",
    "\t\tax.plot(x_axis, y_axis, label=f\"{run['num_objects']}n_{run['grid_size']}g\")\n",
    "\t\tif len(xtics) < len(x_axis):\n",
    "\t\t\txtics = x_axis\n",
    "\t\n",
    "\tax.set_xticks(xtics)\n",
    "\tax.set_title(title)\n",
    "\tax.set_xlabel('Samples')\n",
    "\tif key == 'elapsed_time':\n",
    "\t\tax.set_ylabel(f'Time elapsed (s)')\n",
    "\telse:\n",
    "\t\tax.set_ylabel(f'{key}')\n",
    "\tax.legend()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create scenes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_complexities_kde(values: dict, title='', figsize=(8, 3)):\n",
    "\tplt.figure(figsize=figsize)\n",
    "\tfor key in values.keys():\n",
    "\t\tsns.kdeplot(values[key], label=f'n = {key}')\n",
    "\t\n",
    "\tplt.title(title)\n",
    "\tplt.xlabel('Density')\n",
    "\tplt.ylabel('Frequency')\n",
    "\tplt.xlim(0.0, 1)\n",
    "\tplt.legend()\n",
    "\tplt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "\tplt.tight_layout()\n",
    "\tplt.show()\n",
    "\n",
    "def plot_complexities_hist(values: dict, title='', figsize=(5, 2)):\n",
    "\tnum_plots = len(values)\n",
    "\tfig, axes = plt.subplots(num_plots, 1, figsize=(figsize[0], figsize[1] * num_plots)) # Adjust figure size\n",
    "\n",
    "\tfor i, key in enumerate(values.keys()):\n",
    "\t\tax = axes[i] if num_plots > 1 else axes # Handle single plot case\n",
    "\t\tsns.histplot(values[key], bins=30, kde=True, ax=ax)\n",
    "\t\t# sns.kdeplot(values[key], ax=ax)\n",
    "\t\tax.set_title(f'n = {key}')\n",
    "\t\tax.set_xlabel('Density')\n",
    "\t\tax.set_xlim(0.0, 0.6)\n",
    "\t\tax.set_ylabel('Frequency')\n",
    "\t\tax.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "\n",
    "\tplt.suptitle(title)\n",
    "\tplt.tight_layout() # Improves subplot spacing\n",
    "\tplt.show()\n",
    "\n",
    "num_cases = 10\n",
    "n_values = [3, 4, 5, 6, 7, 8]\n",
    "\n",
    "phi = 0.2\n",
    "ratio = 0.5\n",
    "grid_size = (100, 100)\n",
    "\n",
    "densities = {}\n",
    "for num_objects in n_values:\n",
    "\tprint(f'--n: {num_objects}--')\n",
    "\tscenes = make_scenes(num_cases, num_objects, grid_size, phi, ratio)\n",
    "\tsave_scenes(scenes, num_objects, grid_size, phi, ratio, verbose=1)\n",
    "\tscenes = load_scenes(num_objects, grid_size, phi, ratio)\n",
    "\tdensities[num_objects] =[]\n",
    "\tfor i, scene in enumerate(scenes):\n",
    "\t\tdensities[num_objects].append(cal_density(scene['initial_scene'], grid_size))\n",
    "\n",
    "# plot_complexities_kde(densities, title=f'size = {grid_size} | φ = {phi}')\n",
    "# plot_complexities_hist(densities, title=f'size = {grid_size} | φ = {phi}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_runs(json_scenes, env, phi, ratio, alg, file_name, num_runs=1, **kwargs):\n",
    "\tif ratio == 0.5:\n",
    "\t\tdir_path = f'runs/phi_{phi}/{env.mode}/g{env.grid_size[0]}.{env.grid_size[1]}/n{env.num_objects}'\n",
    "\telse:\n",
    "\t\tdir_path = f'runs/phi_{phi}/{env.mode}/r_{ratio}/g{env.grid_size[0]}.{env.grid_size[1]}/n{env.num_objects}'\n",
    "\tos.makedirs(dir_path, exist_ok=True)\n",
    "\t\n",
    "\tdata_path = os.path.join(dir_path, f'{file_name}.csv')\n",
    "\n",
    "\tfile_exists = os.path.exists(data_path)\n",
    "\tif file_exists:\n",
    "\t\tdf = pd.read_csv(data_path, converters={\n",
    "\t\t\t'plans': eval, 'steps': eval,\n",
    "\t\t\t'elapsed_times': eval, 'costs': eval\n",
    "\t\t})\n",
    "\telse:\n",
    "\t\tdf = pd.DataFrame()\n",
    "\n",
    "\tprint(f'----{alg.__name__}:{file_name}----')\n",
    "\ttotal_runs = len(json_scenes) * num_runs\n",
    "\tpbar = tqdm(total=total_runs, unit='run')\n",
    "\n",
    "\tfor scene_idx, json_scene in enumerate(json_scenes):\n",
    "\t\tscene_id = json_scene['scene_id']\n",
    "\t\talready_num_runs = 0\n",
    "\t\tremaining_num_runs = num_runs\n",
    "\t\tif file_exists and scene_id in df['scene_id'].values:\n",
    "\t\t\tidx = df.index[df['scene_id'] == scene_id][0]\n",
    "\t\t\talready_num_runs = len(df.at[idx, 'plans'])\n",
    "\t\t\tremaining_num_runs = num_runs - already_num_runs\n",
    "\t\t\tpbar.update(already_num_runs)\n",
    "\t\t\tif remaining_num_runs <= 0:\n",
    "\t\t\t\tpbar.set_description(f'Skipping scene {scene_id} - already solved {already_num_runs} times')\n",
    "\t\t\t\tcontinue\n",
    "\n",
    "\t\tfor run_idx in range(1, remaining_num_runs + 1):\n",
    "\t\t\tpbar.set_description(f'Scene {scene_idx}/{len(json_scenes)} - Run {run_idx+already_num_runs}/{num_runs}')\n",
    "\n",
    "\t\t\tinitial_scene, target_scene = scene_json_to_graph(json_scene)\n",
    "\t\t\tenv.reset(initial_scene, target_scene)\n",
    "\t\t\tplan, step, elapsed_time = alg(env).solve(**kwargs)\n",
    "\t\t\tcost = env_cost(env, plan, initial_scene, target_scene, log=False)\n",
    "\n",
    "\t\t\tif file_exists and scene_id in df['scene_id'].values:\n",
    "\t\t\t\tidx = df.index[df['scene_id'] == scene_id][0]\n",
    "\t\t\t\tdf.at[idx, 'plans'] += [plan]\n",
    "\t\t\t\tdf.at[idx, 'steps'] += [step]\n",
    "\t\t\t\tdf.at[idx, 'elapsed_times'] += [elapsed_time]\n",
    "\t\t\t\tdf.at[idx, 'costs'] += [cost]\n",
    "\t\t\telse:\n",
    "\t\t\t\tnew_row = pd.DataFrame([{\n",
    "\t\t\t\t\t'scene_id': scene_id,\n",
    "\t\t\t\t\t'mode': env.mode,\n",
    "\t\t\t\t\t'n': json_scene['num_objects'],\n",
    "\t\t\t\t\t'grid_size': json_scene['grid_size'],\n",
    "\t\t\t\t\t'alg': file_name,\n",
    "\t\t\t\t\t'plans': [plan],\n",
    "\t\t\t\t\t'steps': [step],\n",
    "\t\t\t\t\t'elapsed_times': [elapsed_time],\n",
    "\t\t\t\t\t'costs': [cost],\n",
    "\t\t\t\t}])\n",
    "\t\t\t\tdf = pd.concat([df, new_row], ignore_index=True)\n",
    "\n",
    "\t\t\t# Sort and save\n",
    "\t\t\tdf = df.sort_values(by='scene_id').reset_index(drop=True)\n",
    "\t\t\tdf.to_csv(data_path, index=False)\n",
    "\t\t\tfile_exists = True\n",
    "\n",
    "\t\t\tpbar.update(1)\n",
    "\t\tpbar.set_description(f'Scene {scene_idx}/{len(json_scenes)} - Run {run_idx+already_num_runs}/{num_runs}')\n",
    "\t\t\n",
    "\tpbar.close()\n",
    "\n",
    "phi = 0.2\n",
    "ratio = 0.5\n",
    "num_runs = 1\n",
    "time_limit = 500\n",
    "grid_size = (100, 100)\n",
    "mode = 'stationary'\n",
    "\n",
    "# for num_objects in [3, 4]:\n",
    "# \tenv = ContinuousEnv(mode=mode, num_objects=num_objects, grid_size=grid_size, verbose=0)\n",
    "# \tjson_scenes = load_json_scenes(num_objects, grid_size, phi, ratio)\n",
    "# \tsave_runs(json_scenes, env, phi, ratio, Labbe, \"Labbe\", num_runs=num_runs, c=0.1, time_limit=time_limit)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Labbe Tunning\n",
    "grid_size = (100, 100)\n",
    "mode = 'stationary'\n",
    "num_runs = 5\n",
    "for num_objects in [3, 4, 5, 6, 7, 8]:\n",
    "\tprint(f'--n: {num_objects}--')\n",
    "\tenv = ContinuousEnv(mode=mode, num_objects=num_objects, grid_size=grid_size, verbose=0)\n",
    "\tjson_scenes = load_json_scenes(num_objects, grid_size, phi)\n",
    "\tsave_runs(json_scenes, env, phi, Labbe, \"Labbe-c.0\", num_runs=num_runs, c=0, time_limit=time_limit)\n",
    "\tsave_runs(json_scenes, env, phi, LabbeS, \"LabbeS-c.0\", num_runs=num_runs, c=0, time_limit=time_limit)\n",
    "\tsave_runs(json_scenes, env, phi, Labbe, \"Labbe-c.2\", num_runs=num_runs, c=0.2, time_limit=time_limit)\n",
    "\tsave_runs(json_scenes, env, phi, LabbeS, \"LabbeS-c.2\", num_runs=num_runs, c=0.2, time_limit=time_limit)\n",
    "\tsave_runs(json_scenes, env, phi, Labbe, \"Labbe-c.8\", num_runs=num_runs, c=0.8, time_limit=time_limit)\n",
    "\tsave_runs(json_scenes, env, phi, LabbeS, \"LabbeS-c.8\", num_runs=num_runs, c=0.8, time_limit=time_limit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_objects = 3\n",
    "env = ContinuousEnv(mode=mode, num_objects=num_objects, grid_size=grid_size, phi=phi, verbose=0)\n",
    "json_scenes = load_json_scenes(num_objects, grid_size, phi, ratio)\n",
    "save_runs(json_scenes, env, phi, ratio, Labbe, \"Labbe\", num_runs=num_runs, c=0.1, time_limit=time_limit)\n",
    "save_runs(json_scenes, env, phi, ratio, LabbeS, \"LabbeS\", num_runs=num_runs, c=0.1, time_limit=time_limit)\n",
    "save_runs(json_scenes, env, phi, ratio, StrapGA, \"StrapGA\", num_runs=num_runs, num_buffers=4, time_limit=time_limit)\n",
    "save_runs(json_scenes, env, phi, ratio, A_starGA, \"A_starGA\", num_runs=num_runs, num_buffers=4, time_limit=time_limit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_objects = 4\n",
    "env = ContinuousEnv(mode=mode, num_objects=num_objects, grid_size=grid_size, phi=phi, verbose=0)\n",
    "json_scenes = load_json_scenes(num_objects, grid_size, phi, ratio)\n",
    "save_runs(json_scenes, env, phi, ratio, Labbe, \"Labbe\", num_runs=num_runs, c=0.5, time_limit=time_limit)\n",
    "save_runs(json_scenes, env, phi, ratio, LabbeS, \"LabbeS\", num_runs=num_runs, c=0.5, time_limit=time_limit)\n",
    "save_runs(json_scenes, env, phi, ratio, StrapGA, \"StrapGA\", num_runs=num_runs, num_buffers=4, time_limit=time_limit)\n",
    "save_runs(json_scenes, env, phi, ratio, A_starGA, \"A_starGA\", num_runs=num_runs, num_buffers=4, time_limit=time_limit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_objects = 5\n",
    "env = ContinuousEnv(mode=mode, num_objects=num_objects, grid_size=grid_size, phi=phi, verbose=0)\n",
    "json_scenes = load_json_scenes(num_objects, grid_size, phi, ratio)\n",
    "save_runs(json_scenes, env, phi, ratio, Labbe, \"Labbe\", num_runs=num_runs, c=0.5, time_limit=time_limit)\n",
    "save_runs(json_scenes, env, phi, ratio, LabbeS, \"LabbeS\", num_runs=num_runs, c=0.5, time_limit=time_limit)\n",
    "save_runs(json_scenes, env, phi, ratio, StrapGA, \"StrapGA\", num_runs=num_runs, num_buffers=4, time_limit=time_limit)\n",
    "save_runs(json_scenes, env, phi, ratio, A_starGA, \"A_starGA\", num_runs=num_runs, num_buffers=4, time_limit=time_limit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_objects = 6\n",
    "env = ContinuousEnv(mode=mode, num_objects=num_objects, grid_size=grid_size, phi=phi, verbose=0)\n",
    "json_scenes = load_json_scenes(num_objects, grid_size, phi, ratio)\n",
    "save_runs(json_scenes, env, phi, ratio, Labbe, \"Labbe\", num_runs=num_runs, c=0.5, time_limit=time_limit)\n",
    "save_runs(json_scenes, env, phi, ratio, LabbeS, \"LabbeS\", num_runs=num_runs, c=0.5, time_limit=time_limit)\n",
    "save_runs(json_scenes, env, phi, ratio, StrapGA, \"StrapGA\", num_runs=num_runs, num_buffers=4, time_limit=time_limit)\n",
    "save_runs(json_scenes, env, phi, ratio, A_starGA, \"A_starGA\", num_runs=num_runs, num_buffers=4, time_limit=time_limit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_objects = 7\n",
    "env = ContinuousEnv(mode=mode, num_objects=num_objects, grid_size=grid_size, phi=phi, verbose=0)\n",
    "json_scenes = load_json_scenes(num_objects, grid_size, phi, ratio)\n",
    "save_runs(json_scenes, env, phi, ratio, Labbe, \"Labbe\", num_runs=num_runs, c=0.5, time_limit=time_limit)\n",
    "save_runs(json_scenes, env, phi, ratio, LabbeS, \"LabbeS\", num_runs=num_runs, c=0.5, time_limit=time_limit)\n",
    "save_runs(json_scenes, env, phi, ratio, StrapGA, \"StrapGA\", num_runs=num_runs, num_buffers=4, time_limit=time_limit)\n",
    "save_runs(json_scenes, env, phi, ratio, A_starGA, \"A_starGA\", num_runs=num_runs, num_buffers=4, time_limit=time_limit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_objects = 8\n",
    "env = ContinuousEnv(mode=mode, num_objects=num_objects, grid_size=grid_size, phi=phi, verbose=0)\n",
    "json_scenes = load_json_scenes(num_objects, grid_size, phi, ratio)\n",
    "save_runs(json_scenes, env, phi, ratio, Labbe, \"Labbe\", num_runs=num_runs, c=0.5, time_limit=time_limit)\n",
    "save_runs(json_scenes, env, phi, ratio, LabbeS, \"LabbeS\", num_runs=num_runs, c=0.5, time_limit=time_limit)\n",
    "save_runs(json_scenes, env, phi, ratio, StrapGA, \"StrapGA\", num_runs=num_runs, num_buffers=4, time_limit=time_limit)\n",
    "save_runs(json_scenes, env, phi, ratio, A_starGA, \"A_starGA\", num_runs=num_runs, num_buffers=4, time_limit=time_limit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas.api.types import CategoricalDtype\n",
    "\n",
    "def load_runs(mode, grid_size, algs, n_values, phi, runs_dir='runs'):\n",
    "\tall_dfs = []\n",
    "\n",
    "\tfor num_objects in n_values:\n",
    "\t\tfor alg_name in algs:\n",
    "\t\t\tfilename = f'{runs_dir}/phi_{phi}/{mode}/g{grid_size[0]}.{grid_size[1]}/n{num_objects}/{alg_name}.csv'\n",
    "\t\t\tif not os.path.isfile(filename):\n",
    "\t\t\t\tcontinue\n",
    "\t\t\t\n",
    "\t\t\t# Read CSV\n",
    "\t\t\tdf = pd.read_csv(filename)\n",
    "\n",
    "\t\t\t# calculate the mean not-None costs\n",
    "\t\t\tdf['cost'] = df['costs'].apply(lambda x: np.mean([cost for cost in eval(x) if cost is not None]) if isinstance(eval(x), list) else np.nan)\n",
    "\t\t\tdf['step'] = df['steps'].apply(lambda x: np.mean([step for step in eval(x)]))\n",
    "\t\t\tdf['elapsed_time'] = df['elapsed_times'].apply(lambda x: np.mean([time for time in eval(x)]))\n",
    "\n",
    "\t\t\tall_dfs.append(df)\n",
    "\n",
    "\t# Merge all into one big DataFrame\n",
    "\tif all_dfs:\n",
    "\t\tmerged_df = pd.concat(all_dfs, ignore_index=True)\n",
    "\t\treturn merged_df\n",
    "\telse:\n",
    "\t\tprint(\"No valid run files found.\")\n",
    "\t\treturn pd.DataFrame()  # Return empty DF if nothing was loaded\n",
    "\n",
    "def compare_algs(df, figsize=(10, 4), std=False, sr=False, step=False, title=''):\n",
    "\tif df.empty:\n",
    "\t\tprint(\"No data to compare.\")\n",
    "\n",
    "\t# Filter only valid rows (cost not null = successful run)\n",
    "\tdf['success'] = df['cost'].notna()\n",
    "\n",
    "\t# Preserve algorithm order as they appear in the dataframe\n",
    "\talg_order = df['alg'].drop_duplicates().tolist()\n",
    "\talg_dtype = CategoricalDtype(categories=alg_order, ordered=True)\n",
    "\tdf['alg'] = df['alg'].astype(alg_dtype)\n",
    "\t\n",
    "\t# Group by n and alg\n",
    "\tgrouped = df.groupby(['n', 'alg'])\n",
    "\n",
    "\t# Aggregated metrics\n",
    "\tagg_df = grouped.agg(\n",
    "\t\tcost_mean=('cost', 'mean'),\n",
    "\t\tcost_std=('cost', 'std'),\n",
    "\t\tstep_mean=('step', 'mean'),\n",
    "\t\tstep_std=('step', 'std'),\n",
    "\t\ttime_mean=('elapsed_time', 'mean'),\n",
    "\t\ttime_std=('elapsed_time', 'std'),\n",
    "\t\tsuccess_rate=('success', lambda x: 100 * x.sum() / len(x))\n",
    "\t).reset_index()\n",
    "\n",
    "\t# Ensure algorithm column stays ordered\n",
    "\tagg_df['alg'] = agg_df['alg'].astype(alg_dtype)\n",
    "\n",
    "\t# Pivot with ordered columns\n",
    "\tcost_mean_pivot = agg_df.pivot(index='n', columns='alg', values='cost_mean')[alg_order]\n",
    "\tstep_mean_pivot = agg_df.pivot(index='n', columns='alg', values='step_mean')[alg_order]\n",
    "\ttime_mean_pivot = agg_df.pivot(index='n', columns='alg', values='time_mean')[alg_order]\n",
    "\n",
    "\tcost_std_pivot = agg_df.pivot(index='n', columns='alg', values='cost_std')[alg_order] if std else None\n",
    "\tstep_std_pivot = agg_df.pivot(index='n', columns='alg', values='step_std')[alg_order] if std else None\n",
    "\ttime_std_pivot = agg_df.pivot(index='n', columns='alg', values='time_std')[alg_order] if std else None\n",
    "\n",
    "\t# Plot\n",
    "\tsns.set_style('whitegrid')\n",
    "\tif sr and step:\n",
    "\t\tfig, axs = plt.subplots(1, 4, figsize=figsize)\n",
    "\telif sr or step:\n",
    "\t\tfig, axs = plt.subplots(1, 3, figsize=figsize)\n",
    "\telse:\n",
    "\t\tfig, axs = plt.subplots(1, 2, figsize=figsize)\n",
    "\n",
    "\tplot_bars(cost_mean_pivot, 'Cost Comparison', 'Cost', std_data=cost_std_pivot, ax=axs[0], cmap=colormaps['tab20b'])\n",
    "\tplot_bars(time_mean_pivot, 'Time Comparison', 'Time (log scale)', std_data=time_std_pivot, log_scale=True, ax=axs[1], cmap=colormaps['tab20b'])\n",
    "\tif sr and step:\n",
    "\t\tsr_pivot = agg_df.pivot(index='n', columns='alg', values='success_rate') if sr else None\n",
    "\t\tplot_bars(step_mean_pivot, 'Step Comparison', 'Step', std_data=step_std_pivot, ax=axs[2], cmap=colormaps['tab20b'])\n",
    "\t\tplot_bars(sr_pivot, 'Success Rate', 'Success Rate (%)', ax=axs[3], cmap=colormaps['tab20b'])\n",
    "\telif sr:\n",
    "\t\tsr_pivot = agg_df.pivot(index='n', columns='alg', values='success_rate') if sr else None\n",
    "\t\tplot_bars(sr_pivot, 'Success Rate', 'Success Rate (%)', ax=axs[2], cmap=colormaps['tab20b'])\n",
    "\telif step:\n",
    "\t\tplot_bars(step_mean_pivot, 'Step Comparison', 'Step', std_data=step_std_pivot, ax=axs[2], cmap=colormaps['tab20b'])\n",
    "\t\n",
    "\tfig.suptitle(title, fontsize=16)\n",
    "\tplt.tight_layout()\n",
    "\tplt.show()\n",
    "\n",
    "def plot_bars(df, title, ylabel, std_data=None, log_scale=False, ax=None, cmap=colormaps['tab20b']):\n",
    "\tif ax is None:\n",
    "\t\tfig, ax = plt.subplots(figsize=(6, 4))\n",
    "\n",
    "\tn_values = df.index.tolist()\n",
    "\talgs = df.columns.tolist()\n",
    "\tx = np.arange(len(n_values))\n",
    "\tbar_width = 0.1\n",
    "\n",
    "\tcolors = [cmap(i / len(algs)) for i in range(len(algs))]\n",
    "\n",
    "\tfor i, alg in enumerate(algs):\n",
    "\t\tvalues = df[alg].values\n",
    "\t\terrors = std_data[alg].values if std_data is not None and alg in std_data.columns else None\n",
    "\t\tif alg == 'Labbe':\n",
    "\t\t\tlabel = 'MCTS'\n",
    "\t\telif alg == 'LabbeS':\n",
    "\t\t\tlabel = 'MCTS+Stack'\n",
    "\t\telif alg == 'A_star':\n",
    "\t\t\tlabel = 'Strap+Stack'\n",
    "\t\telif alg == 'A_starGA':\n",
    "\t\t\tlabel = 'StrapGA+Stack'\n",
    "\t\telse:\n",
    "\t\t\tlabel = alg\n",
    "\n",
    "\t\tax.bar(x + i * bar_width, values, width=bar_width, color=colors[i], label=label, yerr=errors, capsize=5 if errors is not None else 0)\n",
    "\n",
    "\tax.set_xlabel('Number of Objects (n)')\n",
    "\tax.set_ylabel(ylabel)\n",
    "\tax.set_title(title)\n",
    "\tax.set_xticks(x + bar_width * (len(algs) - 1) / 2)\n",
    "\tax.set_xticklabels(n_values)\n",
    "\tax.legend(title='Algorithm')\n",
    "\n",
    "\tif log_scale:\n",
    "\t\tax.set_yscale('log')\n",
    "\n",
    "\tax.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "\n",
    "phi = 0.2\n",
    "algs = [\"Labbe\", \"A_starGA\", \"StrapGA\"]\n",
    "n_values = [3, 4, 5, 6, 7, 8]\n",
    "grid_size = (100, 100)\n",
    "mode = 'stationary'\n",
    "df = load_runs(mode, grid_size, algs, n_values, phi, runs_dir='runs1')\n",
    "compare_algs(df, figsize=(16, 4), sr=True, title=f'{mode} | size = {grid_size} | φ = {phi}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_label_pct(scene_id, scene_dir):\n",
    "    \"\"\"\n",
    "    Load scene_{scene_id}.json and return the percentage of objects \n",
    "    whose label is in {3,4,5,6}.\n",
    "    \"\"\"\n",
    "    path = os.path.join(scene_dir, f\"scene_{scene_id}.json\")\n",
    "    with open(path, 'r') as f:\n",
    "        scene = json.load(f)\n",
    "    labels = [obj['label'] for obj in scene['objects']]\n",
    "    count_special = sum(1 for L in labels if L in [8 ,9 ,10])\n",
    "    return 100.0 * count_special / scene['num_objects']\n",
    "\n",
    "def add_label_pct_column(df, scene_dir, grid_size, phi):\n",
    "    \"\"\"\n",
    "    Given runs‐df with a 'scene_id' column, add a 'label_pct' column.\n",
    "    \"\"\"\n",
    "    def pct_for(row):\n",
    "        sid = row['scene_id']\n",
    "        n = row['n']\n",
    "        return compute_label_pct(sid, f'{scene_dir}/phi_{phi}/g{grid_size[0]}.{grid_size[0]}/n{n}')\n",
    "    \n",
    "    df['label_pct'] = df.apply(pct_for, axis=1)\n",
    "    return df\n",
    "\n",
    "df = load_runs(mode, grid_size, algs, n_values, phi, runs_dir='runs1')\n",
    "df = add_label_pct_column(df, 'scenes1', grid_size, phi)\n",
    "df['label_pct_bin'] = df['label_pct'].apply(\n",
    "    lambda x: '< 25%' if x < 25 else '25–50%' if x < 50 else '50–75%' if x < 75 else '> 75%'\n",
    ")\n",
    "# for bin_label in ['< 25%', '25–50%', '50–75%', '> 75%']:\n",
    "# \tsub_df = df[df['label_pct_bin'] == bin_label].copy()\n",
    "# \tcompare_algs(sub_df, figsize=(10, 4), sr=False, title=f'{bin_label} | {mode} | size = {grid_size} | φ = {phi}')\n",
    "\n",
    "# Aggregated metrics\n",
    "agg_df = df.groupby(['n', 'label_pct_bin', 'alg']).agg(\n",
    "\tcost_mean=('cost', 'mean'),\n",
    ").reset_index()\n",
    "\n",
    "# Pivot to have algorithms as columns so we can compute the difference\n",
    "pivot_df = agg_df.pivot_table(\n",
    "    index=['n', 'label_pct_bin'], \n",
    "    columns='alg', \n",
    "    values='cost_mean'\n",
    ").reset_index()\n",
    "\n",
    "# Compute the cost difference\n",
    "pivot_df['diff_cost'] = pivot_df['A_starGA'] - pivot_df['StrapGA']\n",
    "pivot_df = pivot_df[['n', 'label_pct_bin', 'diff_cost']]\n",
    "\n",
    "# Optional: ensure bins are plotted in logical order\n",
    "bin_order = ['< 25%', '25–50%', '50–75%', '> 75%']\n",
    "pivot_df['label_pct_bin'] = pd.Categorical(pivot_df['label_pct_bin'], categories=bin_order, ordered=True)\n",
    "\n",
    "# Pivot the data for plotting: rows = label_pct_bin, columns = n, values = diff_cost\n",
    "plot_df = pivot_df.pivot(\n",
    "    index='n', \n",
    "    columns='label_pct_bin', \n",
    "    values='diff_cost'\n",
    ")\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(8, 5))\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "for n in plot_df.columns:\n",
    "    plt.plot(plot_df.index, plot_df[n], marker='o', label=f'n = {n}')\n",
    "\n",
    "plt.title('Cost Difference (A_starGA - StrapGA) by Label Percentage Bin')\n",
    "plt.xlabel('Label Percentage Bin')\n",
    "plt.ylabel('Cost Difference')\n",
    "plt.legend(title='Number of Objects (n)')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "np.unique(df['label_pct'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('my_dataframe.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
