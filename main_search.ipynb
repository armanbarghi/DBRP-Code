{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import time\n",
    "import heapq\n",
    "import random\n",
    "import itertools\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm, colormaps\n",
    "import pickle\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "import seaborn as sns\n",
    "from torch_geometric.data import Data\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "import networkx as nx\n",
    "\n",
    "from env.graph_env import plot_graph, copy_graph, Indices, GraphEnv, is_stable, in_table_index\n",
    "from env.graph_env import create_graph, create_graph_label, create_graph_label_continuous"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def copy_state(state):\n",
    "\treturn {'graph': copy_graph(state['graph']), 'manipulator': state['manipulator'].clone()}\n",
    "\n",
    "def flatten_pos(pos, grid_size):\n",
    "\treturn int(pos[0] * grid_size + pos[1])\n",
    "\n",
    "def unflatten_pos(pos, grid_size):\n",
    "\treturn torch.tensor([pos // grid_size, pos % grid_size], dtype=torch.float32)\n",
    "\n",
    "def is_empty_object(graph, node):\n",
    "\treturn find_start_node(graph, node) is None\n",
    "\n",
    "def is_edge_in_graph(graph, node1, node2):\n",
    "\tif graph.x[node1, Indices.RELATION.start + node2] == 0:\n",
    "\t\treturn False\n",
    "\treturn True\n",
    "\n",
    "def find_target_node(graph, node):\n",
    "\ti = (graph.x[node, Indices.RELATION] == 1).nonzero(as_tuple=True)[0]\n",
    "\tif len(i):\n",
    "\t\treturn i.item()\n",
    "\treturn None\n",
    "\n",
    "def find_start_node(graph, node):\n",
    "\ti = (graph.x[:, Indices.RELATION.start + node] == 1).nonzero(as_tuple=True)[0]\n",
    "\tif len(i):\n",
    "\t\treturn i.item()\n",
    "\treturn None\n",
    "\n",
    "def find_base_node(graph, node):\n",
    "\twhile graph.x[node, Indices.RELATION].sum() != 0:\n",
    "\t\tnode = find_target_node(graph, node)\n",
    "\treturn node\n",
    "\n",
    "def find_occupying_nodes(table, coor, size):\n",
    "\toccupying_nodes = []\n",
    "\tunique_nodes = np.unique(table[in_table_index(coor, size)])\n",
    "\tfor node in unique_nodes:\n",
    "\t\tif node == 0:\n",
    "\t\t\tcontinue\n",
    "\t\toccupying_nodes.append(node-1)\n",
    "\n",
    "\treturn occupying_nodes\n",
    "\n",
    "def get_empty_objects(env, ref_node, n=1):\n",
    "\tall_objects = list(range(env.num_nodes))\n",
    "\trandom.shuffle(all_objects)\n",
    "\tempty_objects = []\n",
    "\tfor obj in all_objects:\n",
    "\t\tif is_empty_object(env.state_graph, obj) and is_stable(env.state_graph.x, ref_node, obj):\n",
    "\t\t\tempty_objects.append(obj)\n",
    "\t\t\tif len(empty_objects) >= n:\n",
    "\t\t\t\tbreak\n",
    "\treturn empty_objects\n",
    "\n",
    "def get_all_positions_of_object(coord, size):\n",
    "    idx = in_table_index(coord, size)\n",
    "    x_range = np.arange(idx[0].start, idx[0].stop)\n",
    "    y_range = np.arange(idx[1].start, idx[1].stop)\n",
    "    x, y = np.meshgrid(x_range, y_range, indexing='ij')\n",
    "    return np.column_stack((x.ravel(), y.ravel()))\n",
    "\n",
    "def get_all_positions_in_env(grid_size, size):\n",
    "    x_range = np.arange(size[0] // 2, grid_size - size[0] // 2)\n",
    "    y_range = np.arange(size[1] // 2, grid_size - size[1] // 2)\n",
    "    x, y = np.meshgrid(x_range, y_range, indexing='ij')\n",
    "    return np.column_stack((x.ravel(), y.ravel()))\n",
    "\n",
    "def get_empty_positions1(env, ref_node, n=1):\n",
    "\tall_positions = get_all_positions_in_env(env.grid_size, env.get_obj_size(ref_node))\n",
    "\n",
    "\trandom.shuffle(all_positions)\n",
    "\n",
    "\tpositions = []\n",
    "\tfor position in all_positions:\n",
    "\t\tposition = torch.tensor(position, dtype=torch.float32)\n",
    "\t\tif not env.is_coor_occupied(position, ref_node):\n",
    "\t\t\tpositions.append(flatten_pos(position, env.grid_size))\n",
    "\t\t\tif len(positions) >= n:\n",
    "\t\t\t\tbreak\n",
    "\t\t\t\n",
    "\treturn positions\n",
    "\n",
    "def get_empty_positions(env, ref_node, n=1):\n",
    "\tall_positions = get_all_positions_in_env(env.grid_size, env.get_obj_size(ref_node))\n",
    "\n",
    "\t# Sample random positions instead of shuffling the entire list\n",
    "\trandom_indices = random.sample(range(len(all_positions)), len(all_positions))\n",
    "\tsampled_positions = (all_positions[i] for i in random_indices)\n",
    "\n",
    "\t# Use a generator to find the first `n` unoccupied positions\n",
    "\tpositions = []\n",
    "\tfor position in sampled_positions:\n",
    "\t\tposition = torch.tensor(position, dtype=torch.float32)\n",
    "\t\tif not env.is_coor_occupied(position, ref_node):\n",
    "\t\t\tpositions.append(flatten_pos(position, env.grid_size))\n",
    "\t\t\tif len(positions) >= n:\n",
    "\t\t\t\tbreak\n",
    "\n",
    "\treturn positions\n",
    "\n",
    "def draw_dependency_graph(env):\n",
    "\tdependency_graph = nx.DiGraph()\n",
    "\tfor k in range(env.num_nodes):\n",
    "\t\tdependency_graph.add_node(k)\n",
    "\t\ti = find_target_node(env.target_graph, k)\n",
    "\t\tif i is None:\n",
    "\t\t\tj = find_target_node(env.state_graph, k)\n",
    "\t\t\tTk = env.target_graph.x[k, Indices.COORD]\n",
    "\t\t\tCK = env.state_graph.x[k, Indices.COORD]\n",
    "\t\t\tif torch.equal(CK, Tk):\n",
    "\t\t\t\tif j is not None:\n",
    "\t\t\t\t\tdependency_graph.add_edge(k, j)\n",
    "\t\t\t\t\twhile env.state_graph.x[j, Indices.RELATION].sum() != 0:\n",
    "\t\t\t\t\t\tj = find_target_node(env.state_graph, j)\n",
    "\t\t\t\t\t\tif j is None:\n",
    "\t\t\t\t\t\t\tbreak\n",
    "\t\t\t\t\t\tdependency_graph.add_edge(k, j)\n",
    "\t\t\telse:\n",
    "\t\t\t\tsize = env.get_obj_size(k)\n",
    "\t\t\t\toccupying_nodes = find_occupying_nodes(env.table, Tk, size)\n",
    "\t\t\t\tfor j in occupying_nodes:\n",
    "\t\t\t\t\tif j != k:\n",
    "\t\t\t\t\t\tj = find_base_node(env.state_graph, j)\n",
    "\t\t\t\t\t\t# if the k,j pair is not in the dependency graph\n",
    "\t\t\t\t\t\tif not dependency_graph.has_edge(k, j):\n",
    "\t\t\t\t\t\t\tdependency_graph.add_edge(k, j)\n",
    "\t\telse:\n",
    "\t\t\tj = find_start_node(env.state_graph, i)\n",
    "\t\t\tif j is not None and j != k:\n",
    "\t\t\t\tdependency_graph.add_edge(k, j)\n",
    "\n",
    "\tfig, ax = plt.subplots(1, 1, figsize=(2.5, 2.5))\n",
    "\tnx.draw(dependency_graph, env.state_graph.pos, with_labels=True, node_size=400, ax=ax, node_color='skyblue')\n",
    "\tplt.title('Dependency Graph')\n",
    "\tplt.show()\n",
    "\n",
    "def evaluate_alg(env, alg, initial_graph, target_graph, **kwargs):\n",
    "\tenv.reset(initial_graph, target_graph)\n",
    "\tstart = time.time()\n",
    "\tprint(f\"--------{alg.__name__}--------\")\n",
    "\toptimal_actions, steps = alg(env).solve(**kwargs)\n",
    "\telapsed_time = time.time() - start\n",
    "\tprint(f'optimal_actions: {optimal_actions} in {steps} steps')\n",
    "\tprint(f'elapsed time: {elapsed_time:.2f}s')\n",
    "\tif optimal_actions is not None:\n",
    "\t\tenv_cost(env, optimal_actions, initial_graph, target_graph)\n",
    "\treturn optimal_actions\n",
    "\n",
    "def env_cost(env, actions, initial_graph, target_graph, log=True):\n",
    "\tenv.reset(initial_graph, target_graph)\n",
    "\tep_cost = 0\n",
    "\tfor action in actions:\n",
    "\t\tcost, _ = env.step_cost(action, log=log)\n",
    "\t\tep_cost += cost\n",
    "\tif log:\n",
    "\t\tprint(f'episode cost: {ep_cost:.3f}')\n",
    "\tenv.reset(initial_graph, target_graph)\n",
    "\treturn ep_cost\n",
    "\n",
    "def positional_encode(one_hot_position):\n",
    "\tpositions = torch.argmax(one_hot_position, dim=1)\n",
    "\tencodings = torch.zeros((len(positions), 1))\n",
    "\n",
    "\tfor i, position in enumerate(positions):\n",
    "\t\tif torch.sum(one_hot_position[i]) == 0:\n",
    "\t\t\tencodings[i] = -1\n",
    "\t\telse:\n",
    "\t\t\tencodings[i] = position\n",
    "\n",
    "\treturn encodings\n",
    "\n",
    "def state_to_hashable(state):\n",
    "\tif hasattr(Indices, 'LABEL'):\n",
    "\t\tnew_state = torch.cat([state['graph'].x[:, Indices.LABEL], state['graph'].x[:, Indices.COORD], positional_encode(state['graph'].x[:, Indices.RELATION])], dim=1)\n",
    "\telse:\n",
    "\t\tnew_state = torch.cat([state['graph'].x[:, Indices.COORD], positional_encode(state['graph'].x[:, Indices.RELATION])], dim=1)\n",
    "\treturn tuple(state['manipulator'].numpy().tolist() + new_state.view(-1).tolist())\n",
    "\n",
    "def reconstruct_path(node):\n",
    "    path = []\n",
    "    while node.parent is not None:\n",
    "        path.append(node.action)\n",
    "        node = node.parent\n",
    "    path.reverse()\n",
    "    return path\n",
    "\n",
    "def cal_density(env):\n",
    "    phi = np.sum([env.get_obj_size(i)[0] * env.get_obj_size(i)[1] for i in range(env.num_nodes)])\n",
    "    return phi / (env.grid_size * env.grid_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Env_Manipulator(GraphEnv):\n",
    "\tdef __init__(self, verbose=1, **kwargs):\n",
    "\t\tsuper().__init__(**kwargs)\n",
    "\t\tself.manipulator_initial_pos = torch.tensor([(self.grid_size-1)/2, (self.grid_size-1)/2], dtype=torch.float32)\n",
    "\t\tself.normalization_factor = 1 / ( (self.grid_size - 1) * np.sqrt(self.grid_size - 1) )\n",
    "\t\tself.manipulator = self.manipulator_initial_pos.clone()\n",
    "\t\tself.pp_cost = 1 / (self.grid_size - 1)\n",
    "\t\tself.verbose = verbose\n",
    "\n",
    "\tdef create_graph(self):\n",
    "\t\treturn create_graph(self.num_nodes, self.grid_size)\n",
    "\t\n",
    "\tdef _get_obs(self):\n",
    "\t\treturn {'graph': copy_graph(self.state_graph), 'manipulator': self.manipulator.clone()}\n",
    "\t\n",
    "\tdef set_state(self, state):\n",
    "\t\tself.state_graph = state['graph']\n",
    "\t\tself.manipulator = state['manipulator']\n",
    "\n",
    "\tdef get_state(self):\n",
    "\t\treturn self._get_obs()\n",
    "\n",
    "\tdef reset(self, state_graph=None, target_graph=None):\n",
    "\t\tsuper().reset(state_graph, target_graph)\n",
    "\t\tself.manipulator = self.manipulator_initial_pos.clone()\n",
    "\t\treturn self._get_obs(), {}\n",
    "\t\n",
    "\tdef render(self):\n",
    "\t\tif self.verbose > 0 and self.mode == 'manipulator':\n",
    "\t\t\tprint(f'Manipulator: {self.manipulator.numpy()}')\n",
    "\t\treturn super().render()\n",
    "\n",
    "\tdef punish_cost(self):\n",
    "\t\treturn 100\n",
    "\n",
    "\tdef cal_movement(self, pre_coord, new_coord):\n",
    "\t\ttotal_movement = 0\n",
    "\t\ttotal_movement += torch.norm(new_coord - pre_coord)  \t\t\t# movement distance\n",
    "\t\tif self.mode == 'manipulator':\n",
    "\t\t\ttotal_movement += torch.norm(pre_coord - self.manipulator) \t\t# manipulator to object distance\n",
    "\t\t\tself.manipulator = new_coord.clone()\n",
    "\t\treturn total_movement * self.normalization_factor\n",
    "\t \n",
    "\tdef get_valid_actions(self):\n",
    "\t\tvalid_actions = []\n",
    "\t\tfor i in range(self.num_nodes):\n",
    "\t\t\tfor j in range(self.num_nodes):\n",
    "\t\t\t\tif i != j and not self.is_in_state_graph(i, j) and not self.is_in_state_graph(j, i):\n",
    "\t\t\t\t\t\tvalid_actions.append(self.encode_action('on', i, j, 0))\n",
    "\n",
    "\t\t\tfor j in range(self.grid_size * self.grid_size):\n",
    "\t\t\t\tif not self.is_coor_occupied(unflatten_pos(j, self.grid_size)):\n",
    "\t\t\t\t\tvalid_actions.append(self.encode_action('move', i, i, j))\n",
    "\t\t\n",
    "\t\t# return range(self.ACTION_SPACE_SIZE)\n",
    "\t\treturn valid_actions\n",
    "\n",
    "\tdef move_node_with_parents(self, node, coordinates):\n",
    "\t\tn = self.state_graph.num_nodes\n",
    "\t\t# Find all parents of the node and their parents recursively and move them\n",
    "\t\tvisited = [False] * n\n",
    "\t\tvisited[node] = True\n",
    "\t\tstack = [node]\n",
    "\t\twhile len(stack) > 0:\n",
    "\t\t\tnode = stack.pop()\n",
    "\t\t\tself.state_graph.x[node, Indices.COORD] = coordinates.clone()\n",
    "\t\t\ti = find_start_node(self.state_graph, node)\n",
    "\t\t\tif i is not None and not visited[i]:\n",
    "\t\t\t\tstack.append(i)\n",
    "\t\t\t\tvisited[i] = True\n",
    "\t\n",
    "\tdef move_func(self, start_node, coordinates):\n",
    "\t\tif self.is_coor_occupied(coordinates):\n",
    "\t\t\tcost = self.punish_cost()\n",
    "\t\t\tpass\n",
    "\t\telse:\n",
    "\t\t\tprev_target = self.find_connected_node(start_node)\n",
    "\t\t\tif prev_target is not None:\n",
    "\t\t\t\tself.remove_edge(start_node, prev_target)\n",
    "\t\t\tprev_coord = self.state_graph.x[start_node, Indices.COORD].clone()\n",
    "\t\t\tself.move_node_with_parents(start_node, coordinates)\n",
    "\t\t\tcost = self.cal_movement(prev_coord, coordinates)\n",
    "\t\treturn cost\n",
    "\t\n",
    "\tdef stack_func(self, start_node, target_node):\n",
    "\t\tif self.is_in_state_graph(target_node, start_node):\n",
    "\t\t\tcost = self.punish_cost()\n",
    "\t\t\tpass\n",
    "\t\telse:\n",
    "\t\t\tprev_target = self.find_connected_node(start_node)\n",
    "\t\t\tif prev_target == target_node:\n",
    "\t\t\t\tcost = self.punish_cost()\n",
    "\t\t\t\tpass\n",
    "\t\t\telif self.check_loop_by_replacing_edge(start_node, prev_target, target_node):\n",
    "\t\t\t\tcost = self.punish_cost()\n",
    "\t\t\t\tpass\n",
    "\t\t\telif prev_target is None:\n",
    "\t\t\t\tprev_coord = self.state_graph.x[start_node, Indices.COORD].clone()\n",
    "\t\t\t\tself.add_edge(start_node, target_node)\n",
    "\t\t\t\tcost = self.cal_movement(prev_coord, self.state_graph.x[target_node, Indices.COORD])\n",
    "\t\t\telse:\n",
    "\t\t\t\tprev_coord = self.state_graph.x[start_node, Indices.COORD].clone()\n",
    "\t\t\t\tself.remove_edge(start_node, prev_target)\n",
    "\t\t\t\tself.add_edge(start_node, target_node)\n",
    "\t\t\t\tcost = self.cal_movement(prev_coord, self.state_graph.x[target_node, Indices.COORD])\n",
    "\t\treturn cost\n",
    "\n",
    "\tdef step_move(self, node, coordinates, log=True):\n",
    "\t\tcoordinates = coordinates[0] * self.grid_size + coordinates[1]\n",
    "\t\taction = self.encode_action('move', node, node, coordinates)\n",
    "\t\treturn self.step_cost(action, log)\n",
    "\n",
    "\tdef step_on(self, start_node, target_node, log=True):\n",
    "\t\taction = self.encode_action('on', start_node, target_node, 0)\n",
    "\t\treturn self.step_cost(action, log)\n",
    "\n",
    "\tdef step_cost(self, action, log=False):\n",
    "\t\taction_type, start_node, target_node, coordinates = self.decode_action(action)\n",
    "\t\treturn self._step_cost(action_type, start_node, target_node, coordinates, log=log)\n",
    "\n",
    "\tdef _step_cost(self, action_type, start_node, target_node, coordinates, log=False):\n",
    "\t\tcoordinates = unflatten_pos(coordinates, self.grid_size)\n",
    "\t\tcost, truncated, terminated = 0.0, False, False\n",
    "\n",
    "\t\t# self.steps += 1\n",
    "\t\t# if self.steps >= self.max_steps:\n",
    "\t\t# \ttruncated = True\n",
    "\n",
    "\t\tif action_type == 'move':\n",
    "\t\t\tcost += self.move_func(start_node, coordinates)\n",
    "\t\telif action_type == 'on':\n",
    "\t\t\tcost += self.stack_func(start_node, target_node)\n",
    "\t\t\t\n",
    "\t\tcost += self.pp_cost\n",
    "\t\t\n",
    "\t\tif self.is_terminal_state():\n",
    "\t\t\tif self.mode == 'manipulator':\n",
    "\t\t\t\t# return to initial position\n",
    "\t\t\t\tcost += torch.norm(self.manipulator - self.manipulator_initial_pos) * self.normalization_factor\n",
    "\t\t\t\tself.manipulator = self.manipulator_initial_pos.clone()\n",
    "\t\t\tterminated = True\n",
    "\t\n",
    "\t\tif log:\n",
    "\t\t\tif action_type == 'move':\n",
    "\t\t\t\tprint(f'Moved {start_node} to: {coordinates.numpy()} | cost: {cost:.3f} | done: {terminated or truncated}')\n",
    "\t\t\telse:\n",
    "\t\t\t\tprint(f'{start_node} -> {target_node} | cost: {cost:.3f} | done: {terminated or truncated}')\n",
    "\n",
    "\t\treturn cost, self.get_state()\n",
    "\t\n",
    "\tdef normalize_cost(self, cost):\n",
    "\t\tif self.mode == 'manipulator':\n",
    "\t\t\t# sqrt(2) for moving manipulator from a corner to the other corner where the object is\n",
    "\t\t\t# sqrt(2) for moving manipulator from the object to its target corner\n",
    "\t\t\t# sqrt(2)/2 for moving manipulator from the corner to the center\n",
    "\t\t\treturn cost / (2.5*np.sqrt(2) + self.pp_cost)\n",
    "\t\telse:\n",
    "\t\t\t# sqrt(2) for moving the object from a corner to the other corner\n",
    "\t\t\treturn cost / (1 + self.pp_cost)\n",
    "\n",
    "class Env_Man_Label(Env_Manipulator):\n",
    "\tdef __init__(self, num_labels, **kwargs):\n",
    "\t\tself.num_labels = num_labels\n",
    "\t\tsuper().__init__(**kwargs)\n",
    "\n",
    "\tdef create_graph(self, labels=None, stack=True):\n",
    "\t\tif stack:\n",
    "\t\t\treturn create_graph_label(self.num_nodes, self.grid_size, self.num_labels, labels, p=0.9)\n",
    "\t\telse:\n",
    "\t\t\treturn create_graph_label(self.num_nodes, self.grid_size, self.num_labels, labels, p=0.0)\n",
    "\n",
    "\tdef reset(self, state_graph=None, target_graph=None, stack=True):\n",
    "\t\tself.steps = 0\n",
    "\t\tself.state_graph = self.create_graph(stack=stack) if state_graph is None else copy_graph(state_graph)\n",
    "\t\tself.initial_graph = copy_graph(self.state_graph)\n",
    "\t\tlabels = list(self.state_graph.x[:, Indices.LABEL].reshape(-1).numpy())\n",
    "\t\tlabels = list(map(int, labels))\n",
    "\t\tif target_graph is None:\n",
    "\t\t\tself.target_graph = self.create_graph(labels, stack=stack)\n",
    "\t\t\twhile torch.equal(self.state_graph.x, self.target_graph.x):\n",
    "\t\t\t\tself.target_graph = self.create_graph(labels, stack=stack)\n",
    "\t\telse:\n",
    "\t\t\tself.target_graph = copy_graph(target_graph)\n",
    "\t\t\ttarget_labels = list(self.target_graph.x[:, Indices.LABEL].reshape(-1).numpy())\n",
    "\t\t\ttarget_labels = list(map(int, target_labels))\n",
    "\t\t\t# check whether the target graph has the same labels as the state graph\n",
    "\t\t\tif labels != target_labels:\n",
    "\t\t\t\traise ValueError('Target graph has different labels than the state graph')\n",
    "\n",
    "\t\tif stack is False:\n",
    "\t\t\tfor i in range(self.num_nodes):\n",
    "\t\t\t\tif torch.sum(self.state_graph.x[i, Indices.RELATION]) > 0:\n",
    "\t\t\t\t\traise ValueError('Initial graph has edges in Non-stack mode')\n",
    "\t\t\t\tif torch.sum(self.target_graph.x[i, Indices.RELATION]) > 0:\n",
    "\t\t\t\t\traise ValueError('Target graph has edges in Non-stack mode')\n",
    "\t\t\t\n",
    "\t\tself.manipulator = self.manipulator_initial_pos.clone()\n",
    "\t\tinfo = {}\n",
    "\t\treturn self._get_obs(), info\n",
    "\n",
    "\tdef plot_graph(self, graph, ax=None, fig_size=2.5, title=None):\n",
    "\t\tif ax is None:\n",
    "\t\t\tfig, ax = plt.subplots(1, 1, figsize=(fig_size, fig_size))\n",
    "\t\t\n",
    "\t\t# Grid dots\n",
    "\t\tfor i in range(self.grid_size):\n",
    "\t\t\tfor j in range(self.grid_size):\n",
    "\t\t\t\tax.plot(j, i, 'k.', markersize=1)\n",
    "\n",
    "\t\t# Create a graph and add nodes with positions\n",
    "\t\tnx_graph = nx.Graph()\n",
    "\t\tfor i in range(graph.num_nodes):\n",
    "\t\t\tpos = graph.x[i, Indices.COORD].numpy()\n",
    "\t\t\tnx_graph.add_node(i, pos=[pos[1], self.grid_size - 1 - pos[0]])\n",
    "\n",
    "\t\t# Node categorization\n",
    "\t\tlabel_categories = {\n",
    "\t\t\t4: {'nodes': [i for i in range(graph.num_nodes) if graph.x[i, Indices.LABEL].item() == 4], \n",
    "\t\t\t\t'color': 'blue', 'shape': 's', 'size': 1300},\n",
    "\t\t\t3: {'nodes': [i for i in range(graph.num_nodes) if graph.x[i, Indices.LABEL].item() == 3], \n",
    "\t\t\t\t'color': 'green', 'shape': 's', 'size': 500, 'alpha': 0.7},\n",
    "\t\t\t2: {'nodes': [i for i in range(graph.num_nodes) if graph.x[i, Indices.LABEL].item() == 2], \n",
    "\t\t\t\t'color': 'green', 'shape': 's', 'size': 500, 'alpha': 0.7},\n",
    "\t\t\t1: {'nodes': [i for i in range(graph.num_nodes) if graph.x[i, Indices.LABEL].item() == 1], \n",
    "\t\t\t\t'color': 'orange', 'shape': 'o', 'size': 100, 'alpha': 0.7},\n",
    "\t\t\t0: {'nodes': [i for i in range(graph.num_nodes) if graph.x[i, Indices.LABEL].item() == 0], \n",
    "\t\t\t\t'color': 'yellow', 'shape': 'o', 'size': 100, 'alpha': 0.7},\n",
    "\t\t}\n",
    "\n",
    "\t\t# Define node sizes dynamically\n",
    "\t\tnode_sizes = {i: label_categories[label]['size'] for label in label_categories for i in label_categories[label]['nodes']}\n",
    "\n",
    "\t\t# Dynamic label position based on node size\n",
    "\t\tpos = nx.get_node_attributes(nx_graph, 'pos')\n",
    "\t\tlabel_pos = {k: (v[0], v[1] + node_sizes[k] * 0.00055 / fig_size) for k, v in pos.items()}\n",
    "\n",
    "\t\t# Loop through label categories to draw nodes\n",
    "\t\tfor label, properties in label_categories.items():\n",
    "\t\t\tnx.draw_networkx_nodes(\n",
    "\t\t\t\tnx_graph,\n",
    "\t\t\t\tpos,\n",
    "\t\t\t\tnodelist=properties['nodes'],\n",
    "\t\t\t\tnode_color=properties['color'],\n",
    "\t\t\t\tnode_shape=properties['shape'],\n",
    "\t\t\t\tnode_size=properties['size'],\n",
    "\t\t\t\talpha=properties.get('alpha', 1.0),  # Default alpha is 1.0 if not specified\n",
    "\t\t\t\tax=ax\n",
    "\t\t\t)\n",
    "\n",
    "\t\t# Draw node labels dynamically adjusted to node size\n",
    "\t\tnode_indices = {i: str(i) for i in range(graph.num_nodes)}\n",
    "\t\tnx.draw_networkx_labels(nx_graph, label_pos, labels=node_indices, font_size=6.5, font_weight='bold', ax=ax)\n",
    "\n",
    "\t\t# Additional node for fitting the nx_graph in the plot\n",
    "\t\tnx_graph = nx.Graph()\n",
    "\t\tnx_graph.add_node(0, pos=[-0.3, -0.3])\n",
    "\t\tnx_graph.add_node(1, pos=[self.grid_size-0.7, self.grid_size-0.7])\n",
    "\t\tnx.draw(nx_graph, nx.get_node_attributes(nx_graph, 'pos'), ax=ax, node_size=0)\n",
    "\n",
    "\t\tif title is not None:\n",
    "\t\t\tax.set_title(title)\n",
    "\n",
    "\tdef render(self, with_target=True, fig_size=2.5, return_fig=False):\n",
    "\t\tif with_target:\n",
    "\t\t\tfig, ax = plt.subplots(1, 2, figsize=(fig_size * 2, fig_size))\n",
    "\t\t\tself.plot_graph(self.state_graph, ax=ax[0], fig_size=fig_size, title='State Scene')\n",
    "\t\t\tself.plot_graph(self.target_graph, ax=ax[1], fig_size=fig_size, title='Target Scene')\n",
    "\t\telse:\n",
    "\t\t\tfig, ax = plt.subplots(1, 1, figsize=(fig_size, fig_size))\n",
    "\t\t\tself.plot_graph(self.state_graph, ax=ax, fig_size=fig_size, title='State Scene')\n",
    "\n",
    "\t\tif return_fig:\n",
    "\t\t\tplt.close()\n",
    "\t\t\treturn fig\n",
    "\t\telse:\n",
    "\t\t\tplt.show()\n",
    "\n",
    "\tdef get_valid_actions(self):\n",
    "\t\tvalid_actions = []\n",
    "\t\tfor i in range(self.num_nodes):\n",
    "\t\t\tfor j in range(self.num_nodes):\n",
    "\t\t\t\tif i != j and not self.is_in_state_graph(i, j):\n",
    "\t\t\t\t\tif is_stable(self.state_graph.x, i, j):\n",
    "\t\t\t\t\t\tif torch.sum(self.state_graph.x[:, Indices.RELATION.start+j]) == 0:\n",
    "\t\t\t\t\t\t\tvalid_actions.append(self.encode_action('on', i, j, 0))\n",
    "\n",
    "\t\t\tif torch.equal(self.state_graph.x[i, Indices.COORD], self.target_graph.x[i, Indices.COORD]):\n",
    "\t\t\t\tcontinue\n",
    "\t\t\t\n",
    "\t\t\tfree_positions = []\n",
    "\t\t\tfor j in range(self.grid_size * self.grid_size):\n",
    "\t\t\t\tposition = unflatten_pos(j, self.grid_size)\n",
    "\t\t\t\tif not self.is_coor_occupied(position):\n",
    "\t\t\t\t\tdist_to_curr = torch.norm(self.state_graph.x[i, Indices.COORD] - position)\n",
    "\t\t\t\t\tdist_to_target = torch.norm(self.target_graph.x[i, Indices.COORD] - position)\n",
    "\t\t\t\t\tfree_positions.append({\n",
    "\t\t\t\t\t\t'position': j,\n",
    "\t\t\t\t\t\t'distance': torch.min(dist_to_curr, dist_to_target)\n",
    "\t\t\t\t\t})\n",
    "\t\t\t\n",
    "\t\t\t# sort free_positions by distance\n",
    "\t\t\tfree_positions = sorted(free_positions, key=lambda x: x['distance'])\n",
    "\t\t\t\n",
    "\t\t\t# add the closest positions\n",
    "\t\t\tfor j in range(min(3, len(free_positions))):\n",
    "\t\t\t\tvalid_actions.append(self.encode_action('move', i, i, free_positions[j]['position']))\n",
    "\t\t\t\tif free_positions[j]['distance'] == 0:\n",
    "\t\t\t\t\tbreak\n",
    "\t\t\n",
    "\t\t# return range(self.ACTION_SPACE_SIZE)\n",
    "\t\treturn valid_actions\n",
    "\t\n",
    "\tdef stack_func(self, start_node, target_node):\n",
    "\t\tif self.is_in_state_graph(target_node, start_node):\n",
    "\t\t\tcost = self.punish_cost()\n",
    "\t\t\tpass\n",
    "\t\telif not is_stable(self.state_graph.x, start_node, target_node):\n",
    "\t\t\tcost = self.punish_cost()\n",
    "\t\t\tpass\n",
    "\t\telse:\n",
    "\t\t\tprev_target = self.find_connected_node(start_node)\n",
    "\t\t\tif prev_target == target_node:\n",
    "\t\t\t\tcost = self.punish_cost()\n",
    "\t\t\t\tpass\n",
    "\t\t\telif self.check_loop_by_replacing_edge(start_node, prev_target, target_node):\n",
    "\t\t\t\tcost = self.punish_cost()\n",
    "\t\t\t\tpass\n",
    "\t\t\telif prev_target is None:\n",
    "\t\t\t\tprev_coord = self.state_graph.x[start_node, Indices.COORD].clone()\n",
    "\t\t\t\tself.add_edge(start_node, target_node)\n",
    "\t\t\t\tcost = self.cal_movement(prev_coord, self.state_graph.x[target_node, Indices.COORD])\n",
    "\t\t\telse:\n",
    "\t\t\t\tprev_coord = self.state_graph.x[start_node, Indices.COORD].clone()\n",
    "\t\t\t\tself.remove_edge(start_node, prev_target)\n",
    "\t\t\t\tself.add_edge(start_node, target_node)\n",
    "\t\t\t\tcost = self.cal_movement(prev_coord, self.state_graph.x[target_node, Indices.COORD])\n",
    "\t\treturn cost\n",
    "\n",
    "class ContinuousEnv(Env_Man_Label):\n",
    "\tOBJECT_SIZES = {\n",
    "\t\t0: (5, 5),\n",
    "\t\t1: (5, 5),\n",
    "\t\t2: (3, 3),\n",
    "\t\t3: (3, 3),\n",
    "\t\t4: (7, 7),\n",
    "\t}\n",
    "\tdef __init__(self, mode='manipulator', **kwargs):\n",
    "\t\tsuper().__init__(**kwargs)\n",
    "\t\tself.mode = mode\n",
    "\t\tself.normalization_factor = 1 / self.grid_size\n",
    "\t\t# self.normalization_factor = 1\n",
    "\t\tself.pp_cost = 0.2\n",
    "\t\tif self.verbose == 1:\n",
    "\t\t\tprint(f'Mode is {self.mode}')\n",
    "\n",
    "\tdef create_graph(self, labels=None, stack=True, ratio=0.5):\n",
    "\t\tif stack:\n",
    "\t\t\treturn create_graph_label_continuous(self.num_nodes, self.grid_size, self.num_labels, self.OBJECT_SIZES, labels, p=0.9, ratio=ratio)\n",
    "\t\telse:\n",
    "\t\t\treturn create_graph_label_continuous(self.num_nodes, self.grid_size, self.num_labels, self.OBJECT_SIZES, labels, p=0.0, ratio=ratio)\n",
    "\n",
    "\tdef make_table(self, state_graph=None):\n",
    "\t\tif state_graph is None:\n",
    "\t\t\tstate_graph = self.state_graph\n",
    "\n",
    "\t\tself.table = np.zeros((self.grid_size, self.grid_size), dtype=int)\n",
    "\t\tfor i in range(self.num_nodes):\n",
    "\t\t\tif state_graph.x[i, Indices.RELATION].sum() > 0:\n",
    "\t\t\t\tcontinue\n",
    "\t\t\tcoor = state_graph.x[i, Indices.COORD].numpy()\n",
    "\t\t\tsize = self.get_obj_size(i)\n",
    "\t\t\tself.table[in_table_index(coor, size)] = i+1\n",
    "\n",
    "\tdef make_target_table(self):\n",
    "\t\tself.target_table = np.zeros((self.grid_size, self.grid_size), dtype=int)\n",
    "\t\tfor i in range(self.num_nodes):\n",
    "\t\t\tif self.target_graph.x[i, Indices.RELATION].sum() > 0:\n",
    "\t\t\t\tcontinue\n",
    "\t\t\tcoor = self.target_graph.x[i, Indices.COORD].numpy()\n",
    "\t\t\tsize = self.get_obj_size(i)\n",
    "\t\t\tself.target_table[in_table_index(coor, size)] = i+1\n",
    "\n",
    "\tdef reset(self, state_graph=None, target_graph=None, stack=True, ratio=0.5):\n",
    "\t\tself.steps = 0\n",
    "\t\tself.state_graph = self.create_graph(stack=stack, ratio=ratio) if state_graph is None else copy_graph(state_graph)\n",
    "\t\tself.initial_graph = copy_graph(self.state_graph)\n",
    "\t\tlabels = list(self.state_graph.x[:, Indices.LABEL].reshape(-1).numpy())\n",
    "\t\tlabels = list(map(int, labels))\n",
    "\t\tif target_graph is None:\n",
    "\t\t\tself.target_graph = self.create_graph(labels, stack=stack, ratio=1-ratio)\n",
    "\t\t\twhile torch.equal(self.state_graph.x, self.target_graph.x):\n",
    "\t\t\t\tself.target_graph = self.create_graph(labels, stack=stack, ratio=1-ratio)\n",
    "\t\telse:\n",
    "\t\t\tself.target_graph = copy_graph(target_graph)\n",
    "\t\t\ttarget_labels = list(self.target_graph.x[:, Indices.LABEL].reshape(-1).numpy())\n",
    "\t\t\ttarget_labels = list(map(int, target_labels))\n",
    "\t\t\t# check whether the target graph has the same labels as the state graph\n",
    "\t\t\tif labels != target_labels:\n",
    "\t\t\t\traise ValueError('Target graph has different labels than the state graph')\n",
    "\n",
    "\t\tif stack is False:\n",
    "\t\t\tfor i in range(self.num_nodes):\n",
    "\t\t\t\tif torch.sum(self.state_graph.x[i, Indices.RELATION]) > 0:\n",
    "\t\t\t\t\traise ValueError('Initial graph has edges in Non-stack mode')\n",
    "\t\t\t\tif torch.sum(self.target_graph.x[i, Indices.RELATION]) > 0:\n",
    "\t\t\t\t\traise ValueError('Target graph has edges in Non-stack mode')\n",
    "\t\t\t\n",
    "\t\tself.manipulator = self.manipulator_initial_pos.clone()\n",
    "\t\t\n",
    "\t\tself.make_table()\n",
    "\t\tself.make_target_table()\n",
    "\t\treturn self._get_obs(), {}\n",
    "\n",
    "\tdef plot_graph(self, graph, ax=None, fig_size=2.5, title=None):\n",
    "\t\tif ax is None:\n",
    "\t\t\tfig, ax = plt.subplots(1, 1, figsize=(fig_size, fig_size))\n",
    "\n",
    "\t\t# Create a color grid based on the labels and the color dictionary\n",
    "\t\tcolor_by_label = {\n",
    "\t\t\t0: 'yellow',\n",
    "\t\t\t1: 'orange',\n",
    "\t\t\t2: 'green',\n",
    "\t\t\t3: 'green',\n",
    "\t\t\t4: 'blue',\n",
    "\t\t}\n",
    "\t\tcolors = ['white'] + list(color_by_label.values())\n",
    "\n",
    "\t\t# Map the table values to colormap indices\n",
    "\t\tmapped_table = np.zeros((self.grid_size, self.grid_size), dtype=int)\n",
    "\t\tunrendered_nodes = list(range(self.num_nodes))\n",
    "\t\tlabels = []\n",
    "\t\twhile len(unrendered_nodes) > 0:\n",
    "\t\t\ti = unrendered_nodes.pop(0)\n",
    "\t\t\tcoor = graph.x[i, Indices.COORD].numpy()\n",
    "\t\t\tsize = self.get_obj_size(i)\n",
    "\t\t\tif graph.x[i, Indices.RELATION].sum() > 0:\n",
    "\t\t\t\tchild = find_target_node(graph, i)\n",
    "\t\t\t\tif child in unrendered_nodes:\n",
    "\t\t\t\t\tunrendered_nodes.append(i)\n",
    "\t\t\t\t\tcontinue\n",
    "\t\t\t\tif graph.x[i, Indices.LABEL].item() == 0 and graph.x[child, Indices.LABEL].item() in [2, 3]:\n",
    "\t\t\t\t\tsize = (1, 1)\n",
    "\t\t\tmapped_table[in_table_index(coor, size)] = graph.x[i, Indices.LABEL].item() + 1\n",
    "\t\t\tlabels.append(int(graph.x[i, Indices.LABEL].item()))\n",
    "\t\t\n",
    "\t\t# find unique labels\n",
    "\t\tcolors = colors[:max(labels)+2]\n",
    "\t\tcmap = ListedColormap(colors)\n",
    "\n",
    "\t\t# Plot the table\n",
    "\t\tax.imshow(mapped_table, cmap=cmap, origin='upper')\n",
    "\n",
    "\t\t# Add gridlines for better visualization\n",
    "\t\tax.set_xticks(np.arange(-0.5, self.grid_size, 1), minor=True)\n",
    "\t\tax.set_yticks(np.arange(-0.5, self.grid_size, 1), minor=True)\n",
    "\t\tax.grid(which='minor', color='gray', linestyle='-', linewidth=0.2)\n",
    "\t\tax.tick_params(which='minor', bottom=False, left=False)\n",
    "\n",
    "\t\t# Remove major ticks\n",
    "\t\tax.set_xticks([])\n",
    "\t\tax.set_yticks([])\n",
    "\n",
    "\t\t# Add labels to cells for clarity\n",
    "\t\tfor i in range(self.num_nodes):\n",
    "\t\t\tcoor = graph.x[i, Indices.COORD].numpy()\n",
    "\t\t\tsize = self.get_obj_size(i)\n",
    "\t\t\tif graph.x[i, Indices.RELATION].sum() > 0:\n",
    "\t\t\t\tchild = find_target_node(graph, i)\n",
    "\t\t\t\tif graph.x[i, Indices.LABEL].item() == 0 and graph.x[child, Indices.LABEL].item() in [2, 3]:\n",
    "\t\t\t\t\tsize = (1, 1)\n",
    "\t\t\tax.text(coor[1]-size[1]//2, coor[0]-size[0]//2, str(i), ha='center', va='center', color='black')\n",
    "\t\t\n",
    "\t\tif title is not None:\n",
    "\t\t\tax.set_title(title)\n",
    "\n",
    "\tdef plot_graph2(self, graph, ax=None, fig_size=2.5, title=None, constraints=[]):\n",
    "\t\tif ax is None:\n",
    "\t\t\tfig, ax = plt.subplots(1, 1, figsize=(fig_size, fig_size))\n",
    "\n",
    "\t\t# Create a color grid based on the labels and the color dictionary\n",
    "\t\tcolor_by_label = {\n",
    "\t\t\t0: 'yellow',\n",
    "\t\t\t1: 'orange',\n",
    "\t\t\t2: 'green',\n",
    "\t\t\t3: 'green',\n",
    "\t\t\t4: 'blue',\n",
    "\t\t}\n",
    "\t\tif len(constraints) > 0:\n",
    "\t\t\tcolor_by_label[5] = 'red'\n",
    "\t\tcolors = ['white'] + list(color_by_label.values())\n",
    "\n",
    "\t\t# Map the table values to colormap indices\n",
    "\t\tmapped_table = np.zeros((self.grid_size, self.grid_size), dtype=int)\n",
    "\t\tunrendered_nodes = list(range(self.num_nodes))\n",
    "\t\tlabels = []\n",
    "\t\twhile len(unrendered_nodes) > 0:\n",
    "\t\t\ti = unrendered_nodes.pop(0)\n",
    "\t\t\tcoor = graph.x[i, Indices.COORD].numpy()\n",
    "\t\t\tsize = self.get_obj_size(i)\n",
    "\t\t\tif graph.x[i, Indices.RELATION].sum() > 0:\n",
    "\t\t\t\tchild = find_target_node(graph, i)\n",
    "\t\t\t\tif child in unrendered_nodes:\n",
    "\t\t\t\t\tunrendered_nodes.append(i)\n",
    "\t\t\t\t\tcontinue\n",
    "\t\t\t\tif graph.x[i, Indices.LABEL].item() == 0 and graph.x[child, Indices.LABEL].item() in [2, 3]:\n",
    "\t\t\t\t\tsize = (1, 1)\n",
    "\t\t\tmapped_table[in_table_index(coor, size)] = graph.x[i, Indices.LABEL].item() + 1\n",
    "\t\t\tlabels.append(int(graph.x[i, Indices.LABEL].item()))\n",
    "\t\t\n",
    "\t\tfor i in range(len(constraints)):\n",
    "\t\t\t# rand_x, rand_y = np.random.randint(0, self.grid_size, size=2)\n",
    "\t\t\t# if the type of constraints is tensor, convert it to int\n",
    "\t\t\tif isinstance(constraints[i], torch.Tensor):\n",
    "\t\t\t\tcons1traints = constraints[i].numpy()\n",
    "\t\t\telse:\n",
    "\t\t\t\tcons1traints = constraints[i]\n",
    "\t\t\tcons1traints = list(map(int, cons1traints))\n",
    "\t\t\trand_x, rand_y = cons1traints\n",
    "\t\t\tmapped_table[rand_x, rand_y] = max(labels) + 2  # Assign a new value for the new color\n",
    "\t\n",
    "\t\t# find unique labels\n",
    "\t\tif len(constraints) > 0:\n",
    "\t\t\tcolors = colors[:max(labels)+3]\n",
    "\t\telse:\n",
    "\t\t\tcolors = colors[:max(labels)+2]\n",
    "\t\tcmap = ListedColormap(colors)\n",
    "\n",
    "\t\t# Plot the table\n",
    "\t\tax.imshow(mapped_table, cmap=cmap, origin='upper')\n",
    "\n",
    "\t\t# Add gridlines for better visualization\n",
    "\t\tax.set_xticks(np.arange(-0.5, self.grid_size, 1), minor=True)\n",
    "\t\tax.set_yticks(np.arange(-0.5, self.grid_size, 1), minor=True)\n",
    "\t\tax.grid(which='minor', color='gray', linestyle='-', linewidth=0.2)\n",
    "\t\tax.tick_params(which='minor', bottom=False, left=False)\n",
    "\n",
    "\t\t# Remove major ticks\n",
    "\t\tax.set_xticks([])\n",
    "\t\tax.set_yticks([])\n",
    "\n",
    "\t\t# Add labels to cells for clarity\n",
    "\t\tfor i in range(self.num_nodes):\n",
    "\t\t\tcoor = graph.x[i, Indices.COORD].numpy()\n",
    "\t\t\tsize = self.get_obj_size(i)\n",
    "\t\t\tif graph.x[i, Indices.RELATION].sum() > 0:\n",
    "\t\t\t\tchild = find_target_node(graph, i)\n",
    "\t\t\t\tif graph.x[i, Indices.LABEL].item() == 0 and graph.x[child, Indices.LABEL].item() in [2, 3]:\n",
    "\t\t\t\t\tsize = (1, 1)\n",
    "\t\t\tax.text(coor[1]-size[1]//2, coor[0]-size[0]//2, str(i), ha='center', va='center', color='black')\n",
    "\t\t\n",
    "\t\tif title is not None:\n",
    "\t\t\tax.set_title(title)\n",
    "\n",
    "\tdef is_in_env(self, coor, size):\n",
    "\t\tif coor[0] - size[0]//2 < 0 or coor[0] + size[0]//2 >= self.grid_size:\n",
    "\t\t\treturn False\n",
    "\t\tif coor[1] - size[1]//2 < 0 or coor[1] + size[1]//2 >= self.grid_size:\n",
    "\t\t\treturn False\n",
    "\t\treturn True\n",
    "\n",
    "\tdef is_coor_occupied(self, coor, node, table=None):\n",
    "\t\tif table is None:\n",
    "\t\t\ttable = self.table\n",
    "\t\t\n",
    "\t\tsize = self.get_obj_size(node)\n",
    "\t\tif torch.equal(coor, self.state_graph.x[node, Indices.COORD]):\n",
    "\t\t\treturn True\n",
    "\t\tif coor[0] - size[0]//2 < 0 or coor[0] + size[0]//2 >= self.grid_size:\n",
    "\t\t\treturn True\n",
    "\t\tif coor[1] - size[1]//2 < 0 or coor[1] + size[1]//2 >= self.grid_size:\n",
    "\t\t\treturn True\n",
    "\t\t\n",
    "\t\tif np.any((table[in_table_index(coor, size)] != 0) & (table[in_table_index(coor, size)] != node+1)):\n",
    "\t\t\treturn True\n",
    "\t\treturn False\n",
    "\n",
    "\tdef occupied_score(self, coor, node, table=None):\n",
    "\t\tif table is None:\n",
    "\t\t\ttable = self.target_table\n",
    "\t\t\n",
    "\t\tsize = self.get_obj_size(node)\n",
    "\t\toccupied = np.sum((table[in_table_index(coor, size)] != 0) & (table[in_table_index(coor, size)] != node+1))\n",
    "\t\treturn occupied / (size[0] * size[1])\n",
    "\n",
    "\tdef move_func(self, start_node, coordinates):\n",
    "\t\tif self.is_coor_occupied(coordinates, start_node):\n",
    "\t\t\tprint('occupied')\n",
    "\t\t\tcost = self.punish_cost()\n",
    "\t\telse:\n",
    "\t\t\tprev_target = self.find_connected_node(start_node)\n",
    "\t\t\tif prev_target is not None:\n",
    "\t\t\t\tself.remove_edge(start_node, prev_target)\n",
    "\t\t\tprev_coord = self.state_graph.x[start_node, Indices.COORD].clone()\n",
    "\t\t\tself.move_node_with_parents(start_node, coordinates)\n",
    "\t\t\tcost = self.cal_movement(prev_coord, coordinates)\n",
    "\t\treturn cost\n",
    "\n",
    "\tdef stack_func(self, start_node, target_node):\n",
    "\t\tif not is_stable(self.state_graph.x, start_node, target_node):\n",
    "\t\t\tcost = self.punish_cost()\n",
    "\t\telse:\n",
    "\t\t\tprev_target = self.find_connected_node(start_node)\n",
    "\t\t\tif prev_target == target_node:\n",
    "\t\t\t\tcost = self.punish_cost()\n",
    "\t\t\telif prev_target is None:\n",
    "\t\t\t\tprev_coord = self.state_graph.x[start_node, Indices.COORD].clone()\n",
    "\t\t\t\tself.add_edge(start_node, target_node)\n",
    "\t\t\t\tcost = self.cal_movement(prev_coord, self.state_graph.x[target_node, Indices.COORD])\n",
    "\t\t\telse:\n",
    "\t\t\t\tprev_coord = self.state_graph.x[start_node, Indices.COORD].clone()\n",
    "\t\t\t\tself.remove_edge(start_node, prev_target)\n",
    "\t\t\t\tself.add_edge(start_node, target_node)\n",
    "\t\t\t\tcost = self.cal_movement(prev_coord, self.state_graph.x[target_node, Indices.COORD])\n",
    "\t\treturn cost\n",
    "\n",
    "\tdef get_obj_label(self, node):\n",
    "\t\treturn self.state_graph.x[node, Indices.LABEL].item()\n",
    "\n",
    "\tdef get_obj_size(self, node):\n",
    "\t\treturn self.OBJECT_SIZES[self.get_obj_label(node)]\n",
    "\n",
    "\tdef get_valid_actions(self):\n",
    "\t\tvalid_actions = self.get_valid_stacks() + self.get_valid_moves()\n",
    "\t\treturn valid_actions\n",
    "\n",
    "\tdef get_valid_stacks(self):\n",
    "\t\tvalid_stacks = []\n",
    "\t\tfor k in range(self.num_nodes):\n",
    "\t\t\tempty_objects = get_empty_objects(self, ref_node=k, n=np.inf)\n",
    "\t\t\tfor i in empty_objects:\n",
    "\t\t\t\tvalid_stacks.append(self.encode_action('on', k, i, 0))\n",
    "\t\treturn valid_stacks\n",
    "\t\n",
    "\tdef get_valid_moves(self):\n",
    "\t\tvalid_moves = []\n",
    "\t\tfor k in range(self.num_nodes):\n",
    "\t\t\tif torch.equal(self.state_graph.x[k, Indices.COORD], self.target_graph.x[k, Indices.COORD]):\n",
    "\t\t\t\tcontinue\n",
    "\n",
    "\t\t\tpositions = get_empty_positions(self, ref_node=k, n=np.inf)\n",
    "\t\t\tfor position in positions:\n",
    "\t\t\t\tvalid_moves.append(self.encode_action('move', k, k, position))\n",
    "\t\treturn valid_moves\n",
    "\n",
    "\tdef set_state(self, state):\n",
    "\t\tsuper().set_state(state)\n",
    "\t\tself.make_table()\n",
    "\n",
    "\tdef step_cost(self, action, log=False):\n",
    "\t\tresults = super().step_cost(action, log=log)\n",
    "\t\tself.make_table()\n",
    "\t\treturn results\n",
    "\n",
    "\tdef _step_cost(self, action_type, start_node, target_node, coordinates, log=False):\n",
    "\t\tresults = super()._step_cost(action_type, start_node, target_node, coordinates, log=log)\n",
    "\t\tself.make_table()\n",
    "\t\treturn results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Algs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SearchAlg:\n",
    "    def __init__(self, env, node_class):\n",
    "        \"\"\"\n",
    "        Base class for search algorithms.\n",
    "        :param env: The environment in which the search is performed.\n",
    "        :param node_class: The class used for representing nodes in the search.\n",
    "        \"\"\"\n",
    "        self.env = env\n",
    "        self.node_class = node_class  # Generalized node class\n",
    "\n",
    "class LabbeNode:\n",
    "\tnode_counter = 0  # Static variable to assign unique IDs to each node\n",
    "\n",
    "\tdef __init__(self, state, remaining_nodes, parent=None, action=None, c=1):\n",
    "\t\tself.state = state\n",
    "\t\tself.parent = parent\n",
    "\t\tself.action = action\n",
    "\t\tself.children = {}\n",
    "\t\tself.n = 0\n",
    "\t\tself.w = 0.0\n",
    "\t\tself.c = c\n",
    "\t\tself.terminal_flag = False\n",
    "\t\tself.unexpanded_actions = remaining_nodes\n",
    "\t\t\n",
    "\t\t# Assign a unique ID to each node\n",
    "\t\tself.id = LabbeNode.node_counter\n",
    "\t\tLabbeNode.node_counter += 1\n",
    "\n",
    "\tdef get_state(self):\n",
    "\t\treturn copy_state(self.state)\n",
    "\n",
    "\tdef is_fully_expanded(self):\n",
    "\t\treturn len(self.unexpanded_actions) == 0\n",
    "\n",
    "\tdef ucb(self):\n",
    "\t\tif self.n == 0:\n",
    "\t\t\treturn float('inf')  # Prioritize unvisited nodes\n",
    "\n",
    "\t\texpected_value = self.w / self.n\n",
    "\t\texploration_term = self.c * np.sqrt(2 * np.log(self.parent.n) / self.n)\n",
    "\n",
    "\t\treturn expected_value + exploration_term\n",
    "\n",
    "\tdef best_child(self):\n",
    "\t\t# Accesses child nodes for best selection\n",
    "\t\treturn max(self.children.values(), key=lambda child: child.ucb())\n",
    "\n",
    "class Labbe(SearchAlg):\n",
    "\tdef __init__(self, env):\n",
    "\t\tsuper().__init__(env, LabbeNode)\n",
    "\n",
    "\tdef backup_search(self, node, reward, terminal_flag):\n",
    "\t\twhile node is not None:\n",
    "\t\t\tnode.n += 1\n",
    "\t\t\tnode.w += reward\n",
    "\t\t\tnode.terminal_flag = terminal_flag or node.terminal_flag\n",
    "\t\t\tnode = node.parent\n",
    "\n",
    "\tdef expand(self, node):\n",
    "\t\tif node.is_fully_expanded():\n",
    "\t\t\treturn None  # Prevents further expansion if no actions remain\n",
    "\n",
    "\t\tself.env.set_state(node.get_state())\n",
    "\t\t# random.shuffle(node.unexpanded_actions)\n",
    "\t\taction = self.get_motion(node.unexpanded_actions.pop())\n",
    "\t\tif action is None:\n",
    "\t\t\treturn None\n",
    "\t\t_, child_state = self.env.step_cost(action)\n",
    "\n",
    "\t\t# Continue expanding if the state hasn't changed\n",
    "\t\tif torch.equal(child_state['graph'].x, node.state['graph'].x):\n",
    "\t\t\treturn self.expand(node)\n",
    "\n",
    "\t\tremaining_nodes = self.get_remaining_nodes(self.env.get_state())\n",
    "\t\tchild_node = self.node_class(child_state, remaining_nodes, node, action, node.c)\n",
    "\t\tnode.children[action] = child_node\n",
    "\t\treturn child_node\n",
    "\n",
    "\tdef print_tree(self, node, depth=0, ter=False):\n",
    "\t\t# Print the current node with indentation to show its depth in the tree\n",
    "\t\tindent = \"    \" * depth  # Four spaces per level of depth\n",
    "\t\tif node.id == 0:\n",
    "\t\t\tprint(f\"Root | Visits: {node.n} | Value: {node.w:.2f} | Terminal: {node.terminal_flag}\")\n",
    "\t\telse:\n",
    "\t\t\tprint(f\"{indent}ID: {node.id} | Action: {node.action} | \"\n",
    "\t\t\t\t\tf\"Visits: {node.n} | Value: {node.w:.2f} | Terminal: {node.terminal_flag}\")\n",
    "\n",
    "\t\t# Sort children by value estimate\n",
    "\t\tif ter:\n",
    "\t\t\taccepted_children = [child for child in node.children.values() if child.terminal_flag]\n",
    "\t\t\tchildren = sorted(accepted_children, key=lambda child: child.w / child.n if child.n > 0 else float('inf'))\n",
    "\t\telse:\n",
    "\t\t\tchildren = sorted(node.children.values(), key=lambda child: child.w / child.n if child.n > 0 else float('inf'))\n",
    "\n",
    "\t\t# Recurse on children\n",
    "\t\tfor child in children:\n",
    "\t\t\tself.print_tree(child, depth + 1, ter)\n",
    "\n",
    "\tdef evaluate_state(self, state):\n",
    "\t\tstate_graph = state['graph']\n",
    "\t\treward = 0\n",
    "\t\t\n",
    "\t\tfor k in range(state_graph.num_nodes):\n",
    "\t\t\ti = find_target_node(self.env.target_graph, k)\n",
    "\t\t\tif i is not None:\n",
    "\t\t\t\tif is_edge_in_graph(state_graph, k, i):\n",
    "\t\t\t\t\treward += 1\n",
    "\t\t\telif find_target_node(state_graph, k) is None:\n",
    "\t\t\t\tif torch.equal(state_graph.x[k, Indices.COORD], self.env.target_graph.x[k, Indices.COORD]):\n",
    "\t\t\t\t\treward += 1\n",
    "\n",
    "\t\treturn reward\n",
    "\n",
    "\tdef find_best_path(self, ter=False):\n",
    "\t\tpath = []\n",
    "\t\tcurrent_node = self.root_node\n",
    "\n",
    "\t\twhile current_node.children:\n",
    "\t\t\tif ter:\n",
    "\t\t\t\taccepted_children = [child for child in current_node.children.values() if child.terminal_flag]\n",
    "\t\t\t\tif len(accepted_children) == 0:\n",
    "\t\t\t\t\tbreak\n",
    "\t\t\t\tnext_node = max(accepted_children, key=lambda child: child.w / child.n if child.n > 0 else float('inf'))\n",
    "\t\t\telse:\n",
    "\t\t\t\tnext_node = max(current_node.children.values(), key=lambda child: child.w / child.n if child.n > 0 else float('inf'))\n",
    "\t\t\tpath.append((next_node.action, next_node.w))\n",
    "\t\t\tcurrent_node = next_node\n",
    "\n",
    "\t\treturn [action for action, _ in path]\n",
    "\n",
    "\tdef get_remaining_nodes(self, state):\n",
    "\t\tstate_graph = state['graph']\n",
    "\n",
    "\t\tremaining_nodes = []\n",
    "\t\tfor k in range(state_graph.num_nodes):\n",
    "\t\t\tif not torch.equal(state_graph.x[k, Indices.COORD], self.env.target_graph.x[k, Indices.COORD]):\n",
    "\t\t\t\tremaining_nodes.append(k)\n",
    "\n",
    "\t\t# shuffle remaining nodes\n",
    "\t\trandom.shuffle(remaining_nodes)\n",
    "\n",
    "\t\treturn remaining_nodes\n",
    "\n",
    "\tdef get_motion(self, k):\n",
    "\t\tTk = self.env.target_graph.x[k, Indices.COORD]\n",
    "\t\tCK = self.env.state_graph.x[k, Indices.COORD]\n",
    "\t\tif torch.equal(Tk, CK):\n",
    "\t\t\treturn None\n",
    "\t\telif not self.env.is_coor_occupied(Tk, k):\n",
    "\t\t\t# Tk is free\n",
    "\t\t\tposition = Tk[0] * self.env.grid_size + Tk[1]\n",
    "\t\t\treturn self.env.encode_action('move', k, k, int(position.item()))\n",
    "\t\telse:\n",
    "\t\t\t# find which node is occupying Tk\n",
    "\t\t\tsize = self.env.get_obj_size(k)\n",
    "\t\t\toccupying_nodes = find_occupying_nodes(self.env.table, Tk, size)\n",
    "\t\t\tif len(occupying_nodes) == 0:\n",
    "\t\t\t\treturn None\n",
    "\t\t\tj = random.choice(occupying_nodes)\n",
    "\t\t\tfree_positions = get_empty_positions(self.env, ref_node=j, n=1)\n",
    "\t\t\tif len(free_positions) == 0:\n",
    "\t\t\t\treturn None\n",
    "\t\t\treturn self.env.encode_action('move', j, j, free_positions[0])\n",
    "\n",
    "\tdef loop(self):\n",
    "\t\tnode = self.root_node\n",
    "\n",
    "\t\t# Selection\n",
    "\t\tself.env.set_state(node.get_state())\n",
    "\t\twhile node.is_fully_expanded() and not self.env.is_terminal_state():\n",
    "\t\t\tnode = node.best_child()\n",
    "\t\t\tself.env.set_state(node.get_state())\n",
    "\n",
    "\t\t# Expansion\n",
    "\t\tif not self.env.is_terminal_state():\n",
    "\t\t\tnode = self.expand(node)\n",
    "\t\t\tif node is None:\n",
    "\t\t\t\treturn\n",
    "\n",
    "\t\t# Backpropagation\n",
    "\t\tterminal_flag = True if self.env.is_terminal_state() else False\n",
    "\t\treward = self.evaluate_state(node.get_state())\n",
    "\t\tself.backup_search(node, reward, terminal_flag)\n",
    "\n",
    "\tdef solve(self, verbose=1, c=1):\n",
    "\t\tfor i in range(self.env.num_nodes):\n",
    "\t\t\tif torch.sum(self.env.state_graph.x[:, Indices.RELATION.start+i]) > 0:\n",
    "\t\t\t\traise ValueError('Initial graph has edges')\n",
    "\t\treturn self._solve(verbose, c)\n",
    "\n",
    "\tdef _solve(self, verbose=1, c=1):\n",
    "\t\tself.root_node = self.node_class(self.env.get_state(), self.get_remaining_nodes(self.env.get_state()), c=c)\n",
    "\t\t\n",
    "\t\tsteps = 0\n",
    "\t\tif verbose > 0:\n",
    "\t\t\tpbar = tqdm(total=None, unit='iterations')\n",
    "\t\twhile self.root_node.terminal_flag is False:\n",
    "\t\t\tsteps += 1\n",
    "\t\t\tself.loop()\n",
    "\t\t\tif verbose > 0:\n",
    "\t\t\t\tpbar.update(1)\n",
    "\t\tif verbose > 0:\n",
    "\t\t\tpbar.close()\n",
    "\n",
    "\t\treturn self.find_best_path(ter=True), steps\n",
    "\n",
    "class LabbeS(Labbe):\n",
    "\tdef get_remaining_nodes(self, state):\n",
    "\t\tstate_graph = state['graph']\n",
    "\n",
    "\t\tremaining_nodes = []\n",
    "\t\tfor k in range(state_graph.num_nodes):\n",
    "\t\t\ti = find_target_node(self.env.target_graph, k)\n",
    "\t\t\tif i is not None:\n",
    "\t\t\t\tif not is_edge_in_graph(state_graph, k, i):\n",
    "\t\t\t\t\tremaining_nodes.append(k)\n",
    "\t\t\telif find_target_node(state_graph, k) is not None:\n",
    "\t\t\t\tremaining_nodes.append(k)\n",
    "\t\t\telse:\n",
    "\t\t\t\tif not torch.equal(state_graph.x[k, Indices.COORD], self.env.target_graph.x[k, Indices.COORD]):\n",
    "\t\t\t\t\tremaining_nodes.append(k)\n",
    "\n",
    "\t\t# shuffle remaining nodes\n",
    "\t\trandom.shuffle(remaining_nodes)\n",
    "\n",
    "\t\treturn remaining_nodes\n",
    "\n",
    "\tdef get_action_move_node_away(self, k):\n",
    "\t\tfree_position = get_empty_positions(self.env, ref_node=k, n=1)\n",
    "\t\tfree_object = get_empty_objects(self.env, ref_node=k, n=1)\n",
    "\t\tif len(free_object) > 0 and len(free_position) > 0:\n",
    "\t\t\tif random.random() < 0.5:\n",
    "\t\t\t\t# move the node to a random position\n",
    "\t\t\t\treturn self.env.encode_action('move', k, k, free_position[0])\n",
    "\t\t\telse:\n",
    "\t\t\t\t# stack on a random node\n",
    "\t\t\t\treturn self.env.encode_action('on', k, free_object[0], 0)\n",
    "\t\telif len(free_object) == 0 and len(free_position) > 0:\n",
    "\t\t\t# move the node to a random position\n",
    "\t\t\treturn self.env.encode_action('move', k, k, free_position[0])\n",
    "\t\telif len(free_position) == 0 and len(free_object) > 0:\n",
    "\t\t\t# stack on a random node\n",
    "\t\t\treturn self.env.encode_action('on', k, free_object[0], 0)\n",
    "\t\treturn None\n",
    "\t\n",
    "\tdef get_motion(self, k):\n",
    "\t\ti = find_target_node(self.env.target_graph, k)\n",
    "\t\tif i is not None:\n",
    "\t\t\tj = find_start_node(self.env.state_graph, i)\n",
    "\t\t\tif j is not None:\n",
    "\t\t\t\treturn self.get_action_move_node_away(j)\n",
    "\t\t\telse:\n",
    "\t\t\t\treturn self.env.encode_action('on', k, i, 0)\n",
    "\t\telse:\n",
    "\t\t\tj = find_target_node(self.env.state_graph, k)\n",
    "\t\t\tTk = self.env.target_graph.x[k, Indices.COORD]\n",
    "\t\t\tCK = self.env.state_graph.x[k, Indices.COORD]\n",
    "\t\t\tif torch.equal(Tk, CK):\n",
    "\t\t\t\tif j is not None:\n",
    "\t\t\t\t\tj = find_base_node(self.env.state_graph, j)\n",
    "\t\t\t\t\treturn self.get_action_move_node_away(j)\n",
    "\t\t\telse:\n",
    "\t\t\t\tif not self.env.is_coor_occupied(Tk, k):\n",
    "\t\t\t\t\t# Tk is free\n",
    "\t\t\t\t\tposition = Tk[0] * self.env.grid_size + Tk[1]\n",
    "\t\t\t\t\treturn self.env.encode_action('move', k, k, int(position.item()))\n",
    "\t\t\t\telse:\n",
    "\t\t\t\t\t# find which nodes are occupying Tk\n",
    "\t\t\t\t\tsize = self.env.get_obj_size(k)\n",
    "\t\t\t\t\toccupying_nodes = find_occupying_nodes(self.env.table, Tk, size)\n",
    "\t\t\t\t\tif len(occupying_nodes) == 0:\n",
    "\t\t\t\t\t\treturn None\n",
    "\t\t\t\t\tj = random.choice(occupying_nodes)\n",
    "\t\t\t\t\treturn self.get_action_move_node_away(j)\n",
    "\n",
    "\tdef solve(self, verbose=1, c=1):\n",
    "\t\treturn self._solve(verbose, c)\n",
    "\n",
    "class MultiLabbe(Labbe):\n",
    "\t\"\"\"run multiple Labbe instances in parallel and return the best solution\"\"\"\n",
    "\tdef solve(self, num_agents, verbose=1, c=1):\n",
    "\t\tbest_path, best_cost = None, float('inf')\n",
    "\t\tfor _ in range(num_agents):\n",
    "\t\t\tpath, steps = self._solve(verbose, c)\n",
    "\t\t\tif steps < best_steps:\n",
    "\t\t\t\tbest_path, best_steps = path, steps\n",
    "\t\treturn best_path, best_steps\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SearchNode:\n",
    "\tdef __init__(self, state, parent=None, action=None, cost_to_come=0, heuristic=0, depth=0):\n",
    "\t\tself.state = state\n",
    "\t\tself.parent = parent\n",
    "\t\tself.action = action\n",
    "\t\tself.c_cost = cost_to_come\t  \t# cost-to-come\n",
    "\t\tself.h_cost = heuristic\t\t\t# cost-to-go\n",
    "\t\tself.total_cost = self.c_cost + self.h_cost\n",
    "\t\tself.depth = depth\n",
    "\n",
    "\tdef __lt__(self, other):\n",
    "\t\treturn self.total_cost < other.total_cost  # Lower cost first\n",
    "\n",
    "\tdef get_state(self):\n",
    "\t\treturn copy_state(self.state)\n",
    "\n",
    "def find_required_max_depth(env, state, max_depth=100, stack=False):\n",
    "\tsteps = 0\n",
    "\tfor _ in range(5):\n",
    "\t\tenv.set_state(copy_state(state))\n",
    "\t\tif stack:\n",
    "\t\t\tfeasible_path, labbe_steps = LabbeS(env).solve(verbose=0)\n",
    "\t\telse:\n",
    "\t\t\tfeasible_path, labbe_steps = Labbe(env).solve(verbose=0)\n",
    "\t\tsteps += labbe_steps\n",
    "\t\tmax_depth = min(max_depth, len(feasible_path))\n",
    "\treturn max_depth, steps\n",
    "\n",
    "class Dijkstra(SearchAlg):\n",
    "\tdef __init__(self, env):\n",
    "\t\tsuper().__init__(env, SearchNode)\n",
    "\n",
    "\tdef get_valid_actions(self, state):\n",
    "\t\treturn self.env.get_valid_actions()\n",
    "\n",
    "\tdef solve(self, max_depth=100):\n",
    "\t\tsteps = 0\n",
    "\t\tstart_node = self.node_class(self.env.get_state(), cost_to_come=0)\n",
    "\n",
    "\t\tqueue = []\n",
    "\t\theapq.heappush(queue, start_node)\n",
    "\t\tvisited = {}\n",
    "\n",
    "\t\twhile queue:\n",
    "\t\t\tcurrent_node = heapq.heappop(queue)\n",
    "\n",
    "\t\t\t# Check if the current node's state matches the target state\n",
    "\t\t\tself.env.set_state(current_node.get_state())\n",
    "\t\t\tif self.env.is_terminal_state():\n",
    "\t\t\t\treturn reconstruct_path(current_node), steps\n",
    "\n",
    "\t\t\tif current_node.depth >= max_depth:\n",
    "\t\t\t\tcontinue\n",
    "\n",
    "\t\t\tlast_changed_node = self.env.decode_action(current_node.action)[1] if current_node.action is not None else None\n",
    "\t\t\tfor action in self.get_valid_actions(current_node.get_state()):\n",
    "\t\t\t\tsteps += 1\n",
    "\t\t\t\tself.env.set_state(current_node.get_state())\n",
    "\t\t\t\taction_type, start_node, target_node, coordinates = self.env.decode_action(action)\n",
    "\n",
    "\t\t\t\tif last_changed_node == start_node:\n",
    "\t\t\t\t\t# if the last changed node is the same as the current node, continue\n",
    "\t\t\t\t\tcontinue\n",
    "\n",
    "\t\t\t\tcost, child_state = self.env._step_cost(action_type, start_node, target_node, coordinates)\n",
    "\n",
    "\t\t\t\tif torch.equal(child_state['graph'].x, current_node.get_state()['graph'].x):\n",
    "\t\t\t\t\t# if state hasn't changed, continue\n",
    "\t\t\t\t\tcontinue\n",
    "\t\t\t\t\n",
    "\t\t\t\tchild_hash = state_to_hashable(child_state)\n",
    "\n",
    "\t\t\t\t# Calculate the accumulated cost for the current path\n",
    "\t\t\t\tnew_total_cost = current_node.total_cost + cost\n",
    "\n",
    "\t\t\t\t# Retain the node with better cost\n",
    "\t\t\t\tif child_hash not in visited or visited[child_hash] > new_total_cost:\n",
    "\t\t\t\t\tvisited[child_hash] = new_total_cost\n",
    "\t\t\t\t\tchild_node = self.node_class(child_state, current_node, action, cost_to_come=new_total_cost, depth=current_node.depth+1)\n",
    "\n",
    "\t\t\t\t\theapq.heappush(queue, child_node)\n",
    "\n",
    "\t\treturn None, steps  # No path found\n",
    "\n",
    "class A_star(SearchAlg):\n",
    "\tdef __init__(self, env):\n",
    "\t\tsuper().__init__(env, SearchNode)\n",
    "\t\tself.num_buffers = 2\n",
    "\n",
    "\tdef evaluate_state(self, state):\n",
    "\t\tstate_graph = state['graph']\n",
    "\t\theuristic = 0\n",
    "\n",
    "\t\tfor k in range(state_graph.num_nodes):\n",
    "\t\t\tTK = self.env.target_graph.x[k, Indices.COORD]\n",
    "\t\t\tCK = state_graph.x[k, Indices.COORD]\n",
    "\t\t\tmin_dis = torch.norm(CK - TK)\n",
    "\n",
    "\t\t\ti = find_target_node(self.env.target_graph, k)\n",
    "\t\t\tif i is not None:\n",
    "\t\t\t\tif not is_edge_in_graph(state_graph, k, i):\n",
    "\t\t\t\t\tCI = state_graph.x[i, Indices.COORD]\n",
    "\t\t\t\t\tnew_dis = torch.norm(CK - CI)\n",
    "\t\t\t\t\tif new_dis < min_dis:\n",
    "\t\t\t\t\t\tmin_dis = new_dis\n",
    "\t\t\t\t\t\tif find_start_node(state_graph, i) is not None:\n",
    "\t\t\t\t\t\t\theuristic += self.env.pp_cost\n",
    "\t\t\t\t\theuristic += self.env.pp_cost\n",
    "\t\t\t\t\theuristic += self.env.normalization_factor * min_dis\n",
    "\t\t\telif find_target_node(state_graph, k) is not None:\n",
    "\t\t\t\tif min_dis == 0:\n",
    "\t\t\t\t\theuristic += self.env.pp_cost\n",
    "\t\t\telse:\n",
    "\t\t\t\tif min_dis != 0:\n",
    "\t\t\t\t\tstack = False\n",
    "\t\t\t\t\tfor j in range(state_graph.num_nodes):\n",
    "\t\t\t\t\t\tif k != j and is_stable(state_graph.x, k, j):\n",
    "\t\t\t\t\t\t\tCJ = state_graph.x[j, Indices.COORD]\n",
    "\t\t\t\t\t\t\tTJ = self.env.target_graph.x[j, Indices.COORD]\n",
    "\t\t\t\t\t\t\tnew_dis = torch.norm(CK - CJ) + torch.norm(TK - TJ)\n",
    "\t\t\t\t\t\t\tif new_dis < min_dis:\n",
    "\t\t\t\t\t\t\t\tmin_dis = new_dis\n",
    "\t\t\t\t\t\t\t\tstack = True\n",
    "\t\t\t\t\tif stack:\n",
    "\t\t\t\t\t\theuristic += self.env.pp_cost\n",
    "\t\t\t\t\theuristic += self.env.pp_cost\n",
    "\t\t\t\t\theuristic += self.env.normalization_factor * min_dis\n",
    "\t\t\n",
    "\t\t# return self.env.normalize_cost(heuristic)\n",
    "\t\treturn heuristic\n",
    "\n",
    "\tdef evaluate_state(self, state):\n",
    "\t\tstate_graph = state['graph']\n",
    "\t\theuristic = 0\n",
    "\n",
    "\t\tfor k in range(state_graph.num_nodes):\n",
    "\t\t\tTK = self.env.target_graph.x[k, Indices.COORD]\n",
    "\t\t\tCK = state_graph.x[k, Indices.COORD]\n",
    "\t\t\tmin_dis = torch.norm(CK - TK)\n",
    "\n",
    "\t\t\ti = find_target_node(self.env.target_graph, k)\n",
    "\t\t\tif i is not None:\n",
    "\t\t\t\tif not is_edge_in_graph(state_graph, k, i):\n",
    "\t\t\t\t\tCI = state_graph.x[i, Indices.COORD]\n",
    "\t\t\t\t\tnew_dis = torch.norm(CK - CI)\n",
    "\t\t\t\t\tif new_dis < min_dis:\n",
    "\t\t\t\t\t\tmin_dis = new_dis\n",
    "\t\t\t\t\t\tif find_start_node(state_graph, i) is not None:\n",
    "\t\t\t\t\t\t\theuristic += self.env.pp_cost\n",
    "\t\t\t\t\theuristic += self.env.pp_cost\n",
    "\t\t\t\t\theuristic += self.env.normalization_factor * min_dis\n",
    "\t\t\telif find_target_node(state_graph, k) is not None:\n",
    "\t\t\t\tif min_dis == 0:\n",
    "\t\t\t\t\theuristic += self.env.pp_cost\n",
    "\t\t\telse:\n",
    "\t\t\t\tif min_dis != 0:\n",
    "\t\t\t\t\tstack = False\n",
    "\t\t\t\t\tfor j in range(state_graph.num_nodes):\n",
    "\t\t\t\t\t\tif k != j and is_stable(state_graph.x, k, j):\n",
    "\t\t\t\t\t\t\tCJ = state_graph.x[j, Indices.COORD]\n",
    "\t\t\t\t\t\t\tTJ = self.env.target_graph.x[j, Indices.COORD]\n",
    "\t\t\t\t\t\t\tnew_dis = torch.norm(CK - CJ) + torch.norm(TK - TJ)\n",
    "\t\t\t\t\t\t\tif new_dis < min_dis:\n",
    "\t\t\t\t\t\t\t\tmin_dis = new_dis\n",
    "\t\t\t\t\t\t\t\tstack = True\n",
    "\t\t\t\t\tif stack:\n",
    "\t\t\t\t\t\theuristic += self.env.pp_cost\n",
    "\t\t\t\t\theuristic += self.env.pp_cost\n",
    "\t\t\t\t\theuristic += self.env.normalization_factor * min_dis\n",
    "\t\t\n",
    "\t\t# return self.env.normalize_cost(heuristic)\n",
    "\t\treturn heuristic\n",
    "\n",
    "\tdef get_remaining_nodes(self, state):\n",
    "\t\tstate_graph = state['graph']\n",
    "\n",
    "\t\tremaining_nodes = []\n",
    "\t\tfor k in range(state_graph.num_nodes):\n",
    "\t\t\ti = find_target_node(self.env.target_graph, k)\n",
    "\t\t\tif i is not None:\n",
    "\t\t\t\tif not is_edge_in_graph(state_graph, k, i):\n",
    "\t\t\t\t\tremaining_nodes.append(k)\n",
    "\t\t\telif find_target_node(state_graph, k) is not None:\n",
    "\t\t\t\tremaining_nodes.append(k)\n",
    "\t\t\telse:\n",
    "\t\t\t\tif not torch.equal(state_graph.x[k, Indices.COORD], self.env.target_graph.x[k, Indices.COORD]):\n",
    "\t\t\t\t\tremaining_nodes.append(k)\n",
    "\n",
    "\t\t# shuffle remaining nodes\n",
    "\t\trandom.shuffle(remaining_nodes)\n",
    "\n",
    "\t\treturn remaining_nodes\n",
    "\n",
    "\tdef get_empty_positions_with_target(self, ref_node, n=1):\n",
    "\t\tpositions = []\n",
    "\t\ttarget_pos = self.env.target_graph.x[ref_node, Indices.COORD]\n",
    "\t\tp = int(target_pos[0] * self.env.grid_size + target_pos[1])\n",
    "\t\tif not self.env.is_coor_occupied(target_pos, ref_node):\n",
    "\t\t\tpositions.append(p)\n",
    "\t\telse:\n",
    "\t\t\tif n == 0:\n",
    "\t\t\t\treturn positions\n",
    "\t\t\tall_positions = list(range(self.env.grid_size * self.env.grid_size))\n",
    "\t\t\trandom.shuffle(all_positions)\n",
    "\t\t\tfor position in all_positions:\n",
    "\t\t\t\tp = unflatten_pos(position, self.env.grid_size)\n",
    "\t\t\t\tif not torch.equal(p, target_pos) and not self.env.is_coor_occupied(p, ref_node):\n",
    "\t\t\t\t\tpositions.append(position)\n",
    "\t\t\t\t\tif len(positions) >= n:\n",
    "\t\t\t\t\t\tbreak\n",
    "\t\treturn positions\n",
    "\n",
    "\tdef get_valid_actions(self, state):\n",
    "\t\tself.env.set_state(state)\n",
    "\n",
    "\t\tstack_nums = max(int(0.6 * self.num_buffers), 1)\n",
    "\n",
    "\t\tnodes = list(range(self.env.num_nodes))\n",
    "\t\trandom.shuffle(nodes)\n",
    "\n",
    "\t\tvalid_actions = []\n",
    "\t\tfor k in self.get_remaining_nodes(state):\n",
    "\t\t\tvalid_stacks = []\n",
    "\t\t\tfor j in nodes:\n",
    "\t\t\t\tif k != j and not is_edge_in_graph(self.env.state_graph, k, j):\n",
    "\t\t\t\t\tif is_stable(self.env.state_graph.x, k, j):\n",
    "\t\t\t\t\t\tif is_empty_object(self.env.state_graph, j):\n",
    "\t\t\t\t\t\t\tvalid_stacks.append(self.env.encode_action('on', k, j, 0))\n",
    "\t\t\t\t\t\t\tif len(valid_stacks) >= stack_nums:\n",
    "\t\t\t\t\t\t\t\tbreak\n",
    "\n",
    "\t\t\tvalid_moves = []\n",
    "\t\t\tfor position in self.get_empty_positions_with_target(ref_node=k, n=self.num_buffers-len(valid_stacks)):\n",
    "\t\t\t\tvalid_moves.append(self.env.encode_action('move', k, k, position))\n",
    "\t\t\t\t\n",
    "\t\t\tvalid_actions += valid_stacks + valid_moves\n",
    "\n",
    "\t\treturn valid_actions\n",
    "\n",
    "\tdef solve(self, max_depth=100, num_buffers=2):\n",
    "\t\tself.num_buffers = num_buffers\n",
    "\t\treturn self._solve(max_depth)\n",
    "\n",
    "\tdef _solve(self, max_depth=100):\n",
    "\t\tsteps = 0\n",
    "\t\th_cost = self.evaluate_state(self.env.get_state())\n",
    "\t\tstart_node = self.node_class(self.env.get_state(), cost_to_come=0, heuristic=h_cost)\n",
    "\n",
    "\t\tqueue = []\n",
    "\t\theapq.heappush(queue, start_node)\n",
    "\t\tvisited = {}\n",
    "\n",
    "\t\twhile queue:\n",
    "\t\t\tcurrent_node = heapq.heappop(queue)\n",
    "\n",
    "\t\t\t# Check if the current node's state matches the target state\n",
    "\t\t\tself.env.set_state(current_node.get_state())\n",
    "\t\t\tif self.env.is_terminal_state():\n",
    "\t\t\t\treturn reconstruct_path(current_node), steps\n",
    "\n",
    "\t\t\tif current_node.depth >= max_depth:\n",
    "\t\t\t\tcontinue\n",
    "\n",
    "\t\t\tlast_changed_node = self.env.decode_action(current_node.action)[1] if current_node.action is not None else None\n",
    "\t\t\tfor action in self.get_valid_actions(current_node.get_state()):\n",
    "\t\t\t\tsteps += 1\n",
    "\t\t\t\taction_type, start_node, target_node, coordinates = self.env.decode_action(action)\n",
    "\n",
    "\t\t\t\tif start_node == last_changed_node:\n",
    "\t\t\t\t\t# If the last changed node is the same as the current node, continue\n",
    "\t\t\t\t\tcontinue\n",
    "\n",
    "\t\t\t\tself.env.set_state(current_node.get_state())\n",
    "\t\t\t\tcost, child_state = self.env._step_cost(action_type, start_node, target_node, coordinates)\n",
    "\n",
    "\t\t\t\tif torch.equal(child_state['graph'].x, current_node.get_state()['graph'].x):\n",
    "\t\t\t\t\t# if state hasn't changed, continue\n",
    "\t\t\t\t\tcontinue\n",
    "\n",
    "\t\t\t\tchild_hash = state_to_hashable(child_state)\n",
    "\n",
    "\t\t\t\t# Calculate the accumulated cost for the current path\n",
    "\t\t\t\tnew_c_cost = current_node.c_cost + cost\n",
    "\t\t\t\th_cost = self.evaluate_state(child_state)\n",
    "\t\t\t\tnew_total_cost = new_c_cost + h_cost\n",
    "\n",
    "\t\t\t\t# Retain the node with better cost\n",
    "\t\t\t\tif child_hash not in visited or visited[child_hash] > new_total_cost:\n",
    "\t\t\t\t\tvisited[child_hash] = new_total_cost\n",
    "\t\t\t\t\tchild_node = self.node_class(\n",
    "\t\t\t\t\t\tstate=child_state, \n",
    "\t\t\t\t\t\tparent=current_node, \n",
    "\t\t\t\t\t\taction=action, \n",
    "\t\t\t\t\t\tcost_to_come=new_c_cost, \n",
    "\t\t\t\t\t\theuristic=h_cost,\n",
    "\t\t\t\t\t\tdepth=current_node.depth+1\n",
    "\t\t\t\t\t)\n",
    "\n",
    "\t\t\t\t\theapq.heappush(queue, child_node)\n",
    "\n",
    "\t\treturn None, steps  # No path found\n",
    "\n",
    "class A_starGA(A_star):\n",
    "\tdef _solve(self, max_depth=100):\n",
    "\t\tbest_plan = None\n",
    "\t\tbest_cost = float('inf')\n",
    "\n",
    "\t\tsteps = 0\n",
    "\t\th_cost = self.evaluate_state(self.env.get_state())\n",
    "\t\tstart_node = self.node_class(self.env.get_state(), cost_to_come=0, heuristic=h_cost)\n",
    "\n",
    "\t\tqueue = []\n",
    "\t\theapq.heappush(queue, start_node)\n",
    "\t\tvisited = {}\n",
    "\n",
    "\t\twhile queue:\n",
    "\t\t\tcurrent_node = heapq.heappop(queue)\n",
    "\n",
    "\t\t\t# Check if the current node's state matches the target state\n",
    "\t\t\tself.env.set_state(current_node.get_state())\n",
    "\t\t\tif self.env.is_terminal_state():\n",
    "\t\t\t\treturn reconstruct_path(current_node), steps\n",
    "\n",
    "\t\t\tif current_node.depth >= max_depth:\n",
    "\t\t\t\tcontinue\n",
    "\n",
    "\t\t\tlast_changed_node = self.env.decode_action(current_node.action)[1] if current_node.action is not None else None\n",
    "\t\t\tfor action in self.get_valid_actions(current_node.get_state()):\n",
    "\t\t\t\tsteps += 1\n",
    "\t\t\t\taction_type, start_node, target_node, coordinates = self.env.decode_action(action)\n",
    "\n",
    "\t\t\t\tif start_node == last_changed_node:\n",
    "\t\t\t\t\t# If the last changed node is the same as the current node, continue\n",
    "\t\t\t\t\tcontinue\n",
    "\n",
    "\t\t\t\tself.env.set_state(current_node.get_state())\n",
    "\t\t\t\tcost, child_state = self.env._step_cost(action_type, start_node, target_node, coordinates)\n",
    "\n",
    "\t\t\t\tif torch.equal(child_state['graph'].x, current_node.get_state()['graph'].x):\n",
    "\t\t\t\t\t# if state hasn't changed, continue\n",
    "\t\t\t\t\tcontinue\n",
    "\n",
    "\t\t\t\tchild_hash = state_to_hashable(child_state)\n",
    "\n",
    "\t\t\t\t# Calculate the accumulated cost for the current path\n",
    "\t\t\t\tnew_c_cost = current_node.c_cost + cost\n",
    "\t\t\t\th_cost = self.evaluate_state(child_state)\n",
    "\t\t\t\tnew_total_cost = new_c_cost + h_cost\n",
    "\n",
    "\t\t\t\t# Retain the node with better cost\n",
    "\t\t\t\tif child_hash not in visited or visited[child_hash] > new_total_cost:\n",
    "\t\t\t\t\tvisited[child_hash] = new_total_cost\n",
    "\t\t\t\t\tchild_node = self.node_class(\n",
    "\t\t\t\t\t\tstate=child_state, \n",
    "\t\t\t\t\t\tparent=current_node, \n",
    "\t\t\t\t\t\taction=action, \n",
    "\t\t\t\t\t\tcost_to_come=new_c_cost, \n",
    "\t\t\t\t\t\theuristic=h_cost,\n",
    "\t\t\t\t\t\tdepth=current_node.depth+1\n",
    "\t\t\t\t\t)\n",
    "\n",
    "\t\t\t\t\theapq.heappush(queue, child_node)\n",
    "\n",
    "\t\t\t# Goal Attempting\n",
    "\t\t\tself.env.set_state(current_node.get_state())\n",
    "\t\t\tfeasible_path, labbe_steps = LabbeS(self.env).solve(verbose=0)\n",
    "\t\t\tsteps += labbe_steps\n",
    "\n",
    "\t\t\tfeasible_path_cost = current_node.c_cost\n",
    "\t\t\tself.env.set_state(current_node.get_state())\n",
    "\t\t\tfor action in feasible_path:\n",
    "\t\t\t\tfeasible_path_cost += self.env.step_cost(action)[0]\n",
    "\n",
    "\t\t\t# Remove all the nodes with their total cost is greater than the feasible path cost\n",
    "\t\t\tfor node in queue:\n",
    "\t\t\t\tif node.total_cost > feasible_path_cost:\n",
    "\t\t\t\t\tqueue.remove(node)\n",
    "\n",
    "\t\t\tif feasible_path_cost < best_cost:\n",
    "\t\t\t\tbest_plan = reconstruct_path(current_node) + feasible_path\n",
    "\t\t\t\tbest_cost = feasible_path_cost\n",
    "\n",
    "\t\treturn best_plan, steps  # No path found\n",
    "\n",
    "class Strap(A_star):\n",
    "\tdef evaluate_state(self, state):\n",
    "\t\tstate_graph = state['graph']\n",
    "\t\theuristic = 0\n",
    "\n",
    "\t\tfor k in self.get_remaining_nodes(state):\n",
    "\t\t\tCK = state_graph.x[k, Indices.COORD]\n",
    "\t\t\tTK = self.env.target_graph.x[k, Indices.COORD]\n",
    "\t\t\theuristic += torch.norm(CK - TK) * self.env.normalization_factor\n",
    "\t\t\theuristic += self.env.pp_cost\n",
    "\t\t\n",
    "\t\t# return self.env.normalize_cost(heuristic)\n",
    "\t\treturn heuristic\n",
    "\n",
    "\tdef get_remaining_nodes(self, state):\n",
    "\t\tstate_graph = state['graph']\n",
    "\n",
    "\t\tremaining_nodes = []\n",
    "\t\tfor k in range(state_graph.num_nodes):\n",
    "\t\t\tif not torch.equal(state_graph.x[k, Indices.COORD], self.env.target_graph.x[k, Indices.COORD]):\n",
    "\t\t\t\tremaining_nodes.append(k)\n",
    "\n",
    "\t\t# shuffle remaining nodes\n",
    "\t\trandom.shuffle(remaining_nodes)\n",
    "\t\t\n",
    "\t\treturn remaining_nodes\n",
    "\n",
    "\tdef get_valid_actions(self, state):\n",
    "\t\tself.env.set_state(copy_state(state))\n",
    "\n",
    "\t\tvalid_actions = []\n",
    "\t\tfor k in self.get_remaining_nodes(state):\n",
    "\t\t\tTk = self.env.target_graph.x[k, Indices.COORD]\n",
    "\t\t\tif not self.env.is_coor_occupied(Tk, k):\n",
    "\t\t\t\t# Tk is free\n",
    "\t\t\t\tvalid_actions.append(self.env.encode_action('move', k, k, Tk))\n",
    "\t\t\telse:\n",
    "\t\t\t\t# Choose random buffer position\n",
    "\t\t\t\tfor position in get_empty_positions(self.env, ref_node=k, n=self.num_buffers):\n",
    "\t\t\t\t\tvalid_actions.append(self.env.encode_action('move', k, k, position))\n",
    "\n",
    "\t\treturn valid_actions\n",
    "\n",
    "\tdef solve(self, max_depth=100, num_buffers=2, verbose=1):\n",
    "\t\tself.verbose = verbose\n",
    "\n",
    "\t\tself.env.reset(self.env.initial_graph, self.env.target_graph)\n",
    "\t\tmax_depth, labbe_steps = find_required_max_depth(self.env, self.env.get_state(), max_depth, stack=False)\n",
    "\t\tif self.verbose > 0:\n",
    "\t\t\tprint('max depth:', max_depth)\n",
    "\n",
    "\t\tself.env.reset(self.env.initial_graph, self.env.target_graph)\n",
    "\t\toptimal_path, steps = super().solve(max_depth=max_depth, num_buffers=num_buffers)\n",
    "\t\tsteps += labbe_steps\n",
    "\n",
    "\t\treturn optimal_path, steps\n",
    "\n",
    "class StrapGA(Strap):\n",
    "\tdef _solve(self, max_depth=100):\n",
    "\t\tbest_plan = None\n",
    "\t\tbest_cost = float('inf')\n",
    "\n",
    "\t\tsteps = 0\n",
    "\t\th_cost = self.evaluate_state(self.env.get_state())\n",
    "\t\tstart_node = self.node_class(self.env.get_state(), cost_to_come=0, heuristic=h_cost)\n",
    "\n",
    "\t\tqueue = []\n",
    "\t\theapq.heappush(queue, start_node)\n",
    "\t\tvisited = {}\n",
    "\n",
    "\t\twhile queue:\n",
    "\t\t\tcurrent_node = heapq.heappop(queue)\n",
    "\n",
    "\t\t\t# Check if the current node's state matches the target state\n",
    "\t\t\tself.env.set_state(current_node.get_state())\n",
    "\t\t\tif self.env.is_terminal_state():\n",
    "\t\t\t\treturn reconstruct_path(current_node), steps\n",
    "\n",
    "\t\t\tif current_node.depth >= max_depth:\n",
    "\t\t\t\tcontinue\n",
    "\n",
    "\t\t\tlast_changed_node = self.env.decode_action(current_node.action)[1] if current_node.action is not None else None\n",
    "\t\t\tfor action in self.get_valid_actions(current_node.get_state()):\n",
    "\t\t\t\tsteps += 1\n",
    "\t\t\t\taction_type, start_node, target_node, coordinates = self.env.decode_action(action)\n",
    "\n",
    "\t\t\t\tif start_node == last_changed_node:\n",
    "\t\t\t\t\t# If the last changed node is the same as the current node, continue\n",
    "\t\t\t\t\tcontinue\n",
    "\n",
    "\t\t\t\tself.env.set_state(current_node.get_state())\n",
    "\t\t\t\tcost, child_state = self.env._step_cost(action_type, start_node, target_node, coordinates)\n",
    "\n",
    "\t\t\t\tif torch.equal(child_state['graph'].x, current_node.get_state()['graph'].x):\n",
    "\t\t\t\t\t# if state hasn't changed, continue\n",
    "\t\t\t\t\tcontinue\n",
    "\n",
    "\t\t\t\tchild_hash = state_to_hashable(child_state)\n",
    "\n",
    "\t\t\t\t# Calculate the accumulated cost for the current path\n",
    "\t\t\t\tnew_c_cost = current_node.c_cost + cost\n",
    "\t\t\t\th_cost = self.evaluate_state(child_state)\n",
    "\t\t\t\tnew_total_cost = new_c_cost + h_cost\n",
    "\n",
    "\t\t\t\t# Retain the node with better cost\n",
    "\t\t\t\tif child_hash not in visited or visited[child_hash] > new_total_cost:\n",
    "\t\t\t\t\tvisited[child_hash] = new_total_cost\n",
    "\t\t\t\t\tchild_node = self.node_class(\n",
    "\t\t\t\t\t\tstate=child_state, \n",
    "\t\t\t\t\t\tparent=current_node, \n",
    "\t\t\t\t\t\taction=action, \n",
    "\t\t\t\t\t\tcost_to_come=new_c_cost, \n",
    "\t\t\t\t\t\theuristic=h_cost,\n",
    "\t\t\t\t\t\tdepth=current_node.depth+1\n",
    "\t\t\t\t\t)\n",
    "\n",
    "\t\t\t\t\theapq.heappush(queue, child_node)\n",
    "\n",
    "\t\t\t# Goal Attempting\n",
    "\t\t\tself.env.set_state(current_node.get_state())\n",
    "\t\t\tfeasible_path, labbe_steps = Labbe(self.env).solve(verbose=0)\n",
    "\t\t\tsteps += labbe_steps\n",
    "\n",
    "\t\t\tfeasible_path_cost = current_node.c_cost\n",
    "\t\t\tself.env.set_state(current_node.get_state())\n",
    "\t\t\tfor action in feasible_path:\n",
    "\t\t\t\tfeasible_path_cost += self.env.step_cost(action)[0]\n",
    "\n",
    "\t\t\t# Remove all the nodes with their total cost is greater than the feasible path cost\n",
    "\t\t\tfor node in queue:\n",
    "\t\t\t\tif node.total_cost > feasible_path_cost:\n",
    "\t\t\t\t\tqueue.remove(node)\n",
    "\n",
    "\t\t\tif feasible_path_cost < best_cost:\n",
    "\t\t\t\tbest_plan = reconstruct_path(current_node) + feasible_path\n",
    "\t\t\t\tbest_cost = feasible_path_cost\n",
    "\n",
    "\t\treturn best_plan, steps  # No path found\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score(env, coor, obj):\n",
    "\tdis_obj = torch.norm(env.target_graph.x[obj, Indices.COORD] - coor).item()\n",
    "\treturn env.occupied_score(coor, obj) + dis_obj * env.normalization_factor\n",
    "\n",
    "class MctsNode:\n",
    "\tnode_counter = 0  # Static variable to assign unique IDs to each node\n",
    "\n",
    "\tdef __init__(self, state, valid_actions, parent=None, action=None, cost_to_come=0.0, c=1, depth=0):\n",
    "\t\tself.state = state\n",
    "\t\tself.parent = parent\n",
    "\t\tself.action = action\n",
    "\t\tself.children = {}\n",
    "\t\tself.visit_count = 0\n",
    "\t\tself.value = float('inf')\n",
    "\t\tself.value_upper = -float('inf')\n",
    "\t\tself.c_cost = cost_to_come\n",
    "\t\tself.c = c\n",
    "\t\tself.unexpanded_actions = valid_actions\n",
    "\t\tself.depth = depth\n",
    "\t\t\n",
    "\t\t# Assign a unique ID to each node\n",
    "\t\tself.id = MctsNode.node_counter\n",
    "\t\tMctsNode.node_counter += 1\n",
    "\n",
    "\tdef get_state(self):\n",
    "\t\treturn copy_state(self.state)\n",
    "\n",
    "\tdef is_fully_expanded(self):\n",
    "\t\treturn len(self.unexpanded_actions) == 0\n",
    "\n",
    "\tdef uct(self):\n",
    "\t\t# if self.visit_count == 0:\n",
    "\t\t# \treturn -float('inf')  # Prioritize unvisited nodes\n",
    "\t\t# visit_count = self.visit_count\n",
    "\t\tvisit_count = self.visit_count + 1\n",
    "\n",
    "\t\ttotal_cost_estimate = self.value #(self.parent.value - self.value) / (self.parent.value_upper - self.value_upper)\n",
    "\t\texploration_term = self.c * np.sqrt(2 * np.log(self.parent.visit_count) / visit_count)\n",
    "\n",
    "\t\treturn total_cost_estimate - exploration_term  # Minimization form\n",
    "\n",
    "class Sorp(SearchAlg):\n",
    "\tdef __init__(self, env, node_class=None):\n",
    "\t\tif node_class is None:\n",
    "\t\t\tnode_class = MctsNode\n",
    "\t\tsuper().__init__(env, node_class)\n",
    "\t\tself.num_buffers = 2\n",
    "\n",
    "\tdef get_remaining_nodes(self, state):\n",
    "\t\tstate_graph = state['graph']\n",
    "\n",
    "\t\tremaining_nodes = []\n",
    "\t\tfor k in range(state_graph.num_nodes):\n",
    "\t\t\ti = find_target_node(self.env.target_graph, k)\n",
    "\t\t\tif i is not None:\n",
    "\t\t\t\tif not is_edge_in_graph(state_graph, k, i):\n",
    "\t\t\t\t\tremaining_nodes.append(k)\n",
    "\t\t\telif find_target_node(state_graph, k) is not None:\n",
    "\t\t\t\tremaining_nodes.append(k)\n",
    "\t\t\telse:\n",
    "\t\t\t\tif not torch.equal(state_graph.x[k, Indices.COORD], self.env.target_graph.x[k, Indices.COORD]):\n",
    "\t\t\t\t\tremaining_nodes.append(k)\n",
    "\n",
    "\t\t# shuffle remaining nodes\n",
    "\t\trandom.shuffle(remaining_nodes)\n",
    "\n",
    "\t\treturn remaining_nodes\n",
    "\n",
    "\tdef get_empty_positions_with_target(self, ref_node, n=1):\n",
    "\t\tpositions = []\n",
    "\t\ttarget_p = self.env.target_graph.x[ref_node, Indices.COORD]\n",
    "\t\tif not self.env.is_coor_occupied(target_p, ref_node):\n",
    "\t\t\tpositions.append(flatten_pos(target_p, self.env.grid_size))\n",
    "\t\telse:\n",
    "\t\t\tif n == 0:\n",
    "\t\t\t\treturn positions\n",
    "\t\t\tall_positions = get_all_positions_in_env(self.env.grid_size, self.env.get_obj_size(ref_node))\n",
    "\t\t\t# all_positions = sorted(all_positions, key=lambda x: score(self.env, torch.tensor(x), ref_node))\n",
    "\t\t\trandom.shuffle(all_positions)\n",
    "\t\t\t\n",
    "\t\t\tfor position in all_positions:\n",
    "\t\t\t\tposition = torch.tensor(position)\n",
    "\t\t\t\tif not torch.equal(position, target_p) and not self.env.is_coor_occupied(position, ref_node):\n",
    "\t\t\t\t\tpositions.append(flatten_pos(position, self.env.grid_size))\n",
    "\t\t\t\t\tif len(positions) >= n:\n",
    "\t\t\t\t\t\tbreak\n",
    "\t\treturn positions\n",
    "\n",
    "\tdef get_valid_actions(self, state):\n",
    "\t\tself.env.set_state(state)\n",
    "\n",
    "\t\tstack_nums = max(int(0.6 * self.num_buffers), 1)\n",
    "\n",
    "\t\tnodes = list(range(self.env.num_nodes))\n",
    "\t\trandom.shuffle(nodes)\n",
    "\n",
    "\t\tvalid_actions = []\n",
    "\t\tfor k in self.get_remaining_nodes(state):\n",
    "\t\t\tvalid_stacks = []\n",
    "\t\t\tfor j in nodes:\n",
    "\t\t\t\tif k != j and not is_edge_in_graph(self.env.state_graph, k, j):\n",
    "\t\t\t\t\tif is_stable(self.env.state_graph.x, k, j):\n",
    "\t\t\t\t\t\tif is_empty_object(self.env.state_graph, j):\n",
    "\t\t\t\t\t\t\tvalid_stacks.append(self.env.encode_action('on', k, j, 0))\n",
    "\t\t\t\t\t\t\tif len(valid_stacks) >= stack_nums:\n",
    "\t\t\t\t\t\t\t\tbreak\n",
    "\n",
    "\t\t\tvalid_moves = []\n",
    "\t\t\tfor position in self.get_empty_positions_with_target(ref_node=k, n=self.num_buffers-len(valid_stacks)):\n",
    "\t\t\t\tvalid_moves.append(self.env.encode_action('move', k, k, position))\n",
    "\n",
    "\t\t\tvalid_actions += valid_stacks + valid_moves\n",
    "\n",
    "\t\treturn valid_actions\n",
    "\n",
    "\tdef select(self, node):\n",
    "\t\t# Accesses child nodes for best selection\n",
    "\t\treturn min(node.children.values(), key=lambda child: child.uct())\n",
    "\n",
    "\tdef expand(self, node):\n",
    "\t\tif node.is_fully_expanded():\n",
    "\t\t\treturn None  # Prevents further expansion if no actions remain\n",
    "\n",
    "\t\taction = node.unexpanded_actions.pop()\n",
    "\t\tself.env.set_state(node.get_state())\n",
    "\t\taction_type, start_node, target_node, coordinates = self.env.decode_action(action)\n",
    "\n",
    "\t\t# Continue expanding if the last changed node is the same as the current node\n",
    "\t\tif node.action is not None:\n",
    "\t\t\t_, last_changed_node, _, _ = self.env.decode_action(node.action)\n",
    "\t\t\tif last_changed_node == start_node:\n",
    "\t\t\t\treturn self.expand(node)\n",
    "\n",
    "\t\tcost, child_state = self.env._step_cost(action_type, start_node, target_node, coordinates)\n",
    "\n",
    "\t\t# Continue expanding if the state hasn't changed\n",
    "\t\tif torch.equal(child_state['graph'].x, node.state['graph'].x):\n",
    "\t\t\treturn self.expand(node)\n",
    "\n",
    "\t\tnew_c_cost = cost + node.c_cost\n",
    "\t\tchild_node = self.node_class(child_state, self.get_valid_actions(self.env.get_state()), node, action, new_c_cost, node.c, node.depth+1)\n",
    "\t\tnode.children[action] = child_node\n",
    "\t\treturn child_node\n",
    "\n",
    "\tdef rollout(self, state):\n",
    "\t\tself.env.set_state(state)\n",
    "\t\tcosts = 0\n",
    "\t\tfeasible_path, steps = LabbeS(self.env).solve(verbose=0)\n",
    "\t\tself.env.set_state(state)\n",
    "\t\tfor action in feasible_path:\n",
    "\t\t\tcosts += self.env.step_cost(action)[0]\n",
    "\n",
    "\t\treturn costs, steps\n",
    "\n",
    "\tdef rollout_live(self, node):\n",
    "\t\tcosts = 0\n",
    "\t\tself.env.set_state(node.get_state())\n",
    "\t\tfeasible_path, steps = LabbeS(self.env).solve(verbose=0)\n",
    "\t\tself.env.set_state(node.get_state())\n",
    "\t\tfor action in feasible_path:\n",
    "\t\t\tcost, child_state = self.env.step_cost(action)\n",
    "\t\t\tcosts += cost\n",
    "\t\t\t# remove action from the node's unexpanded actions\n",
    "\t\t\tif action in node.unexpanded_actions:\n",
    "\t\t\t\tnode.unexpanded_actions.remove(action)\n",
    "\t\t\t# add the new child to the node\n",
    "\t\t\tnew_c_cost = cost + node.c_cost\n",
    "\t\t\tchild_node = self.node_class(child_state, self.get_valid_actions(self.env.get_state()), node, action, new_c_cost, node.c, node.depth+1)\n",
    "\t\t\tnode.children[action] = child_node\n",
    "\t\t\tnode = child_node\n",
    "\n",
    "\t\treturn costs, steps, node\n",
    "\n",
    "\tdef backup_search(self, node, c_min):\n",
    "\t\twhile node is not None:\n",
    "\t\t\tnode.visit_count += 1\n",
    "\t\t\tif node.value > c_min:\n",
    "\t\t\t\tnode.value = c_min\n",
    "\t\t\tif node.value_upper < c_min:\n",
    "\t\t\t\tnode.value_upper = c_min\n",
    "\t\t\tnode = node.parent\n",
    "\n",
    "\tdef print_tree(self, node, depth=0, max_depth=float('inf'), ter=False):\n",
    "\t\tif depth >= max_depth:\n",
    "\t\t\treturn\n",
    "\n",
    "\t\t# Print the current node with indentation to show its depth in the tree\n",
    "\t\tindent = \"    \" * depth  # Four spaces per level of depth\n",
    "\t\tif node.id == 0:\n",
    "\t\t\tprint(f\"Root | Visits: {node.visit_count} | Value: {node.value:.2f}\")\n",
    "\t\telse:\n",
    "\t\t\tprint(f\"{indent}Node ID: {node.id} | Action: {node.action} | cost: {node.c_cost:.2f} | \"\n",
    "\t\t\t\t\tf\"Visits: {node.visit_count} | Value: {node.value:.2f}\")\n",
    "\n",
    "\t\t# Sort children by value estimate\n",
    "\t\tif ter:\n",
    "\t\t\taccepted_children = [child for child in node.children.values()]\n",
    "\t\t\tchildren = sorted(accepted_children, key=lambda child: child.value)\n",
    "\t\telse:\n",
    "\t\t\tchildren = sorted(node.children.values(), key=lambda child: child.value)\n",
    "\n",
    "\t\t# Recurse on children\n",
    "\t\tfor child in children:\n",
    "\t\t\tself.print_tree(child, depth + 1, max_depth, ter)\n",
    "\n",
    "\tdef find_best_path(self, ter=False):\n",
    "\t\tpath = []\n",
    "\t\tcurrent_node = self.root_node\n",
    "\t\tself.env.set_state(current_node.get_state())\n",
    "\n",
    "\t\twhile current_node.children:\n",
    "\t\t\tnext_node = min(current_node.children.values(), key=lambda child: child.value)\n",
    "\t\t\tpath.append(next_node.action)\n",
    "\t\t\tcurrent_node = next_node\n",
    "\t\t\tself.env.step_cost(next_node.action)\n",
    "\n",
    "\t\tif ter and not self.env.is_terminal_state():\n",
    "\t\t\tprint('Path isn\\'t completed in the iteration')\n",
    "\t\t\tprint(f'path continues from {path}')\n",
    "\t\t\tfeasible_path = LabbeS(self.env).solve(c=1, verbose=0)[0]\n",
    "\t\t\tself.env.set_state(current_node.get_state())\n",
    "\t\t\tfor action in feasible_path:\n",
    "\t\t\t\tpath.append(action)\n",
    "\t\t\tprint(f'new path: {path}')\n",
    "\t\treturn path\n",
    "\n",
    "\tdef loop(self, max_depth):\n",
    "\t\tnode = self.root_node\n",
    "\n",
    "\t\t# Selection\n",
    "\t\tself.env.set_state(node.get_state())\n",
    "\t\twhile node.is_fully_expanded() and not self.env.is_terminal_state():\n",
    "\t\t\tnode = self.select(node)\n",
    "\t\t\tself.env.set_state(node.get_state())\n",
    "\t\t\n",
    "\t\t# Expansion\n",
    "\t\tif not self.env.is_terminal_state():\n",
    "\t\t\tnode = self.expand(node)\n",
    "\t\t\tif node is None:\n",
    "\t\t\t\treturn 0\n",
    "\n",
    "\t\t# Simulation (Rollout)\n",
    "\t\tc_cost = node.c_cost\n",
    "\t\tterminal_cost, steps = 0, 0\n",
    "\t\tif self.env.is_terminal_state():\n",
    "\t\t\tc_rollout = terminal_cost\n",
    "\t\telif node.depth >= max_depth:\n",
    "\t\t\tc_rollout = float('inf')\n",
    "\t\telse:\n",
    "\t\t\tc_rollout, steps, node = self.rollout_live(node)\n",
    "\n",
    "\t\tc_min = c_rollout + c_cost\n",
    "\n",
    "\t\t# Backpropagation\n",
    "\t\tself.backup_search(node, c_min)\n",
    "\n",
    "\t\treturn steps\n",
    "\n",
    "\tdef solve(self, iterations, max_depth=100, verbose=1, c=1, num_buffers=2):\n",
    "\t\tself.num_buffers = num_buffers\n",
    "\t\tself.root_node = self.node_class(self.env.get_state(), self.get_valid_actions(self.env.get_state()), c=c)\n",
    "\t\tlast_value = self.root_node.value\n",
    "\t\t\n",
    "\t\tsteps, iteration = 0, 0\n",
    "\t\tif verbose > 0:\n",
    "\t\t\tpbar = tqdm(total=None, unit='iterations')\n",
    "\t\twhile iteration < iterations:\n",
    "\t\t\titeration += 1\n",
    "\t\t\tsteps += self.loop(max_depth) + 1\n",
    "\t\t\tif verbose > 0:\n",
    "\t\t\t\tpbar.update(1)\n",
    "\t\t\tif iteration != 0 and iteration % 100 == 0:\n",
    "\t\t\t\tif abs(last_value - self.root_node.value) < 0.01:\n",
    "\t\t\t\t\tbreak\n",
    "\t\t\t\t\n",
    "\t\t\t\tlast_value = self.root_node.value\n",
    "\n",
    "\t\tif verbose > 0:\n",
    "\t\t\tpbar.close()\n",
    "\n",
    "\t\treturn self.find_best_path(ter=True), steps\n",
    "\n",
    "class MctsNode2:\n",
    "\tnode_counter = 0  # Static variable to assign unique IDs to each node\n",
    "\n",
    "\tdef __init__(self, state, valid_actions, parent=None, action=None, cost=0.0, cost_to_come=0.0, c=1, depth=0):\n",
    "\t\tself.state = state\n",
    "\t\tself.parent = parent\n",
    "\t\tself.action = action\n",
    "\t\tself.children = {}\n",
    "\t\tself.visit_count = 0\n",
    "\t\tself.value = 0\n",
    "\t\tself.cost = cost\n",
    "\t\tself.cost_to_come = cost_to_come\n",
    "\t\tself.c = c\n",
    "\t\tself.unexpanded_actions = valid_actions\n",
    "\t\tself.depth = depth\n",
    "\t\t\n",
    "\t\t# Assign a unique ID to each node\n",
    "\t\tself.id = MctsNode2.node_counter\n",
    "\t\tMctsNode2.node_counter += 1\n",
    "\n",
    "\tdef get_state(self):\n",
    "\t\treturn copy_state(self.state)\n",
    "\n",
    "\tdef is_fully_expanded(self):\n",
    "\t\treturn len(self.unexpanded_actions) == 0\n",
    "\n",
    "\tdef uct(self, c_min=0, c_max=1):\n",
    "\t\tvisit_count = self.visit_count + 1\n",
    "\n",
    "\t\ttotal_cost_estimate = ( (self.cost_to_come + self.value / visit_count) - c_min ) / (c_max - c_min)\n",
    "\t\texploration_term = self.c * np.sqrt(2 * np.log(self.parent.visit_count) / visit_count)\n",
    "\n",
    "\t\treturn total_cost_estimate - exploration_term  # Minimization form\n",
    "\n",
    "class Sorp2(Sorp):\n",
    "\tdef __init__(self, env):\n",
    "\t\tsuper().__init__(env, MctsNode2)\n",
    "\t\tself.num_buffers = 2\n",
    "\n",
    "\tdef get_empty_positions_with_target(self, ref_node, n=1):\n",
    "\t\tpositions = []\n",
    "\t\ttarget_p = self.env.target_graph.x[ref_node, Indices.COORD]\n",
    "\t\tif not self.env.is_coor_occupied(target_p, ref_node):\n",
    "\t\t\tpositions.append(flatten_pos(target_p, self.env.grid_size))\n",
    "\t\telse:\n",
    "\t\t\tif n == 0:\n",
    "\t\t\t\treturn positions\n",
    "\t\t\tall_positions = get_all_positions_in_env(self.env.grid_size, self.env.get_obj_size(ref_node))\n",
    "\t\t\t# all_positions = sorted(all_positions, key=lambda x: score(self.env, torch.tensor(x), ref_node))\n",
    "\t\t\trandom.shuffle(all_positions)\n",
    "\t\t\t\n",
    "\t\t\tfor position in all_positions:\n",
    "\t\t\t\tposition = torch.tensor(position)\n",
    "\t\t\t\tif not torch.equal(position, target_p) and not self.env.is_coor_occupied(position, ref_node):\n",
    "\t\t\t\t\tpositions.append(flatten_pos(position, self.env.grid_size))\n",
    "\t\t\t\t\tif len(positions) >= n:\n",
    "\t\t\t\t\t\tbreak\n",
    "\t\treturn positions\n",
    "\n",
    "\tdef select(self, node):\n",
    "\t\t# Accesses child nodes for best selection\n",
    "\t\tif self.c_min == np.inf or self.c_max == self.c_min:\n",
    "\t\t\treturn min(node.children.values(), key=lambda child: child.uct())\n",
    "\t\telse:\n",
    "\t\t\treturn min(node.children.values(), key=lambda child: child.uct(self.c_min, self.c_max))\n",
    "\n",
    "\tdef expand(self, node):\n",
    "\t\tif node.is_fully_expanded():\n",
    "\t\t\treturn None  # Prevents further expansion if no actions remain\n",
    "\n",
    "\t\taction = node.unexpanded_actions.pop()\n",
    "\t\tself.env.set_state(node.get_state())\n",
    "\t\taction_type, start_node, target_node, coordinates = self.env.decode_action(action)\n",
    "\n",
    "\t\t# Continue expanding if the last changed node is the same as the current node\n",
    "\t\tif node.action is not None:\n",
    "\t\t\t_, last_changed_node, _, _ = self.env.decode_action(node.action)\n",
    "\t\t\tif last_changed_node == start_node:\n",
    "\t\t\t\treturn self.expand(node)\n",
    "\n",
    "\t\tcost, child_state = self.env._step_cost(action_type, start_node, target_node, coordinates)\n",
    "\n",
    "\t\t# Continue expanding if the state hasn't changed\n",
    "\t\tif torch.equal(child_state['graph'].x, node.state['graph'].x):\n",
    "\t\t\treturn self.expand(node)\n",
    "\n",
    "\t\tchild_node = self.node_class(\n",
    "\t\t\tstate=child_state, \n",
    "\t\t\tvalid_actions=self.get_valid_actions(self.env.get_state()), \n",
    "\t\t\tparent=node, \n",
    "\t\t\taction=action, \n",
    "\t\t\tcost=cost.item(), \n",
    "\t\t\tcost_to_come=node.cost_to_come+cost.item(),\n",
    "\t\t\tc=node.c, \n",
    "\t\t\tdepth=node.depth+1\n",
    "\t\t)\n",
    "\t\tnode.children[action] = child_node\n",
    "\n",
    "\t\treturn child_node\n",
    "\n",
    "\tdef rollout(self, node):\n",
    "\t\tc_rollout = 0\n",
    "\t\tself.env.set_state(node.get_state())\n",
    "\t\tfeasible_path, steps = LabbeS(self.env).solve(verbose=0)\n",
    "\t\tself.env.set_state(node.get_state())\n",
    "\t\tfor i, action in enumerate(feasible_path):\n",
    "\t\t\tcost, child_state = self.env.step_cost(action)\n",
    "\t\t\tc_rollout += cost.item()\n",
    "\t\t\tif i == 0:\n",
    "\t\t\t\t# remove action from the node's unexpanded actions\n",
    "\t\t\t\tif action in node.unexpanded_actions:\n",
    "\t\t\t\t\tnode.unexpanded_actions.remove(action)\n",
    "\t\t\t\t# add the new child to the node\n",
    "\t\t\t\tchild_node = self.node_class(\n",
    "\t\t\t\t\tstate=child_state, \n",
    "\t\t\t\t\tvalid_actions=self.get_valid_actions(self.env.get_state()), \n",
    "\t\t\t\t\tparent=node, \n",
    "\t\t\t\t\taction=action, \n",
    "\t\t\t\t\tcost=cost.item(), \n",
    "\t\t\t\t\tcost_to_come=node.cost_to_come+cost.item(),\n",
    "\t\t\t\t\tc=node.c, \n",
    "\t\t\t\t\tdepth=node.depth+1\n",
    "\t\t\t\t)\n",
    "\t\t\t\tnode.children[action] = child_node\n",
    "\n",
    "\t\treturn c_rollout, steps, feasible_path, child_node\n",
    "\n",
    "\tdef backup_search(self, node, value):\n",
    "\t\twhile node is not None:\n",
    "\t\t\tnode.visit_count += 1\n",
    "\t\t\tnode.value += value\n",
    "\t\t\tnode = node.parent\n",
    "\n",
    "\tdef print_tree(self, node, depth=0, max_depth=float('inf'), ter=False):\n",
    "\t\tif depth >= max_depth:\n",
    "\t\t\treturn\n",
    "\n",
    "\t\t# Print the current node with indentation to show its depth in the tree\n",
    "\t\tindent = \"    \" * depth  # Four spaces per level of depth\n",
    "\t\tif node.id == 0:\n",
    "\t\t\tprint(f\"Root | Visits: {node.visit_count} | Value: {node.value:.2f}\")\n",
    "\t\telse:\n",
    "\t\t\tprint(f\"{indent}Node ID: {node.id} | Action: {node.action} | CtC: {node.cost_to_come:.2f} | \"\n",
    "\t\t\t\t\tf\"Visits: {node.visit_count} | Value: {node.value:.2f}\")\n",
    "\n",
    "\t\t# Sort children by value estimate\n",
    "\t\tif ter:\n",
    "\t\t\taccepted_children = [child for child in node.children.values()]\n",
    "\t\t\tchildren = sorted(accepted_children, key=lambda child: child.value)\n",
    "\t\telse:\n",
    "\t\t\tchildren = sorted(node.children.values(), key=lambda child: child.value)\n",
    "\n",
    "\t\t# Recurse on children\n",
    "\t\tfor child in children:\n",
    "\t\t\tself.print_tree(child, depth + 1, max_depth, ter)\n",
    "\n",
    "\tdef find_best_path(self, ter=False):\n",
    "\t\treturn reconstruct_path(self.best_plan[0])+self.best_plan[1]\n",
    "\n",
    "\tdef loop(self, max_depth):\n",
    "\t\tnode = self.root_node\n",
    "\n",
    "\t\t# Selection\n",
    "\t\tself.env.set_state(node.get_state())\n",
    "\t\twhile node.is_fully_expanded() and not self.env.is_terminal_state():\n",
    "\t\t\tnode = self.select(node)\n",
    "\t\t\tself.env.set_state(node.get_state())\n",
    "\t\t\n",
    "\t\t# Expansion\n",
    "\t\tif not self.env.is_terminal_state():\n",
    "\t\t\tnode = self.expand(node)\n",
    "\t\t\tif node is None:\n",
    "\t\t\t\treturn 0\n",
    "\n",
    "\t\t# Simulation (Rollout)\n",
    "\t\tfeasible_plan = []\n",
    "\t\tsteps = 0\n",
    "\t\tif self.env.is_terminal_state():\n",
    "\t\t\tvalue = 0\n",
    "\t\telse:\n",
    "\t\t\tc_rollout, steps, feasible_plan, child_node = self.rollout(node)\n",
    "\n",
    "\t\t\tnew_cost = c_rollout + node.cost_to_come\n",
    "\t\t\tself.c_max = max(self.c_max, new_cost)\n",
    "\t\t\tif new_cost < self.c_min:\n",
    "\t\t\t\tself.best_plan = (node, feasible_plan)\n",
    "\t\t\t\tself.c_min = new_cost\n",
    "\n",
    "\t\t\tnode = child_node\n",
    "\t\t\tvalue = c_rollout - node.cost\n",
    "\n",
    "\t\t# Backpropagation\n",
    "\t\tself.backup_search(node, value)\n",
    "\n",
    "\t\treturn steps\n",
    "\n",
    "\tdef solve(self, iterations, max_depth=100, verbose=1, c=1, num_buffers=2):\n",
    "\t\tself.num_buffers = num_buffers\n",
    "\t\tself.root_node = self.node_class(\n",
    "\t\t\tstate=self.env.get_state(), \n",
    "\t\t\tvalid_actions=self.get_valid_actions(self.env.get_state()), \n",
    "\t\t\tc=c\n",
    "\t\t)\n",
    "\t\tself.c_max = -np.inf\n",
    "\t\tself.c_min = np.inf\n",
    "\t\tself.best_plan = None\n",
    "\n",
    "\t\twindow_last_values = []\n",
    "\t\twindow_last_values.append(self.root_node.value)\n",
    "\t\t\n",
    "\t\tsteps, iteration = 0, 0\n",
    "\t\tif verbose > 0:\n",
    "\t\t\tpbar = tqdm(total=None, unit='iterations')\n",
    "\t\twhile iteration < iterations:\n",
    "\t\t\titeration += 1\n",
    "\t\t\tsteps += self.loop(max_depth) + 1\n",
    "\t\t\tif verbose > 0:\n",
    "\t\t\t\tpbar.update(1)\n",
    "\t\t\tif iteration != 0 and iteration % 20 == 0:\n",
    "\t\t\t\tif self.c_max == self.c_min:\n",
    "\t\t\t\t\tshit_value = np.inf\n",
    "\t\t\t\telse:\n",
    "\t\t\t\t\tshit_value = ((self.root_node.value / self.root_node.visit_count) - self.c_min) / (self.c_max - self.c_min)\n",
    "\t\t\t\t# print(f'v_shit: {shit_value:.3f} | c_min: {self.c_min:.3f} | c_max: {self.c_max:.3f}')\n",
    "\t\t\t\twindow_last_values.append(self.c_min)\n",
    "\t\t\t\tif len(window_last_values) > 5:\n",
    "\t\t\t\t\twindow_last_values.pop(0)\n",
    "\t\t\t\t\tif len(set(window_last_values)) == 1:\n",
    "\t\t\t\t\t\tbreak\n",
    "\n",
    "\t\tif verbose > 0:\n",
    "\t\t\tpbar.close()\n",
    "\n",
    "\t\treturn self.find_best_path(ter=True), steps\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def refine_until_convergence(env, plan, initial_graph, target_graph, alg, verbose=0):\n",
    "\tstart_time = time.time()\n",
    "\tbest_cost = env_cost(env, plan, initial_graph, target_graph, log=True)\n",
    "\twhile True:\n",
    "\t\tprint('-------------------------')\n",
    "\t\tif alg == 'Strap' or alg == 'Labbe':\n",
    "\t\t\trefined_plan = plan_refinement(env, plan, initial_graph, target_graph, verbose=verbose)\n",
    "\t\telif alg == 'Sorp' or alg == 'Sorp2' or alg == 'A_star' or alg == 'LabbeS':\n",
    "\t\t\trefined_plan = plan_refinement_stack(env, plan, initial_graph, target_graph, verbose=verbose)\n",
    "\t\telse:\n",
    "\t\t\traise ValueError('Invalid algorithm')\n",
    "\n",
    "\t\tif plan == refined_plan:\n",
    "\t\t\tbreak\n",
    "\n",
    "\t\tcost = env_cost(env, refined_plan, initial_graph, target_graph, log=True)\n",
    "\t\tif cost < best_cost:\n",
    "\t\t\tif verbose > 0:\n",
    "\t\t\t\tprint(f'cost get better from {best_cost:.3f} to {cost:.3f}')\n",
    "\t\t\tbest_cost = cost\n",
    "\n",
    "\t\tplan = refined_plan\n",
    "\n",
    "\tend_time = time.time()\n",
    "\treturn plan, best_cost, end_time - start_time\n",
    "\n",
    "def plan_refinement_stack(env, plan, initial_graph, target_graph, verbose=0):\n",
    "\tpre_costs = 0\n",
    "\taction_sequence = []\n",
    "\tenv.reset(initial_graph, target_graph)\n",
    "\tfor action in plan:\n",
    "\t\ta_type, k, l, coordinates = env.decode_action(action)\n",
    "\t\tp_pick = env.state_graph.x[k, Indices.COORD].clone()\n",
    "\t\tif a_type == 'move':\n",
    "\t\t\tp_place = unflatten_pos(coordinates, env.grid_size)\n",
    "\t\telif a_type == 'on':\n",
    "\t\t\tp_place = env.state_graph.x[l, Indices.COORD].clone()\n",
    "\t\telse:\n",
    "\t\t\traise ValueError('Invalid action type')\n",
    "\n",
    "\t\taction_sequence.append({\n",
    "\t\t\t'type': a_type,\n",
    "\t\t\t'k': k,\n",
    "\t\t\t'l': l,\n",
    "\t\t\t'p_pick': p_pick,\n",
    "\t\t\t'p_place': p_place\n",
    "\t\t})\n",
    "\t\tpre_costs += env.step_cost(action)[0]\n",
    "\n",
    "\tenv.reset(initial_graph, target_graph)\n",
    "\tB = {}\n",
    "\tH = {0: (env.get_state(), env.table)} # arrangement history\n",
    "\tfor i in range(len(action_sequence)):\n",
    "\t\tk = action_sequence[i]['k']\n",
    "\n",
    "\t\tif k in B:\t# if object k was moved\n",
    "\t\t\tbIdx = B[k]\t# previous action index on k\n",
    "\n",
    "\t\t\t# Find constraints\n",
    "\t\t\tC = []\n",
    "\n",
    "\t\t\t# Occupied possitions in the action index bIdx\n",
    "\t\t\tfor j in range(env.grid_size * env.grid_size):\n",
    "\t\t\t\tposition = unflatten_pos(j, env.grid_size)\n",
    "\t\t\t\tif env.is_coor_occupied(position, k, H[bIdx][1]):\n",
    "\t\t\t\t\tC.append(position)\n",
    "\n",
    "\t\t\t# Ocuupied buffers in the action index bIdx to i-1\n",
    "\t\t\tsize_k = env.get_obj_size(k)\n",
    "\t\t\tfor j in range(bIdx, i):\n",
    "\t\t\t\tif action_sequence[j]['type'] == 'on':\n",
    "\t\t\t\t\t# if the action is stack, continue\n",
    "\t\t\t\t\tcontinue\n",
    "\t\t\t\t\n",
    "\t\t\t\tsize = env.get_obj_size(action_sequence[j]['k'])\n",
    "\t\t\t\tsize = (size[0]+size_k[0]-1, size[1]+size_k[1]-1)\n",
    "\t\t\t\tidx = in_table_index(action_sequence[j]['p_place'], size)\n",
    "\t\t\t\tfor position in itertools.product(range(idx[0].start, idx[0].stop), range(idx[1].start, idx[1].stop)):\n",
    "\t\t\t\t\tposition = torch.tensor(position, dtype=torch.float32)\n",
    "\t\t\t\t\tC.append(position)\n",
    "\n",
    "\t\t\tempty_objs = []\n",
    "\t\t\tfor obj in range(env.num_nodes):\n",
    "\t\t\t\tif is_stable(H[0][0]['graph'].x, k, obj):\n",
    "\t\t\t\t\tis_empty = True\n",
    "\t\t\t\t\tfor j in range(bIdx, i):\n",
    "\t\t\t\t\t\tif not is_empty_object(H[j][0]['graph'], obj):\n",
    "\t\t\t\t\t\t\tis_empty = False\n",
    "\t\t\t\t\t\t\tbreak\n",
    "\t\t\t\t\tif is_empty:\n",
    "\t\t\t\t\t\tempty_objs.append(obj)\n",
    "\n",
    "\t\t\tp1 = action_sequence[bIdx]['p_pick']\n",
    "\t\t\tp2 = action_sequence[i-1]['p_place']\n",
    "\t\t\tp3 = action_sequence[bIdx+1]['p_pick']\n",
    "\t\t\tp4 = action_sequence[i]['p_place']\n",
    "\n",
    "\t\t\t# Generate a buffer set under constraint C\n",
    "\t\t\tP = []\n",
    "\t\t\tfor j in range(env.grid_size * env.grid_size):\n",
    "\t\t\t\tp = unflatten_pos(j, env.grid_size)\n",
    "\t\t\t\tif not any(torch.equal(p, c) for c in C):\n",
    "\t\t\t\t\tP.append(p)\n",
    "\t\t\tif len(P) == 0:\n",
    "\t\t\t\tif verbose > 0:\n",
    "\t\t\t\t\tprint(f'No feasible buffer set')\n",
    "\t\t\t\n",
    "\t\t\t# Find the best buffer\n",
    "\t\t\tif action_sequence[bIdx]['type'] == 'on':\n",
    "\t\t\t\tp_to_buff = action_sequence[bIdx]['p_place']\n",
    "\t\t\t\tcontainer = find_base_node(H[i][0]['graph'], k)\n",
    "\t\t\t\tp_i = H[i][0]['graph'].x[container, Indices.COORD].clone()\n",
    "\t\t\t\tmin_cost = torch.norm(p1 - p_to_buff) + torch.norm(p2 - p_i) + torch.norm(p3 - p_to_buff) + torch.norm(p4 - p_i)\n",
    "\t\t\telse:\n",
    "\t\t\t\tp = action_sequence[bIdx]['p_place'].clone()\n",
    "\t\t\t\tmin_cost = torch.norm(p1 - p) + torch.norm(p2 - p) + torch.norm(p3 - p) + torch.norm(p4 - p)\n",
    "\n",
    "\t\t\tbest_p = None\n",
    "\t\t\tfor p in P:\n",
    "\t\t\t\tcost = torch.norm(p1 - p) + torch.norm(p2 - p) + torch.norm(p3 - p) + torch.norm(p4 - p)\n",
    "\t\t\t\tif cost < min_cost:\n",
    "\t\t\t\t\tbest_p = p.clone()\n",
    "\t\t\t\t\tmin_cost = cost\n",
    "\n",
    "\t\t\tbest_obj = None\n",
    "\t\t\tfor empty_obj in empty_objs:\n",
    "\t\t\t\tp_to_buff = H[bIdx][0]['graph'].x[empty_obj, Indices.COORD].clone()\n",
    "\t\t\t\tp_i = H[i][0]['graph'].x[empty_obj, Indices.COORD].clone()\n",
    "\t\t\t\tcost = torch.norm(p1 - p_to_buff) + torch.norm(p2 - p_i) + torch.norm(p3 - p_to_buff) + torch.norm(p4 - p_i)\n",
    "\t\t\t\tif cost < min_cost:\n",
    "\t\t\t\t\tmin_cost = cost\n",
    "\t\t\t\t\tbest_obj = empty_obj\n",
    "\n",
    "\t\t\tif best_obj is not None:\n",
    "\t\t\t\tif verbose > 0:\n",
    "\t\t\t\t\tif action_sequence[bIdx]['type'] == 'on':\n",
    "\t\t\t\t\t\tlast_obj = action_sequence[bIdx]['l']\n",
    "\t\t\t\t\t\tprint(f'Buffer of object {k} changed from obj {last_obj} to obj {best_obj}')\n",
    "\t\t\t\t\telse:\n",
    "\t\t\t\t\t\tlast_pos = action_sequence[bIdx]['p_place']\n",
    "\t\t\t\t\t\tprint(f'Buffer of object {k} changed from pos {last_pos} to obj {best_obj}')\n",
    "\n",
    "\t\t\t\taction_sequence[bIdx] = {\n",
    "\t\t\t\t\t'type': 'on',\n",
    "\t\t\t\t\t'k': k,\n",
    "\t\t\t\t\t'l': best_obj,\n",
    "\t\t\t\t\t'p_pick': action_sequence[bIdx]['p_pick'].clone(),\n",
    "\t\t\t\t\t'p_place': H[bIdx][0]['graph'].x[best_obj, Indices.COORD].clone()\n",
    "\t\t\t\t}\n",
    "\t\t\t\taction_sequence[i] = {\n",
    "\t\t\t\t\t'type': 'move',\n",
    "\t\t\t\t\t'k': k,\n",
    "\t\t\t\t\t'l': k,\n",
    "\t\t\t\t\t'p_pick': H[i][0]['graph'].x[best_obj, Indices.COORD].clone(),\n",
    "\t\t\t\t\t'p_place': action_sequence[i]['p_place'].clone()\n",
    "\t\t\t\t}\n",
    "\t\t\t\tbreak\n",
    "\t\t\telif best_p is not None:\n",
    "\t\t\t\tif verbose > 0:\n",
    "\t\t\t\t\tif action_sequence[bIdx]['type'] == 'on':\n",
    "\t\t\t\t\t\tlast_obj = action_sequence[bIdx]['l']\n",
    "\t\t\t\t\t\tprint(f'Buffer of object {k} changed from obj {last_obj} to pos {best_p}')\n",
    "\t\t\t\t\telse:\n",
    "\t\t\t\t\t\tlast_pos = action_sequence[bIdx]['p_place']\n",
    "\t\t\t\t\t\tprint(f'Buffer of object {k} changed from pos {last_pos} to pos {best_p}')\n",
    "\n",
    "\t\t\t\taction_sequence[bIdx] = {\n",
    "\t\t\t\t\t'type': 'move',\n",
    "\t\t\t\t\t'k': k,\n",
    "\t\t\t\t\t'l': k,\n",
    "\t\t\t\t\t'p_pick': action_sequence[bIdx]['p_pick'].clone(),\n",
    "\t\t\t\t\t'p_place': best_p\n",
    "\t\t\t\t}\n",
    "\t\t\t\taction_sequence[i] = {\n",
    "\t\t\t\t\t'type': 'move',\n",
    "\t\t\t\t\t'k': k,\n",
    "\t\t\t\t\t'l': k,\n",
    "\t\t\t\t\t'p_pick': best_p,\n",
    "\t\t\t\t\t'p_place': action_sequence[i]['p_place'].clone()\n",
    "\t\t\t\t}\n",
    "\t\t\t\tbreak\n",
    "\n",
    "\t\tenv.step_cost(plan[i])\n",
    "\t\tH[i+1] = (env.get_state(), env.table)\n",
    "\t\tB[k] = i\n",
    "\n",
    "\trefined_actions = []\n",
    "\tfor action in action_sequence:\n",
    "\t\tif action['type'] == 'on':\n",
    "\t\t\trefined_actions.append(env.encode_action('on', action['k'], action['l'], 0))\n",
    "\t\telse:\n",
    "\t\t\trefined_actions.append(env.encode_action('move', action['k'], action['k'], action['p_place']))\n",
    "\n",
    "\treturn refined_actions\n",
    "\n",
    "def plan_refinement(env, plan, initial_graph, target_graph, verbose=0):\n",
    "\tpre_costs = 0\n",
    "\taction_sequence = []\n",
    "\tenv.reset(initial_graph, target_graph)\n",
    "\tfor action in plan:\n",
    "\t\taction_type, k, _, coordinates = env.decode_action(action)\n",
    "\t\tif action_type == 'on':\n",
    "\t\t\treturn plan\n",
    "\t\tp_pick = env.state_graph.x[k, Indices.COORD].clone()\n",
    "\t\tp_place = unflatten_pos(coordinates, env.grid_size)\n",
    "\t\t\n",
    "\t\taction_sequence.append({\n",
    "\t\t\t'k': k,\n",
    "\t\t\t'p_pick': p_pick,\n",
    "\t\t\t'p_place': p_place\n",
    "\t\t})\n",
    "\t\tpre_costs += env.step_cost(action)[0]\n",
    "\n",
    "\tenv.reset(initial_graph, target_graph)\n",
    "\tB = {}\n",
    "\tH = {0: (env.get_state(), env.table)} # arrangement history\n",
    "\tfor i in range(len(action_sequence)):\n",
    "\t\tk = action_sequence[i]['k']\n",
    "\n",
    "\t\tif k in B:\t# if object k was moved\n",
    "\t\t\tbIdx = B[k]\t# previous action index on k\n",
    "\n",
    "\t\t\t# Find constraints\n",
    "\t\t\tC = []\n",
    "\n",
    "\t\t\t# Occupied possitions in the action index bIdx\n",
    "\t\t\tfor j in range(env.grid_size * env.grid_size):\n",
    "\t\t\t\tposition = unflatten_pos(j, env.grid_size)\n",
    "\t\t\t\tif env.is_coor_occupied(position, k, H[bIdx][1]):\n",
    "\t\t\t\t\tC.append(position)\n",
    "\n",
    "\t\t\t# Ocuupied buffers in the action index bIdx to i-1\n",
    "\t\t\tsize_k = env.get_obj_size(k)\n",
    "\t\t\tfor j in range(bIdx, i):\n",
    "\t\t\t\tsize = env.get_obj_size(action_sequence[j]['k'])\n",
    "\t\t\t\tsize = (size[0]+size_k[0]-1, size[1]+size_k[1]-1)\n",
    "\t\t\t\tidx = in_table_index(action_sequence[j]['p_place'], size)\n",
    "\t\t\t\tfor position in itertools.product(range(idx[0].start, idx[0].stop), range(idx[1].start, idx[1].stop)):\n",
    "\t\t\t\t\tposition = torch.tensor(position, dtype=torch.float32)\n",
    "\t\t\t\t\tC.append(position)\n",
    "\n",
    "\t\t\tp1 = action_sequence[bIdx]['p_pick']\n",
    "\t\t\tp2 = action_sequence[i-1]['p_place']\n",
    "\t\t\tp3 = action_sequence[bIdx+1]['p_pick']\n",
    "\t\t\tp4 = action_sequence[i]['p_place']\n",
    "\n",
    "\t\t\t# Generate a buffer set under constraint C\n",
    "\t\t\tP = []\n",
    "\t\t\tfor j in range(env.grid_size * env.grid_size):\n",
    "\t\t\t\tp = unflatten_pos(j, env.grid_size)\n",
    "\t\t\t\tif not any(torch.equal(p, c) for c in C):\n",
    "\t\t\t\t\tP.append(p)\n",
    "\t\t\tif len(P) == 0:\n",
    "\t\t\t\tif verbose > 0:\n",
    "\t\t\t\t\tprint(f'No feasible buffer set')\n",
    "\t\t\t\n",
    "\t\t\t# Find the best buffer\n",
    "\t\t\tp = action_sequence[bIdx]['p_place'].clone()\n",
    "\t\t\tmin_cost = torch.norm(p1 - p) + torch.norm(p2 - p) + torch.norm(p3 - p) + torch.norm(p4 - p)\n",
    "\n",
    "\t\t\tbest_p = None\n",
    "\t\t\tfor p in P:\n",
    "\t\t\t\tcost = torch.norm(p1 - p) + torch.norm(p2 - p) + torch.norm(p3 - p) + torch.norm(p4 - p)\n",
    "\t\t\t\tif cost < min_cost:\n",
    "\t\t\t\t\tbest_p = p.clone()\n",
    "\t\t\t\t\tmin_cost = cost\n",
    "\n",
    "\t\t\tif best_p is not None:\n",
    "\t\t\t\tif verbose > 0:\n",
    "\t\t\t\t\tlast_pos = action_sequence[bIdx]['p_place']\n",
    "\t\t\t\t\tprint(f'Buffer of object {k} changed from pos {last_pos} to pos {best_p}')\n",
    "\n",
    "\t\t\t\taction_sequence[bIdx] = {\n",
    "\t\t\t\t\t'k': k,\n",
    "\t\t\t\t\t'p_pick': action_sequence[bIdx]['p_pick'].clone(),\n",
    "\t\t\t\t\t'p_place': best_p\n",
    "\t\t\t\t}\n",
    "\t\t\t\taction_sequence[i] = {\n",
    "\t\t\t\t\t'k': k,\n",
    "\t\t\t\t\t'p_pick': best_p,\n",
    "\t\t\t\t\t'p_place': action_sequence[i]['p_place'].clone()\n",
    "\t\t\t\t}\n",
    "\t\t\t\tbreak\n",
    "\n",
    "\t\tenv.step_cost(plan[i])\n",
    "\t\tH[i+1] = (env.get_state(), env.table)\n",
    "\t\tB[k] = i\n",
    "\n",
    "\trefined_actions = []\n",
    "\tfor action in action_sequence:\n",
    "\t\trefined_actions.append(env.encode_action('move', action['k'], action['k'], action['p_place']))\n",
    "\n",
    "\treturn refined_actions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mode is manipulator\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x250 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "env = ContinuousEnv(num_nodes=5, grid_size=20, num_labels=5)\n",
    "env.reset(stack=False)\n",
    "initial_graph, target_graph = copy_graph(env.initial_graph), copy_graph(env.target_graph)\n",
    "env.reset(initial_graph, target_graph)\n",
    "env.render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------Sorp2--------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100iterations [00:32,  3.10iterations/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "optimal_actions: [12, 447, 1943, 207, 1434, 1168] in 2743 steps\n",
      "elapsed time: 32.39s\n",
      "3 -> 0 | cost: 1.043 | done: False\n",
      "Moved 1 to: [1. 7.] | cost: 0.600 | done: False\n",
      "Moved 4 to: [16.  3.] | cost: 1.033 | done: False\n",
      "Moved 0 to: [9. 7.] | cost: 0.882 | done: False\n",
      "Moved 3 to: [10. 14.] | cost: 0.554 | done: False\n",
      "Moved 2 to: [17.  8.] | cost: 1.075 | done: True\n",
      "episode cost: 5.187\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "optimal_actions = evaluate_alg(env, Sorp2, initial_graph, target_graph, iterations=1000, num_buffers=4, c=1, verbose=1);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------Sorp--------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "200iterations [00:34,  5.83iterations/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "optimal_actions: [447, 16, 207, 1434, 1168, 1943] in 2840 steps\n",
      "elapsed time: 34.42s\n",
      "Moved 1 to: [1. 7.] | cost: 0.726 | done: False\n",
      "4 -> 0 | cost: 0.799 | done: False\n",
      "Moved 0 to: [9. 7.] | cost: 0.341 | done: False\n",
      "Moved 3 to: [10. 14.] | cost: 1.054 | done: False\n",
      "Moved 2 to: [17.  8.] | cost: 0.693 | done: False\n",
      "Moved 4 to: [16.  3.] | cost: 1.466 | done: True\n",
      "episode cost: 5.078\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "optimal_actions = evaluate_alg(env, Sorp, initial_graph, target_graph, iterations=1000, num_buffers=4, c=1, verbose=1);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------Strap--------\n",
      "max depth: 6\n",
      "optimal_actions: [1395, 447, 1943, 1168, 207, 1434] in 61689 steps\n",
      "elapsed time: 248.94s\n",
      "Moved 3 to: [ 8. 15.] | cost: 1.171 | done: False\n",
      "Moved 1 to: [1. 7.] | cost: 0.761 | done: False\n",
      "Moved 4 to: [16.  3.] | cost: 1.033 | done: False\n",
      "Moved 2 to: [17.  8.] | cost: 0.876 | done: False\n",
      "Moved 0 to: [9. 7.] | cost: 0.844 | done: False\n",
      "Moved 3 to: [10. 14.] | cost: 0.941 | done: True\n",
      "episode cost: 5.627\n"
     ]
    }
   ],
   "source": [
    "optimal_actions = evaluate_alg(env, Strap, initial_graph, target_graph, num_buffers=4);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moved 1 to: [1. 7.] | cost: 0.726 | done: False\n",
      "4 -> 0 | cost: 0.799 | done: False\n",
      "Moved 0 to: [9. 7.] | cost: 0.341 | done: False\n",
      "Moved 3 to: [10. 14.] | cost: 1.054 | done: False\n",
      "Moved 2 to: [17.  8.] | cost: 0.693 | done: False\n",
      "Moved 4 to: [16.  3.] | cost: 1.466 | done: True\n",
      "episode cost: 5.078\n",
      "-------------------------\n",
      "------\n",
      "Moved 1 to: [1. 7.] | cost: 0.726 | done: False\n",
      "4 -> 0 | cost: 0.799 | done: False\n",
      "Moved 0 to: [9. 7.] | cost: 0.341 | done: False\n",
      "Moved 3 to: [10. 14.] | cost: 1.054 | done: False\n",
      "Moved 2 to: [17.  8.] | cost: 0.693 | done: False\n",
      "Moved 4 to: [16.  3.] | cost: 1.466 | done: True\n",
      "episode cost: 5.078\n",
      "-------------------------\n"
     ]
    }
   ],
   "source": [
    "refine_until_convergence(env, optimal_actions, initial_graph, target_graph, 'Labbe', verbose=1);\n",
    "print('------')\n",
    "refine_until_convergence(env, optimal_actions, initial_graph, target_graph, 'LabbeS', verbose=1);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_runs(phi, env, graphs, alg, file_name, **kwargs):\n",
    "\tfild_dir = f'runs/{phi}/g{env.grid_size}/n{env.num_nodes}'\n",
    "\tif not os.path.exists(fild_dir):\n",
    "\t\tos.makedirs(fild_dir)\n",
    "\t\n",
    "\tfile_dir = f'{fild_dir}/{file_name}.pkl'\n",
    "\n",
    "\truns = []\n",
    "\tpbar = tqdm(total=len(graphs), unit='rearrangement')\n",
    "\tfor graph in graphs:\n",
    "\t\tstart = time.time()\n",
    "\t\tenv.reset(state_graph=graph['initial_graph'], target_graph=graph['target_graph'])\n",
    "\t\toptimal_actions, steps = alg(env).solve(**kwargs)\n",
    "\t\telapsed_time = time.time() - start\n",
    "\t\truns.append({\n",
    "\t\t\t'optimal_actions': optimal_actions,\n",
    "\t\t\t'steps': steps,\n",
    "\t\t\t'elapsed_time': elapsed_time\n",
    "\t\t})\n",
    "\t\twith open(file_dir, 'wb') as f:\n",
    "\t\t\tpickle.dump(runs, f)\n",
    "\n",
    "\t\tpbar.update(1)\n",
    "\tpbar.close()\n",
    "\n",
    "def make_graphs(env, num_graphs, stack, ratio=0.5):\n",
    "\tgraphs = []\n",
    "\tfor _ in range(num_graphs):\n",
    "\t\tenv.reset(stack=stack, ratio=ratio)\n",
    "\t\tgraphs.append({\n",
    "\t\t\t'initial_graph': env.initial_graph,\n",
    "\t\t\t'target_graph': env.target_graph\n",
    "\t\t})\n",
    "\treturn graphs\n",
    "\n",
    "def save_graphs(dir, graphs, num_nodes, grid_size):\n",
    "\tif not os.path.exists(f'graphs/{dir}'):\n",
    "\t\tos.makedirs(f'graphs/{dir}')\n",
    "\twith open(f'graphs/{dir}/{num_nodes}n_{grid_size}g.pkl', 'wb') as f:\n",
    "\t\tpickle.dump(graphs, f)\n",
    "\n",
    "def load_graphs(dir, num_nodes, grid_size):\n",
    "\twith open(f'graphs/{dir}/{num_nodes}n_{grid_size}g.pkl', 'rb') as f:\n",
    "\t\tgraphs = pickle.load(f)\n",
    "\treturn graphs\n",
    "\n",
    "def plot_characteristics(ax, runs, key, title=\"\"):\n",
    "\txtics = []\n",
    "\tfor run in runs:\n",
    "\t\tx_axis = range(1, len(run['runs'])+1)\n",
    "\t\ty_axis = [run[key] for run in run['runs']]\n",
    "\t\tax.plot(x_axis, y_axis, label=f\"{run['num_nodes']}n_{run['grid_size']}g\")\n",
    "\t\tif len(xtics) < len(x_axis):\n",
    "\t\t\txtics = x_axis\n",
    "\t\n",
    "\tax.set_xticks(xtics)\n",
    "\tax.set_title(title)\n",
    "\tax.set_xlabel('Samples')\n",
    "\tif key == 'elapsed_time':\n",
    "\t\tax.set_ylabel(f'Time elapsed (s)')\n",
    "\telse:\n",
    "\t\tax.set_ylabel(f'{key}')\n",
    "\tax.legend()\n",
    "\n",
    "def load_runs(phi, algs, n_values, grid_size, refine=False):\n",
    "\truns = {}\n",
    "\tfor num_nodes in n_values:\n",
    "\t\tpath = glob.glob(f'runs/{phi}/g{grid_size}/n{num_nodes}/*')\n",
    "\t\truns[num_nodes] = {}\n",
    "\t\tfor file in path:\n",
    "\t\t\twith open(file, 'rb') as f:\n",
    "\t\t\t\tfirst_back_slash = file.rindex('\\\\')\n",
    "\t\t\t\talg_name = f'{file[first_back_slash+1:-4]}'\n",
    "\t\t\t\tif alg_name not in algs:\n",
    "\t\t\t\t\tcontinue\n",
    "\t\t\t\truns[num_nodes][alg_name] = pickle.load(f)\n",
    "\t\t\t\n",
    "\t\t\tgraphs = load_graphs(phi, num_nodes, grid_size)\n",
    "\t\t\tassert len(graphs) == len(runs[num_nodes][alg_name])\n",
    "\n",
    "\t\t\tenv = ContinuousEnv(num_nodes=num_nodes, grid_size=grid_size, num_labels=5, verbose=0)\n",
    "\t\t\tfor i, graph in enumerate(graphs):\n",
    "\t\t\t\tenv.reset(graph['initial_graph'], graph['target_graph'])\n",
    "\t\t\t\trun = runs[num_nodes][alg_name][i]\n",
    "\t\t\t\tif refine:\n",
    "\t\t\t\t\tprint(f'------n:{num_nodes} // alg:{alg_name}------')\n",
    "\t\t\t\t\t_, cost, elapsed_time = refine_until_convergence(env, run['optimal_actions'], graph['initial_graph'], graph['target_graph'], alg_name, verbose=1)\n",
    "\t\t\t\t\trun['elapsed_time'] += elapsed_time\n",
    "\t\t\t\t\trun['cost'] = cost\n",
    "\t\t\t\telse:\n",
    "\t\t\t\t\trun['cost'] = env_cost(env, run['optimal_actions'], graph['initial_graph'], graph['target_graph'], log=False).item()\n",
    "\treturn runs\n",
    "\n",
    "def plot_bars(data, title, ylabel, std_data=[], log_scale=False, ax=None, cmap=colormaps['viridis']):\n",
    "\tn_values = list(data.keys())\n",
    "\talgorithms = list(data[n_values[0]].keys())\n",
    "\n",
    "\tx = np.arange(len(n_values))  # The x positions for the groups\n",
    "\tbar_width = 0.2  # Width of the bars\n",
    "\n",
    "\tif ax is None:\n",
    "\t\tfig, ax = plt.subplots(figsize=(5, 4))\n",
    "\n",
    "\t# Fill missing values with 0\n",
    "\tfor i, sec in enumerate(data):\n",
    "\t\tfor alg in algorithms:\n",
    "\t\t\tif alg not in data[sec]:\n",
    "\t\t\t\tdata[sec][alg] = 0\n",
    "\n",
    "\tfor i, sec in enumerate(std_data):\n",
    "\t\tfor alg in algorithms:\n",
    "\t\t\tif alg not in std_data[sec]:\n",
    "\t\t\t\tstd_data[sec][alg] = 0\n",
    "\n",
    "\tvalues = {alg: [data[sec][alg] for sec in data] for alg in algorithms}\n",
    "\tif len(std_data):\n",
    "\t\tstd_devs = {alg: [std_data[sec][alg] for sec in std_data] for alg in algorithms}\n",
    "\n",
    "\tcolors = [cmap(i / len(algorithms)) for i in range(len(algorithms))]\n",
    "\n",
    "\tfor i, (alg, color) in enumerate(zip(algorithms, colors)):\n",
    "\t\tlabel = {'A_star': 'STRAP+Stack', 'Strap': 'STRAP', 'Sorp': 'SORP', 'Labbe': 'MCTS', 'LabbeS': 'MCTS+Stack'}.get(alg, alg)\n",
    "\t\tif len(std_data):\n",
    "\t\t\tax.bar(x + i * bar_width, values[alg], width=bar_width, color=color, label=label, yerr=std_devs[alg], capsize=5)\n",
    "\t\telse:\n",
    "\t\t\tax.bar(x + i * bar_width, values[alg], width=bar_width, color=color, label=label)\n",
    "\n",
    "\t# Formatting the plot\n",
    "\tax.set_xlabel('Number of Objects (n)')\n",
    "\tax.set_ylabel(ylabel)\n",
    "\tax.set_title(title)\n",
    "\tax.set_xticks(x + bar_width * (len(algorithms) - 1) / 2)\n",
    "\tax.set_xticklabels(n_values)\n",
    "\tax.legend(title='Algorithm')\n",
    "\n",
    "\t# Set y-axis to log scale if specified\n",
    "\tif log_scale:\n",
    "\t\tax.set_yscale('log')\n",
    "\n",
    "def compare_algs(phi, grid_size, algs, n_values, refine=False):\n",
    "\truns = load_runs(phi, algs, n_values, grid_size, refine=refine)\n",
    "\n",
    "\tcosts, times, steps = {}, {}, {}\n",
    "\tcosts_std, times_std, steps_std = {}, {}, {}  # Store standard deviations\n",
    "\n",
    "\tfor n in n_values:\n",
    "\t\tcosts[n], times[n], steps[n] = {}, {}, {}\n",
    "\t\tcosts_std[n], times_std[n], steps_std[n] = {}, {}, {}\n",
    "\n",
    "\t\tfor alg in runs[n]:\n",
    "\t\t\tcost_values = [run['cost'] for run in runs[n][alg]]\n",
    "\t\t\ttime_values = [run['elapsed_time'] for run in runs[n][alg]]\n",
    "\t\t\tstep_values = [run['steps'] for run in runs[n][alg]]\n",
    "\n",
    "\t\t\tcosts[n][alg] = np.mean(cost_values)\n",
    "\t\t\ttimes[n][alg] = np.mean(time_values)\n",
    "\t\t\tsteps[n][alg] = np.mean(step_values)\n",
    "\n",
    "\t\t\tcosts_std[n][alg] = np.std(cost_values)\n",
    "\t\t\ttimes_std[n][alg] = np.std(time_values)\n",
    "\t\t\tsteps_std[n][alg] = np.std(step_values)\n",
    "\n",
    "\tsns.set_style('whitegrid')\n",
    "\tfig, axs = plt.subplots(1, 2, figsize=(10, 4))\n",
    "\n",
    "\t# plot_bars(costs, 'Cost Comparison', 'Cost', ax=axs[0], cmap=colormaps['tab20b'])\n",
    "\t# plot_bars(times, 'Time Comparison', 'Time (log scale)', log_scale=True, ax=axs[1], cmap=colormaps['tab20b'])\n",
    "\tplot_bars(costs, 'Cost Comparison', 'Cost', ax=axs[0], cmap=colormaps['tab20b'], std_data=costs_std)\n",
    "\tplot_bars(times, 'Time Comparison', 'Time (log scale)', log_scale=True, ax=axs[1], cmap=colormaps['tab20b'])\n",
    "\n",
    "\tplt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "\tplt.tight_layout()\n",
    "\tplt.suptitle(f' = {phi[1:]}', fontsize=16, fontweight='bold')\n",
    "\tplt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_graphs = 10\n",
    "grid_size = 30\n",
    "num_nodes = 6\n",
    "ratio = 1\n",
    "phi = f'r{ratio}'\n",
    "env = ContinuousEnv(num_nodes=num_nodes, grid_size=grid_size, num_labels=5, verbose=0)\n",
    "# graphs = make_graphs(env, num_graphs, stack=False, ratio=ratio)\n",
    "# save_graphs(phi, graphs, num_nodes, grid_size)\n",
    "graphs = load_graphs(phi, num_nodes, grid_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_runs(phi, env, graphs, Labbe, \"Labbe\", verbose=0)\n",
    "save_runs(phi, env, graphs, LabbeS, \"LabbeS\", verbose=0)\n",
    "save_runs(phi, env, graphs, Sorp, \"Sorp\", iterations=1000, num_buffers=4, c=1, verbose=0)\n",
    "save_runs(phi, env, graphs, Sorp, \"Sorp_c2\", iterations=1000, num_buffers=4, c=1, verbose=0)\n",
    "save_runs(phi, env, graphs, Sorp2, \"Sorp2\", iterations=1000, num_buffers=4, c=1, verbose=0)\n",
    "save_runs(phi, env, graphs, Sorp2, \"Sorp2_c2\", iterations=1000, num_buffers=4, c=2, verbose=0)\n",
    "save_runs(phi, env, graphs, Strap, \"Strap\", num_buffers=4, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phi = 'r1'\n",
    "grid_size = 30\n",
    "algs = ['Sorp', 'Sorp_c2', 'Sorp2', 'Sorp2_c2', 'Strap']\n",
    "n_values = [3,4,5,6]\n",
    "compare_algs(phi, grid_size, algs, n_values, refine=False)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
