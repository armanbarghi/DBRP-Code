{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import time\n",
    "import heapq\n",
    "import random\n",
    "import itertools\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm, colormaps\n",
    "import pickle\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "import seaborn as sns\n",
    "from torch_geometric.data import Data\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap, BoundaryNorm\n",
    "from typing import Union\n",
    "import networkx as nx\n",
    "\n",
    "from env.graph_env import copy_graph, Indices, is_stable, in_table_index\n",
    "from env.graph_env import create_graph_label_continuous, flatten_pos, unflatten_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "OBJECT_SIZES = {\n",
    "\t0: (5, 5),\n",
    "\t1: (5, 5),\n",
    "\t2: (3, 3),\n",
    "\t3: (7, 7),\n",
    "}\n",
    "\n",
    "def copy_state(state):\n",
    "\treturn {'graph': copy_graph(state['graph']), 'manipulator': state['manipulator'].clone()}\n",
    "\n",
    "def is_empty_object(graph, node):\n",
    "\treturn find_start_node(graph, node) is None\n",
    "\n",
    "def is_edge_in_graph(graph, node1, node2):\n",
    "\tif graph.x[node1, Indices.RELATION.start + node2] == 0:\n",
    "\t\treturn False\n",
    "\treturn True\n",
    "\n",
    "def is_in_env(coor, size, grid_size):\n",
    "\tif coor[0] - size[0]//2 < 0 or coor[0] + size[0]//2 >= grid_size[0]:\n",
    "\t\treturn False\n",
    "\tif coor[1] - size[1]//2 < 0 or coor[1] + size[1]//2 >= grid_size[1]:\n",
    "\t\treturn False\n",
    "\treturn True\n",
    "\n",
    "def find_target_node(graph, node):\n",
    "\ti = (graph.x[node, Indices.RELATION] == 1).nonzero(as_tuple=True)[0]\n",
    "\tif len(i):\n",
    "\t\treturn i.item()\n",
    "\treturn None\n",
    "\n",
    "def find_start_node(graph, node):\n",
    "\ti = (graph.x[:, Indices.RELATION.start + node] == 1).nonzero(as_tuple=True)[0]\n",
    "\tif len(i):\n",
    "\t\treturn i.item()\n",
    "\treturn None\n",
    "\n",
    "def find_base_node(graph, node):\n",
    "\twhile graph.x[node, Indices.RELATION].sum() != 0:\n",
    "\t\tnode = find_target_node(graph, node)\n",
    "\treturn node\n",
    "\n",
    "def find_occupying_nodes(table, coor, size):\n",
    "\toccupying_nodes = []\n",
    "\tunique_nodes = np.unique(table[in_table_index(coor, size)])\n",
    "\tfor node in unique_nodes:\n",
    "\t\tif node == 0:\n",
    "\t\t\tcontinue\n",
    "\t\toccupying_nodes.append(node-1)\n",
    "\n",
    "\treturn occupying_nodes\n",
    "\n",
    "def get_obj_size(label):\n",
    "\treturn OBJECT_SIZES[label]\n",
    "\n",
    "def get_empty_objects(env, ref_node, n=1):\n",
    "\tall_objects = list(range(env.num_nodes))\n",
    "\trandom.shuffle(all_objects)\n",
    "\tempty_objects = []\n",
    "\tfor obj in all_objects:\n",
    "\t\tif is_empty_object(env.state_graph, obj) and is_stable(env.state_graph.x, ref_node, obj):\n",
    "\t\t\tempty_objects.append(obj)\n",
    "\t\t\tif len(empty_objects) >= n:\n",
    "\t\t\t\tbreak\n",
    "\treturn empty_objects\n",
    "\n",
    "def get_all_positions_of_object(coord, size):\n",
    "    idx = in_table_index(coord, size)\n",
    "    x_range = np.arange(idx[0].start, idx[0].stop)\n",
    "    y_range = np.arange(idx[1].start, idx[1].stop)\n",
    "    x, y = np.meshgrid(x_range, y_range, indexing='ij')\n",
    "    return np.column_stack((x.ravel(), y.ravel()))\n",
    "\n",
    "def get_all_positions_in_env(grid_size, size):\n",
    "    x_range = np.arange(size[0] // 2, grid_size[0] - size[0] // 2)\n",
    "    y_range = np.arange(size[1] // 2, grid_size[1] - size[1] // 2)\n",
    "    x, y = np.meshgrid(x_range, y_range, indexing='ij')\n",
    "    return np.column_stack((x.ravel(), y.ravel()))\n",
    "\n",
    "def get_empty_positions(env, ref_node, n=1):\n",
    "\tall_positions = get_all_positions_in_env(env.grid_size, env.obj_size(ref_node))\n",
    "\n",
    "\t# Sample random positions instead of shuffling the entire list\n",
    "\trandom_indices = random.sample(range(len(all_positions)), len(all_positions))\n",
    "\tsampled_positions = (all_positions[i] for i in random_indices)\n",
    "\n",
    "\t# Use a generator to find the first `n` unoccupied positions\n",
    "\tpositions = []\n",
    "\tfor position in sampled_positions:\n",
    "\t\tposition = torch.tensor(position, dtype=torch.float32)\n",
    "\t\tif not env.is_coor_occupied(position, ref_node):\n",
    "\t\t\tpositions.append(flatten_pos(position, env.grid_size))\n",
    "\t\t\tif len(positions) >= n:\n",
    "\t\t\t\tbreak\n",
    "\n",
    "\treturn positions\n",
    "\n",
    "def draw_dependency_graph(env):\n",
    "\tdependency_graph = nx.DiGraph()\n",
    "\tfor k in range(env.num_nodes):\n",
    "\t\tdependency_graph.add_node(k)\n",
    "\t\ti = find_target_node(env.target_graph, k)\n",
    "\t\tif i is None:\n",
    "\t\t\tj = find_target_node(env.state_graph, k)\n",
    "\t\t\tTk = env.target_graph.x[k, Indices.COORD]\n",
    "\t\t\tCK = env.state_graph.x[k, Indices.COORD]\n",
    "\t\t\tif torch.equal(CK, Tk):\n",
    "\t\t\t\tif j is not None:\n",
    "\t\t\t\t\tdependency_graph.add_edge(k, j)\n",
    "\t\t\t\t\twhile env.state_graph.x[j, Indices.RELATION].sum() != 0:\n",
    "\t\t\t\t\t\tj = find_target_node(env.state_graph, j)\n",
    "\t\t\t\t\t\tif j is None:\n",
    "\t\t\t\t\t\t\tbreak\n",
    "\t\t\t\t\t\tdependency_graph.add_edge(k, j)\n",
    "\t\t\telse:\n",
    "\t\t\t\tsize = env.get_obj_size(k)\n",
    "\t\t\t\toccupying_nodes = find_occupying_nodes(env.table, Tk, size)\n",
    "\t\t\t\tfor j in occupying_nodes:\n",
    "\t\t\t\t\tif j != k:\n",
    "\t\t\t\t\t\tj = find_base_node(env.state_graph, j)\n",
    "\t\t\t\t\t\t# if the k,j pair is not in the dependency graph\n",
    "\t\t\t\t\t\tif not dependency_graph.has_edge(k, j):\n",
    "\t\t\t\t\t\t\tdependency_graph.add_edge(k, j)\n",
    "\t\telse:\n",
    "\t\t\tj = find_start_node(env.state_graph, i)\n",
    "\t\t\tif j is not None and j != k:\n",
    "\t\t\t\tdependency_graph.add_edge(k, j)\n",
    "\n",
    "\tfig, ax = plt.subplots(1, 1, figsize=(2.5, 2.5))\n",
    "\tnx.draw(dependency_graph, env.state_graph.pos, with_labels=True, node_size=400, ax=ax, node_color='skyblue')\n",
    "\tplt.title('Dependency Graph')\n",
    "\tplt.show()\n",
    "\n",
    "def draw_manipulator_decoding(env):\n",
    "\theight_grid, width_grid = env.grid_size\n",
    "\ttable = np.zeros(env.grid_size, dtype=int)\n",
    "\tfor i in range(height_grid):\n",
    "\t\tfor j in range(width_grid):\n",
    "\t\t\ttable[i, j] = env.manipulator_decode([i, j])[0]\n",
    "\tplt.imshow(table, cmap='viridis')\n",
    "\tplt.show()\n",
    "\n",
    "def evaluate_alg(env, alg, initial_graph, target_graph, **kwargs):\n",
    "\tenv.reset(initial_graph, target_graph)\n",
    "\tstart = time.time()\n",
    "\tprint(f\"--------{alg.__name__}--------\")\n",
    "\toptimal_actions, steps = alg(env).solve(**kwargs)\n",
    "\telapsed_time = time.time() - start\n",
    "\tprint(f'optimal_actions: {optimal_actions} in {steps} steps')\n",
    "\tprint(f'elapsed time: {elapsed_time:.2f}s')\n",
    "\tif optimal_actions is not None:\n",
    "\t\tenv_cost(env, optimal_actions, initial_graph, target_graph)\n",
    "\treturn optimal_actions\n",
    "\n",
    "def env_cost(env, actions, initial_graph, target_graph, log=True):\n",
    "\tenv.reset(initial_graph, target_graph)\n",
    "\tep_cost = 0\n",
    "\tfor action in actions:\n",
    "\t\tcost, _ = env.step_cost(action, log=log)\n",
    "\t\tep_cost += cost\n",
    "\tif log:\n",
    "\t\tprint(f'episode cost: {ep_cost:.3f}')\n",
    "\tenv.reset(initial_graph, target_graph)\n",
    "\treturn ep_cost\n",
    "\n",
    "def positional_encode(one_hot_position):\n",
    "\tpositions = torch.argmax(one_hot_position, dim=1)\n",
    "\tencodings = torch.zeros((len(positions), 1))\n",
    "\n",
    "\tfor i, position in enumerate(positions):\n",
    "\t\tif torch.sum(one_hot_position[i]) == 0:\n",
    "\t\t\tencodings[i] = -1\n",
    "\t\telse:\n",
    "\t\t\tencodings[i] = position\n",
    "\n",
    "\treturn encodings\n",
    "\n",
    "def state_to_hashable(state):\n",
    "\tif hasattr(Indices, 'LABEL'):\n",
    "\t\tnew_state = torch.cat([state['graph'].x[:, Indices.LABEL], state['graph'].x[:, Indices.COORD], positional_encode(state['graph'].x[:, Indices.RELATION])], dim=1)\n",
    "\telse:\n",
    "\t\tnew_state = torch.cat([state['graph'].x[:, Indices.COORD], positional_encode(state['graph'].x[:, Indices.RELATION])], dim=1)\n",
    "\treturn tuple(state['manipulator'].numpy().tolist() + new_state.view(-1).tolist())\n",
    "\n",
    "def reconstruct_path(node):\n",
    "    path = []\n",
    "    while node.parent is not None:\n",
    "        path.append(node.action)\n",
    "        node = node.parent\n",
    "    path.reverse()\n",
    "    return path\n",
    "\n",
    "def cal_density(env):\n",
    "    phi = np.sum([env.get_obj_size(i)[0] * env.get_obj_size(i)[1] for i in range(env.num_nodes)])\n",
    "    return phi / (env.grid_size[0] * env.grid_size[1])\n",
    "\n",
    "def plot_graph(graph, grid_size, ax=None, fig_size=2.5, title=None, constraints=[]):\n",
    "\tif ax is None:\n",
    "\t\tfig, ax = plt.subplots(1, 1, figsize=(fig_size, fig_size*(grid_size[1]/grid_size[0])))\n",
    "\n",
    "\t# Create a color grid based on the labels and the color dictionary\n",
    "\tcolor_by_label = {\n",
    "\t\t0: 'white',\t\t# background\n",
    "\t\t1: 'yellow',\n",
    "\t\t2: 'orange',\n",
    "\t\t3: 'green',\n",
    "\t\t4: 'blue',\n",
    "\t\t5: 'red',\t\t# manipulator\n",
    "\t}\n",
    "\n",
    "\t# Map the table values to colormap indices\n",
    "\tmapped_table = np.zeros(grid_size, dtype=int)\n",
    "\tunrendered_nodes = list(range(graph.num_nodes))\n",
    "\twhile len(unrendered_nodes) > 0:\n",
    "\t\ti = unrendered_nodes.pop(0)\n",
    "\t\tlabel_i = graph.x[i, Indices.LABEL].item()\n",
    "\t\tcoor = graph.x[i, Indices.COORD].numpy()\n",
    "\t\tsize = get_obj_size(label_i)\n",
    "\t\tif graph.x[i, Indices.RELATION].sum() > 0:\n",
    "\t\t\tchild = find_target_node(graph, i)\n",
    "\t\t\tif child in unrendered_nodes:\n",
    "\t\t\t\tunrendered_nodes.append(i)\n",
    "\t\t\t\tcontinue\n",
    "\t\t\tif label_i == 0 and graph.x[child, Indices.LABEL].item() == 2:\n",
    "\t\t\t\tsize = (1, 1)\n",
    "\t\tmapped_table[in_table_index(coor, size)] = label_i + 1\n",
    "\t\n",
    "\tfor i in range(len(constraints)):\n",
    "\t\t# if the type of constraints is tensor, convert it to int\n",
    "\t\tif isinstance(constraints[i], torch.Tensor):\n",
    "\t\t\tconstraints = constraints[i].numpy()\n",
    "\t\telse:\n",
    "\t\t\tconstraints = constraints[i]\n",
    "\t\tc_x, c_y = list(map(int, constraints))\n",
    "\t\tmapped_table[c_x, c_y] = 5\n",
    "\n",
    "\t# Create a color list based on the numbers in the table\n",
    "\tunique_values = np.unique(mapped_table)\n",
    "\tcolor_list = [color_by_label[val] for val in unique_values]\n",
    "\n",
    "\t# Create a colormap and a normalization based on the unique values\n",
    "\tcmap = ListedColormap(color_list)\n",
    "\tbounds = np.append(unique_values, unique_values[-1] + 1)\n",
    "\tnorm = BoundaryNorm(bounds, cmap.N)\n",
    "\n",
    "\t# Plot the table\n",
    "\tax.imshow(mapped_table, cmap=cmap, norm=norm, origin='upper')\n",
    "\n",
    "\t# Add gridlines for better visualization\n",
    "\tax.set_xticks(np.arange(-0.5, mapped_table.shape[1], 1), minor=True)\n",
    "\tax.set_yticks(np.arange(-0.5, mapped_table.shape[0], 1), minor=True)\n",
    "\tax.grid(which='minor', color='gray', linestyle='-', linewidth=0.3)\n",
    "\tax.tick_params(which='minor', bottom=False, left=False)\n",
    "\n",
    "\t# Remove major ticks\n",
    "\tax.set_xticks([])\n",
    "\tax.set_yticks([])\n",
    "\n",
    "\t# Add labels to cells for clarity\n",
    "\tfor i in range(graph.num_nodes):\n",
    "\t\tcoor_i = graph.x[i, Indices.COORD].numpy()\n",
    "\t\tlabel_i = graph.x[i, Indices.LABEL].item()\n",
    "\t\tsize_i = get_obj_size(label_i)\n",
    "\t\tif graph.x[i, Indices.RELATION].sum() > 0:\n",
    "\t\t\tchild = find_target_node(graph, i)\n",
    "\t\t\tif label_i == 0 and graph.x[child, Indices.LABEL].item() == 2:\n",
    "\t\t\t\tsize_i = (1, 1)\n",
    "\t\tax.text(coor_i[1]-size_i[1]//2, coor_i[0]-size_i[0]//2, str(i), ha='center', va='center', color='black')\n",
    "\t\n",
    "\tif title is not None:\n",
    "\t\tax.set_title(title)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAANUAAACLCAYAAAD2xNwEAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuNSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/xnp5ZAAAACXBIWXMAAA9hAAAPYQGoP6dpAAARDElEQVR4nO2de1BT57rGnxCFILlwMR4GLBdBRKpi1VRpLVsdhF7sOcJgtY5uLps646gtbd3uqbNH64zXVmXPVuiM1kHJOK2DFdp62dYLM9Z6a4taOB4VGakKXiJFBAFR8p4/NIGQBAJdyVqQ9+cwmPf7nu/9VsiTFZ6sqIyICAzDCIaH2BtgmP4Gm4phBIZNxTACw6ZiGIFhUzGMwLCpGEZg2FQMIzBsKoYRGDYVwwgMm4phBMatTFVWVobU1FSEhoZCoVAgODgY06dPx5YtWyzmrV27FsXFxb3uc+nSJXz66aeoqqr6cxu2QVVVFTIyMhAREQGFQoHAwEDEx8dj5cqVgvdieofMXa79O3XqFKZOnYqQkBCkpaUhMDAQN2/exJkzZ1BZWYlr166Z5yqVSqSmpmLnzp296rV3717MmjULJSUlmDJlijAHAODatWvQ6XTw9vZGZmYmwsLCcPv2bZSWluLQoUNoaWkRrBfTewaIvQFXsWbNGmg0Gvz888/w9fW1GLt37544m+ohOTk5aGxsxIULFxAaGmox1leOwS0gN2HEiBE0ZcqUbucBsPpKS0sjIqKqqipauHAhRUVFkUKhIH9/f0pNTaXr16+b9fn5+TbXKCkpMc85ePAgTZ48mQYNGkRKpZLefPNNKi8v73ZvSUlJFBYW5vAxHzx4kOLj40mpVJJKpaIJEybQ7t27LeacOXOGkpKSSK1Wk7e3N8XHx9PJkyct5qxcuZIAUEVFBaWlpZFGoyG1Wk3p6en06NEjq756vZ7GjRtHCoWC/Pz8aPbs2XTjxg2H993XcRtTJSYmkkqlorKysi7n6fV68vLyotdee430ej3p9Xo6deoUEREVFhZSbGwsrVixgrZt20bLly8nPz8/Cg0NNT+4Kisr6f333ycAtHz5cvMad+7cISKigoICkslk9Prrr9OWLVtow4YNFBYWRr6+vhbmtMWCBQtILpfTsWPHuj3e/Px8kslkNGrUKFqzZg3l5uZSVlYWzZ8/3zzn2LFj5OnpSXFxcbRp0ybKycmhMWPGkKenJ509e9Y8z2Sql156iVJSUigvL4+ysrIIAC1btsyi7+rVq0kmk9Hs2bMpLy+PVq1aRYMHD6awsDCqq6vrdt/9Abcx1Q8//EByuZzkcjnFxcXRsmXL6PDhw9Ta2mo118fHx3x26khTU5NV7fTp0wSACgoKzLXCwkKrsxMRUUNDA/n6+tJ7771nUb9z5w5pNBqremfKy8vJ29ubANDYsWPpgw8+oOLiYquzxYMHD0ilUtHEiROpubnZYsxoNJq/Dx8+nJKSksw10zGGh4fT9OnTzTWTqTIzMy3WSk5OpoCAAPPtqqoqksvltGbNGot5ZWVlNGDAAKt6f8VtTEVEdO7cOUpOTqZBgwaZX5ZptVr69ttvLebZM1VHWltb6f79+2QwGMjX15eys7PNY/ZMtW/fPgJAx48fJ4PBYPGVmJhIkZGR3R7DlStXaN68eeTr62s+BqVSSdu2bbPqX1RUZHed0tJSAkC7du2y2ktWVhZ5eXlRW1sbEbWb6ty5cxZrbN68mQBQfX29+bZMJqOKigqrNUeOHEkJCQndHl9/wG2CCgDQ6XTYt28fWltbcfHiRRQVFSEnJwepqam4cOECYmJiutQ3Nzdj3bp1yM/PR3V1NahDcFpfX99t/4qKCgDAtGnTbI6r1epu14iKioJer0dbWxsuXbqE/fv347PPPsOCBQsQHh6OhIQEVFZWAgBGjRrV7V7S0tLszqmvr4efn5/5dkhIiMW4aayurg5qtRoVFRUgIgwfPtzmegMHDuz2+PoDbmUqE56entDpdNDpdIiKikJGRgYKCwu7fa9nyZIlyM/PR3Z2NuLi4qDRaCCTyTBnzhwYjcZu+5rm6PV6BAYGWo0PGOD4j0Mul2P06NEYPXo04uLiMHXqVOzevRsJCQkO6U17+fzzzzF27Fibc5RKpVVPW5ieXIxGI2QyGQ4dOmRzbuf1+ituaaqOTJgwAQBw+/Ztc00mk9mcu3fvXqSlpWHTpk3mWktLCx48eGAxz54+IiICADBkyBCHH/yO0PkYTH3Ky8sRGRnZ5V7UarVge4mIiAARITw8HFFRUYKs2RdxmysqSkpKLF6umTh48CAAYMSIEeaaj4+PlVGAZ8/UndfYsmUL2traLGo+Pj4AYLVGUlIS1Go11q5diydPnlitbzAYujyGH3/80aau8zEkJiZCpVJh3bp1Vm8Im/Y/fvx4REREYOPGjWhsbOzxXmyRkpICuVyOVatWWd1PRITa2toer9kXcZsz1ZIlS9DU1ITk5GRER0ejtbUVp06dwp49exAWFoaMjAzz3PHjx+Po0aPYvHkzgoKCEB4ejokTJ2LGjBnQ6/XQaDSIiYnB6dOncfToUQQEBFj0Gjt2LORyOTZs2ID6+np4eXlh2rRpGDJkCL744gvMnz8f48aNw5w5c6DVanHjxg0cOHAAr776KrZu3Wr3GDZs2IBff/0VKSkpGDNmDACgtLQUBQUF8Pf3R3Z2NoBnZ5+cnBxkZWVBp9Nh7ty58PPzw8WLF9HU1IRdu3bBw8MDX375Jd544w28+OKLyMjIQHBwMKqrq1FSUgK1Wo3vv/++R/dxREQEVq9ejU8++QRVVVWYOXMmVCoVrl+/jqKiIixYsABLly7t0Zp9EtEiEhdz6NAhyszMpOjoaFIqleTp6UmRkZG0ZMkSunv3rsXcy5cvU3x8vDm+NiWBdXV1lJGRQYMHDyalUklJSUl0+fJlCg0NtUoLt2/fTsOGDSO5XG6VBJaUlFBSUhJpNBpSKBQUERFB6enp9Msvv3R5DD/99BMtWrSIRo0aRRqNhgYOHEghISGUnp5OlZWVVvO/++47euWVV8jb25vUajW9/PLL9NVXX1nMOX/+PKWkpFBAQAB5eXlRaGgovfPOOxbvhZnSP4PBYKE1vdHd+f21b775hiZPnkw+Pj7k4+ND0dHRtGjRIrpy5UqXx9dfcJtr/xjGVbjN71QM4yrYVAwjMGwqhhEYNhXDCAybimEEhk3FMALj0Ju/RqMRNTU1UKlUdi/BYZj+DhGhoaEBQUFB8PCwfz5yyFQ1NTV44YUXBNscw/Rlbt68iaFDh9odd8hUKpXKvFjHjyfU1NQAAIKCgqw09sZY40B95EjrtQIDgZISye3ZVRqx+wPA1atXodPpzH6wh0OmMr3kU6vVFqZqaGgw1ztjb4w1DtStVgIaPDwAlUpye3aVRuz+QPtHV7r7FYiDCoYRGDYVwwgMm4phBKZHn6eqqakxv+YEuv4gm70x1jhQv3XL9pgNndh7dpVG7P4AcP/+fbtjHeEzFcMITI/OVEFBQTZTkeDgYLsae2OskW5/KWvE7N/xVVpX8JmKYQSGTcUwAsOmYhiB4fRPQhqx+0tZI3Z/gNM/hhENTv8kqBG7v5Q1nP4xjBvCpmIYgWFTMYzAcPonIY3Y/aWsEbs/wOkfw4gGp38S1IjdX8oaTv8Yxg1hUzGMwLCp3ITc3FyEhYVBoVBgxowZOH/+vNhb6rewqdyAPXv24KOPPsLKlStRWlqKmJgYzJs3D/fu3RN7a/0SjtQlpHFW//Xr1+Pdd99FYmIiAODjjz/GkSNHkJOTg8WLF4u6NzHW6q3G0Ujdbf7PX3flyY9/RdlvZVj86u/A4SMAAI/HWkwc9hSl//kXMLzAUvBY++y7l8GxeneauJ1/av99EY7UJagRcq07rffQZgRitHUIVtSZ60P9WlFa0YJgRY3t9XpYtzum1Ur2vumphiN1hhEJNlU/x1/lAbkHcLfesn7/oRGBGnH21N9hU/VzPAfIMD4cOPa/7TWjkXDy/x4jbrh4++qKrVu3mv8jgCFDhmDmzJmorKwUe1sOw+mfhDRO6f9Yi/SEZny4ow4RQ30xNnwgth5+jEctMrw+8b9Q3SK31JhCh85r2al3q+nFfXDixAnMnTsXsbGxaGtrw/r16zF79mzs27evx2vZ3TOnf8yf4b9f9kZtgxEbixtgeNiGqKGDkLs4HFpNk9hbs0lu7iNotRvNt3Ny2hAbexeXLs1HSEizDYXJ1J0NYa/uiOZAD3ZsCad/EtQI2t/LgGBFDf75FvDPt56Vqlt8ATT1PMnrom53rFfpnwHBwe1rNT/3UVjYQwQH2z+TdNQ4Uu9aw+kf008xGoHsbECn80R09ECxt+MQ/PKPkTSLFgHl5UBhoZ/YW3EYNhUjWRYvBvbvB06cADw95d0LJAK//GMkBxFh8WKgqAg4fhwIDxd7Rz2DI3UJaZwVqVvVexuP90bTi/tg7dpWHD4sw44d/mhsHIDz54HaWl8olbbPVgaDnf526o5pqq3GOFJn+iyFhbUAgFmzajtU72LVqhfwt7+Js6eewJG6BDXOiNRtaiQaqd+6FWQVdVdXBwFo62U8zpE6w/Rp2FQMIzBONVVBQQHGjBkDtVoNtVqNuLg4HD9+3JktGUZ0nJr+DRo0CEuXLkX480y0sLAQmZmZ+PrrrzFp0iSbGntrddWnv2g4/TPVbez5TyV5vdFINP37y1/yodW233n/+Aewaxfht9+yMWmS0YZC6Asjd/ZswwwjAE5O/9ovjGxrAwoLgZYWYMqUxy66MFLYj3K7SuPu6V/nC2ot50s//XP6+1RlZUBc3DMzKZXA9u3+iIrqGxdGMkxvcHr6N2IEcOECcPYssHAh8OGHD3D16hNnt2UY0XD6mcrTE4iMfPb38eOBkycHYMeOR5g61dmdGUYcXP4+ldEItLaSq9syjMtwaqT+738/xVtvBSA4WI7GRkJxcTNOn25EXt4wVFe32NAIHY1KINIWuz9H6r3USDRS/+OPp8jOrse9e21QqTwwcuQA5OUNw6RJKgDWpmKY/oBTI/XcXAWCg/94fssIoPX5GarFRdEoR+ocqfMFtQzT52FTMYzAsKkYRmCc/HF6sVMcCaRvYvfn9K+XGommf4wEiNsJaDs9gEwP6M71rsb+jMbNcNkFtdYaTv+k2l98jdiPG07/GEZSsKkYRmDYVIxTOXPmDN5++20EBQVBJpOhuLhY7C05HTYV41SampoQGxuL3NxcsbfiMjhSd6DuKo3Y/Z2hGT16NKZNm2au1dbWorq6miN1hukt6d+mw9Dhye3vR/6OFbdWQPvcOIZOT3ztdXSqP+NA1jkbXQydZnVXd0TTezhS70HdVRqx+wupMcCAGrT/bOqe/zHRcawj9upiHidH6gwjEmwqhhEYNhXDCAynfw7UXaURu78zNP6P/fHkjyfPbsMA9QM1vG57QeOtgaevp5VGazNUaK9XV1uncq46Tk7/GEnQXNMMw672B+rDww8BAE9jnyIkOUSsbTkVTv96UHeVRuz+Qmqaw5uBT63nesPbKhnsCKd/DMOYYVMxjMCwqRhGYNhUDCMwHKk7UHeVRuz+ztB0F5H3tM6ROnZC2IscXXthJMP0BidH6n0vApaCRuz+Qmq6is0BvqCWYRgHYFMxjMCwqRhGYJyc/jleZ434/Z2h4fSPYQRm5//shNbGv2prevB2Huuu3hfg9E+CGrH7S1nD6R/DuCFsKoYRGDYVwwgMm4phBIYjdQlpxO4vZY3Y/QHHI3U+UzGMwHCkLkGN2P2lrOFInWHcEDYVwwgMm4phBMah36mICABw9epVKJVKc92Uhth6rWlvjDXS7S9ljdj9AeD3338H0O4HezhkKlMDnU7nyHSG6dc0NDRAo9HYHZdRd7YDYDQaUVNTA5VKBZlMJugGGaavQERoaGhAUFAQPDzs/+bkkKkYhnEcDioYRmDYVAwjMGwqhhEYNhXDCAybimEEhk3FMALDpmIYgfl/XuWEUkiWgUAAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 250x250 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moved 2 to: [2. 3.] | cost: 4.300 | done: False\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 250x250 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moved 0 to: [12. 15.] | cost: 4.267 | done: False\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 250x250 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moved 1 to: [ 7. 17.] | cost: 1.667 | done: False\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 250x250 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moved 1 to: [13. 21.] | cost: 1.267 | done: False\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 250x250 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moved 1 to: [ 3. 16.] | cost: 2.600 | done: False\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 250x250 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moved 1 to: [13. 11.] | cost: 3.000 | done: False\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 250x250 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moved 1 to: [ 3. 11.] | cost: 2.667 | done: False\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 250x250 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moved 1 to: [ 8. 23.] | cost: 2.000 | done: False\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 250x250 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moved 2 to: [ 7. 19.] | cost: 5.467 | done: False\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 250x250 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moved 0 to: [4. 2.] | cost: 3.400 | done: False\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 250x250 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class BaseGraphEnv():\n",
    "\tdef __init__(self, num_nodes, grid_size, max_steps=200):\n",
    "\t\tself.max_steps = max_steps\n",
    "\t\tself.num_nodes = num_nodes\n",
    "\t\tself.grid_size = grid_size\n",
    "\n",
    "\tdef is_terminal_state(self):\n",
    "\t\treturn torch.equal(self.state_graph.x, self.target_graph.x)\n",
    "\n",
    "\tdef same_coor_in_target_graph(self, node, coor):\n",
    "\t\treturn torch.equal(self.target_graph.x[node, Indices.COORD], coor)\n",
    "\n",
    "\tdef check_loop_by_replacing_edge(self, start_node, prev_target, target_node):\n",
    "\t\tedge_index = self.state_graph.edge_index.clone()\n",
    "\t\tif prev_target is not None:\n",
    "\t\t\tmask = ~((edge_index[0] == start_node) & (edge_index[1] == prev_target))\n",
    "\t\t\tedge_index = edge_index[:, mask]\n",
    "\t\tnew_edge = torch.tensor([[start_node], [target_node]], dtype=torch.long)\n",
    "\t\tedge_index = torch.cat([edge_index, new_edge], dim=1)\n",
    "\t\treturn has_cycles(Data(x=self.state_graph.x, edge_index=edge_index))\n",
    "\n",
    "\tdef remove_edge(self, node1, node2):\n",
    "\t\tmask = ~((self.state_graph.edge_index[0] == node1) & (self.state_graph.edge_index[1] == node2))\n",
    "\t\tself.state_graph.edge_index = self.state_graph.edge_index[:, mask]\n",
    "\t\tself.state_graph.x[node1][Indices.RELATION.start+node2] = 0\n",
    "\n",
    "\tdef add_edge(self, node1, node2):\n",
    "\t\tnew_edge = torch.tensor([[node1], [node2]], dtype=torch.long)\n",
    "\t\tself.state_graph.edge_index = torch.cat([self.state_graph.edge_index, new_edge], dim=1)\n",
    "\t\tself.state_graph.x[node1][Indices.RELATION.start+node2] = 1\n",
    "\t\tdestination = self.state_graph.x[node2, Indices.COORD].clone()\n",
    "\t\treturn self.move_node_with_parents(node1, destination)\n",
    "\n",
    "\tdef decode_action(self, action: int):\n",
    "\t\tn = self.num_nodes\n",
    "\t\tm = self.grid_size[0] * self.grid_size[1]\n",
    "\t\tnum_edge_actions = n * (n - 1)\n",
    "\t\tcoordinates = 0\n",
    "\n",
    "\t\tif action < num_edge_actions:\n",
    "\t\t\taction_type = 'on'\n",
    "\t\t\tstart_node = action // (n - 1)\n",
    "\t\t\ttarget_node = action % (n - 1)\n",
    "\t\t\tif target_node >= start_node:\n",
    "\t\t\t\ttarget_node += 1\n",
    "\t\telse:\n",
    "\t\t\taction_type = 'move'\n",
    "\t\t\tadjusted_action = action - num_edge_actions\n",
    "\t\t\tstart_node = adjusted_action // m\n",
    "\t\t\tcoordinates = adjusted_action % m\n",
    "\t\t\ttarget_node = start_node\n",
    "\n",
    "\t\treturn action_type, start_node, target_node, coordinates\n",
    "\n",
    "\tdef encode_action(self, action_type: str, start_node: int, target_node: int, coordinates: Union[int, list, np.ndarray, torch.Tensor])-> int:\n",
    "\n",
    "\t\t# Convert coordinate pair to flattened index if needed\n",
    "\t\tif isinstance(coordinates, torch.Tensor):\n",
    "\t\t\tcoordinates = int(flatten_pos(coordinates, self.grid_size).item())\n",
    "\t\telif isinstance(coordinates, list) or isinstance(coordinates, np.ndarray):\n",
    "\t\t\tcoordinates = int(flatten_pos(coordinates, self.grid_size))\n",
    "\n",
    "\t\tn = self.num_nodes\n",
    "\t\tm = self.grid_size[0] * self.grid_size[1]\n",
    "\t\tnum_edge_actions = n * (n - 1)\n",
    "\n",
    "\t\tif action_type == 'on':\n",
    "\t\t\tif target_node >= start_node:\n",
    "\t\t\t\ttarget_node -= 1\n",
    "\t\t\taction = start_node * (n - 1) + target_node\n",
    "\t\telif action_type == 'move':\n",
    "\t\t\taction = num_edge_actions + start_node * m + coordinates\n",
    "\t\telse:\n",
    "\t\t\traise ValueError('Invalid action type')\n",
    "\n",
    "\t\treturn action\n",
    "\n",
    "\tdef move_node_with_parents(self, node, coordinates):\n",
    "\t\treward = 0\n",
    "\t\tn = self.num_nodes\n",
    "\t\t# Find all parents of the node and their parents recursively and move them\n",
    "\t\tvisited = [False] * n\n",
    "\t\tvisited[node] = True\n",
    "\t\tstack = [node]\n",
    "\t\twhile len(stack) > 0:\n",
    "\t\t\tnode = stack.pop()\n",
    "\t\t\tprev_coordinates = self.state_graph.x[node, Indices.COORD].clone()\n",
    "\t\t\tself.state_graph.x[node, Indices.COORD] = coordinates.clone()\n",
    "\t\t\tif not torch.equal(prev_coordinates, coordinates):\n",
    "\t\t\t\tif self.same_coor_in_target_graph(node, prev_coordinates):\n",
    "\t\t\t\t\treward -= 1\n",
    "\t\t\t\telif self.same_coor_in_target_graph(node, coordinates):\n",
    "\t\t\t\t\treward += 1\n",
    "\t\t\tparents = get_parents(node, self.state_graph.edge_index)\n",
    "\t\t\tfor i in parents:\n",
    "\t\t\t\tif not visited[i]:\n",
    "\t\t\t\t\tstack.append(i)\n",
    "\t\t\t\t\tvisited[i] = True\n",
    "\t\treturn reward\n",
    "\n",
    "class ContinuousEnv(BaseGraphEnv):\n",
    "\tdef __init__(self, mode, verbose=1, **kwargs):\n",
    "\t\tsuper().__init__(**kwargs)\n",
    "\t\tself.mode = mode\n",
    "\t\tif self.mode == 'mobile':\n",
    "\t\t\tself.manipulator_initial_pos = torch.tensor([0, (self.grid_size[1]-1)/2], dtype=torch.float32)\n",
    "\t\telif self.mode == 'manipulator':\n",
    "\t\t\tself.manipulator_initial_pos = torch.tensor([(self.grid_size[0]-1)/2, (self.grid_size[1]-1)/2], dtype=torch.float32)\n",
    "\t\telse:\n",
    "\t\t\traise ValueError('Invalid mode')\n",
    "\t\tself.manipulator = self.manipulator_initial_pos.clone()\n",
    "\t\tself.normalization_factor = 1 / min(self.grid_size)\n",
    "\t\tself.manipulator = self.manipulator_initial_pos.clone()\n",
    "\t\tself.pp_cost = 0.2\n",
    "\t\tself.punish_cost = 100\n",
    "\t\tself.num_labels = 4\n",
    "\t\tself.verbose = verbose\n",
    "\n",
    "\tdef create_graph(self, labels=None, stack=True, ratio=0.5):\n",
    "\t\tif stack:\n",
    "\t\t\treturn create_graph_label_continuous(self.num_nodes, self.grid_size, self.num_labels, OBJECT_SIZES, labels, p=0.9, ratio=ratio)\n",
    "\t\telse:\n",
    "\t\t\treturn create_graph_label_continuous(self.num_nodes, self.grid_size, self.num_labels, OBJECT_SIZES, labels, p=0.0, ratio=ratio)\n",
    "\n",
    "\tdef make_table(self, state_graph=None):\n",
    "\t\tif state_graph is None:\n",
    "\t\t\tstate_graph = self.state_graph\n",
    "\n",
    "\t\tself.table = np.zeros(self.grid_size, dtype=int)\n",
    "\t\tfor i in range(self.num_nodes):\n",
    "\t\t\tif state_graph.x[i, Indices.RELATION].sum() > 0:\n",
    "\t\t\t\tcontinue\n",
    "\t\t\tcoor = state_graph.x[i, Indices.COORD].numpy()\n",
    "\t\t\tsize = self.obj_size(i)\n",
    "\t\t\tself.table[in_table_index(coor, size)] = i+1\n",
    "\n",
    "\tdef make_target_table(self):\n",
    "\t\tself.target_table = np.zeros(self.grid_size, dtype=int)\n",
    "\t\tfor i in range(self.num_nodes):\n",
    "\t\t\tif self.target_graph.x[i, Indices.RELATION].sum() > 0:\n",
    "\t\t\t\tcontinue\n",
    "\t\t\tcoor = self.target_graph.x[i, Indices.COORD].numpy()\n",
    "\t\t\tsize = self.obj_size(i)\n",
    "\t\t\tself.target_table[in_table_index(coor, size)] = i+1\n",
    "\n",
    "\tdef _get_obs(self):\n",
    "\t\treturn {'graph': copy_graph(self.state_graph), 'manipulator': self.manipulator.clone()}\n",
    "\t\n",
    "\tdef set_state(self, state):\n",
    "\t\tself.state_graph = copy_graph(state['graph'])\n",
    "\t\tself.manipulator = state['manipulator'].clone()\n",
    "\t\tself.make_table()\n",
    "\n",
    "\tdef get_state(self):\n",
    "\t\treturn self._get_obs()\n",
    "\n",
    "\tdef reset(self, state_graph=None, target_graph=None, stack=True, ratio=0.5):\n",
    "\t\tself.steps = 0\n",
    "\t\tself.state_graph = self.create_graph(stack=stack, ratio=ratio) if state_graph is None else copy_graph(state_graph)\n",
    "\t\tself.initial_graph = copy_graph(self.state_graph)\n",
    "\t\tlabels = list(self.state_graph.x[:, Indices.LABEL].reshape(-1).numpy())\n",
    "\t\tlabels = list(map(int, labels))\n",
    "\t\tif target_graph is None:\n",
    "\t\t\tself.target_graph = self.create_graph(labels, stack=stack, ratio=1-ratio)\n",
    "\t\t\twhile torch.equal(self.state_graph.x, self.target_graph.x):\n",
    "\t\t\t\tself.target_graph = self.create_graph(labels, stack=stack, ratio=1-ratio)\n",
    "\t\telse:\n",
    "\t\t\tself.target_graph = copy_graph(target_graph)\n",
    "\t\t\ttarget_labels = list(self.target_graph.x[:, Indices.LABEL].reshape(-1).numpy())\n",
    "\t\t\ttarget_labels = list(map(int, target_labels))\n",
    "\t\t\t# check whether the target graph has the same labels as the state graph\n",
    "\t\t\tif labels != target_labels:\n",
    "\t\t\t\traise ValueError('Target graph has different labels than the state graph')\n",
    "\n",
    "\t\tif stack is False:\n",
    "\t\t\tfor i in range(self.num_nodes):\n",
    "\t\t\t\tif torch.sum(self.state_graph.x[i, Indices.RELATION]) > 0:\n",
    "\t\t\t\t\traise ValueError('Initial graph has edges in Non-stack mode')\n",
    "\t\t\t\tif torch.sum(self.target_graph.x[i, Indices.RELATION]) > 0:\n",
    "\t\t\t\t\traise ValueError('Target graph has edges in Non-stack mode')\n",
    "\t\t\t\n",
    "\t\tself.manipulator = self.manipulator_initial_pos.clone()\n",
    "\t\t\n",
    "\t\tself.make_table()\n",
    "\t\tself.make_target_table()\n",
    "\t\treturn self._get_obs(), {}\n",
    "\n",
    "\tdef render(self, with_target=True, fig_size=2.5, return_fig=False):\n",
    "\t\tif self.verbose > 0:\n",
    "\t\t\tprint(f'Manipulator: {self.manipulator.numpy()}')\n",
    "\t\tif with_target:\n",
    "\t\t\tfig, ax = plt.subplots(1, 2, figsize=(fig_size * 2, fig_size))\n",
    "\t\t\tplot_graph(self.state_graph, self.grid_size, ax=ax[0], fig_size=fig_size, title='State Scene', constraints=[])\n",
    "\t\t\tplot_graph(self.target_graph, self.grid_size, ax=ax[1], fig_size=fig_size, title='Target Scene')\n",
    "\t\telse:\n",
    "\t\t\tfig, ax = plt.subplots(1, 1, figsize=(fig_size, fig_size))\n",
    "\t\t\tplot_graph(self.state_graph, self.grid_size, ax=ax, fig_size=fig_size, title='State Scene', constraints=[self.manipulator])\n",
    "\n",
    "\t\tif return_fig:\n",
    "\t\t\tplt.close()\n",
    "\t\t\treturn fig\n",
    "\t\telse:\n",
    "\t\t\tplt.show()\n",
    "\n",
    "\tdef get_valid_stacks(self):\n",
    "\t\tvalid_stacks = []\n",
    "\t\tfor k in range(self.num_nodes):\n",
    "\t\t\tempty_objects = get_empty_objects(self, ref_node=k, n=np.inf)\n",
    "\t\t\tfor i in empty_objects:\n",
    "\t\t\t\tvalid_stacks.append(self.encode_action('on', k, i, 0))\n",
    "\t\treturn valid_stacks\n",
    "\t\n",
    "\tdef get_valid_moves(self):\n",
    "\t\tvalid_moves = []\n",
    "\t\tfor k in range(self.num_nodes):\n",
    "\t\t\tif torch.equal(self.state_graph.x[k, Indices.COORD], self.target_graph.x[k, Indices.COORD]):\n",
    "\t\t\t\tcontinue\n",
    "\n",
    "\t\t\tpositions = get_empty_positions(self, ref_node=k, n=np.inf)\n",
    "\t\t\tfor position in positions:\n",
    "\t\t\t\tvalid_moves.append(self.encode_action('move', k, k, position))\n",
    "\t\treturn valid_moves\n",
    "\n",
    "\tdef get_valid_actions(self):\n",
    "\t\tvalid_actions = self.get_valid_stacks() + self.get_valid_moves()\n",
    "\t\treturn valid_actions\n",
    "\n",
    "\tdef move_node_with_parents(self, node, coordinates):\n",
    "\t\tn = self.state_graph.num_nodes\n",
    "\t\t# Find all parents of the node and their parents recursively and move them\n",
    "\t\tvisited = [False] * n\n",
    "\t\tvisited[node] = True\n",
    "\t\tstack = [node]\n",
    "\t\twhile len(stack) > 0:\n",
    "\t\t\tnode = stack.pop()\n",
    "\t\t\tself.state_graph.x[node, Indices.COORD] = coordinates.clone()\n",
    "\t\t\ti = find_start_node(self.state_graph, node)\n",
    "\t\t\tif i is not None and not visited[i]:\n",
    "\t\t\t\tstack.append(i)\n",
    "\t\t\t\tvisited[i] = True\n",
    "\t\n",
    "\tdef move_func(self, start_node, coordinates):\n",
    "\t\tif self.is_coor_occupied(coordinates, start_node):\n",
    "\t\t\tprint('occupied')\n",
    "\t\t\tcost = self.punish_cost\n",
    "\t\telse:\n",
    "\t\t\tprev_target = find_target_node(self.state_graph, start_node)\n",
    "\t\t\tif prev_target is not None:\n",
    "\t\t\t\tself.remove_edge(start_node, prev_target)\n",
    "\t\t\tprev_coord = self.state_graph.x[start_node, Indices.COORD].clone()\n",
    "\t\t\tself.move_node_with_parents(start_node, coordinates)\n",
    "\t\t\tcost = self.cal_movement(prev_coord, coordinates)\n",
    "\t\treturn cost\n",
    "\n",
    "\tdef stack_func(self, start_node, target_node):\n",
    "\t\tif not is_stable(self.state_graph.x, start_node, target_node):\n",
    "\t\t\tcost = self.punish_cost\n",
    "\t\telif not is_empty_object(self.state_graph, target_node):\n",
    "\t\t\tcost = self.punish_cost\n",
    "\t\telse:\n",
    "\t\t\tprev_target = find_target_node(self.state_graph, start_node)\n",
    "\t\t\tif prev_target == target_node:\n",
    "\t\t\t\tcost = self.punish_cost\n",
    "\t\t\t# elif self.check_loop_by_replacing_edge(start_node, prev_target, target_node):\n",
    "\t\t\t# \tcost = self.punish_cost\n",
    "\t\t\telif prev_target is None:\n",
    "\t\t\t\tprev_coord = self.state_graph.x[start_node, Indices.COORD].clone()\n",
    "\t\t\t\tself.add_edge(start_node, target_node)\n",
    "\t\t\t\tcost = self.cal_movement(prev_coord, self.state_graph.x[target_node, Indices.COORD])\n",
    "\t\t\telse:\n",
    "\t\t\t\tprev_coord = self.state_graph.x[start_node, Indices.COORD].clone()\n",
    "\t\t\t\tself.remove_edge(start_node, prev_target)\n",
    "\t\t\t\tself.add_edge(start_node, target_node)\n",
    "\t\t\t\tcost = self.cal_movement(prev_coord, self.state_graph.x[target_node, Indices.COORD])\n",
    "\t\treturn cost\n",
    "\n",
    "\tdef is_coor_occupied(self, coor, node, table=None):\n",
    "\t\tif table is None:\n",
    "\t\t\ttable = self.table\n",
    "\t\t\n",
    "\t\tsize = self.obj_size(node)\n",
    "\n",
    "\t\tif torch.equal(coor, self.state_graph.x[node, Indices.COORD]):\n",
    "\t\t\treturn True\n",
    "\t\tif coor[0] - size[0]//2 < 0 or coor[0] + size[0]//2 >= self.grid_size[0]:\n",
    "\t\t\treturn True\n",
    "\t\tif coor[1] - size[1]//2 < 0 or coor[1] + size[1]//2 >= self.grid_size[1]:\n",
    "\t\t\treturn True\n",
    "\t\t\n",
    "\t\tif np.any((table[in_table_index(coor, size)] != 0) & (table[in_table_index(coor, size)] != node+1)):\n",
    "\t\t\treturn True\n",
    "\t\treturn False\n",
    "\n",
    "\tdef occupied_score(self, coor, node, table=None):\n",
    "\t\tif table is None:\n",
    "\t\t\ttable = self.target_table\n",
    "\t\t\n",
    "\t\tsize = self.obj_size(node)\n",
    "\t\toccupied = np.sum((table[in_table_index(coor, size)] != 0) & (table[in_table_index(coor, size)] != node+1))\n",
    "\t\treturn occupied / (size[0] * size[1])\n",
    "\n",
    "\tdef get_obj_label(self, node):\n",
    "\t\treturn self.state_graph.x[node, Indices.LABEL].item()\n",
    "\n",
    "\tdef obj_size(self, node):\n",
    "\t\treturn get_obj_size(self.get_obj_label(node))\n",
    "\t\n",
    "\tdef manipulator_decode(self, coord):\n",
    "\t\tx, y = coord\n",
    "\t\tgrid_height, grid_width = self.grid_size\n",
    "\t\t# Avoid division by zero if dimensions are 1\n",
    "\t\tnorm_x = x / (grid_height - 1) if grid_height > 1 else 0\n",
    "\t\tnorm_y = y / (grid_width - 1) if grid_width > 1 else 0\n",
    "\n",
    "\t\t# Use normalized comparisons to decide which edge the coordinate is closest to.\n",
    "\t\tif norm_x < norm_y and norm_x < (1 - norm_y):\n",
    "\t\t\t# Closer to the top edge\n",
    "\t\t\treturn 0, y, grid_width - 1 - y\n",
    "\t\telif norm_x <= norm_y and norm_x >= (1 - norm_y):\n",
    "\t\t\t# Closer to the right edge\n",
    "\t\t\treturn 1, x, grid_height - 1 - x\n",
    "\t\telif norm_x >= norm_y and norm_x >= (1 - norm_y):\n",
    "\t\t\t# Closer to the bottom edge\n",
    "\t\t\treturn 2, grid_width - 1 - y, y\n",
    "\t\telse:\n",
    "\t\t\t# Closer to the left edge\n",
    "\t\t\treturn 3, grid_height - 1 - x, x\n",
    "\n",
    "\tdef cal_manipulator_movement(self, pre_coord, new_coord):\n",
    "\t\tpre_s, pre_cc, pre_cw = self.manipulator_decode(pre_coord)\n",
    "\t\tnew_s, new_cc, new_cw = self.manipulator_decode(new_coord)\n",
    "\t\tif pre_s == new_s:\n",
    "\t\t\tif pre_s == 0 or pre_s == 2:\n",
    "\t\t\t\treturn torch.norm(pre_coord[1] - new_coord[1])\n",
    "\t\t\telse:\n",
    "\t\t\t\treturn torch.norm(pre_coord[0] - new_coord[0])\n",
    "\t\telif (new_s==1 and pre_s==3) or (new_s==3 and pre_s==1):\n",
    "\t\t\treturn min(pre_cw + new_cc, pre_cc + new_cw) + self.grid_size[1]\n",
    "\t\telif (new_s==2 and pre_s==0) or (new_s==0 and pre_s==2):\n",
    "\t\t\treturn min(pre_cw + new_cc, pre_cc + new_cw) + self.grid_size[0]\n",
    "\t\telif new_s == pre_s+1 or (new_s == 0 and pre_s == 3):\n",
    "\t\t\treturn pre_cw + new_cc + 1\n",
    "\t\telse:\n",
    "\t\t\treturn pre_cc + new_cw + 1\n",
    "\n",
    "\tdef cal_movement(self, pre_coord, new_coord):\n",
    "\t\ttotal_movement = 0\n",
    "\t\tif self.mode == 'mobile':\n",
    "\t\t\ttotal_movement += self.cal_manipulator_movement(self.manipulator, pre_coord)\n",
    "\t\t\ttotal_movement += self.cal_manipulator_movement(pre_coord, new_coord)\n",
    "\t\t\tnew_s = self.manipulator_decode(new_coord)[0]\n",
    "\t\t\tif new_s == 0:\n",
    "\t\t\t\tself.manipulator = torch.tensor([0, new_coord[1]], dtype=torch.float32)\n",
    "\t\t\telif new_s == 1:\n",
    "\t\t\t\tself.manipulator = torch.tensor([new_coord[0], self.grid_size[1]-1], dtype=torch.float32)\n",
    "\t\t\telif new_s == 2:\n",
    "\t\t\t\tself.manipulator = torch.tensor([self.grid_size[0]-1, new_coord[1]], dtype=torch.float32)\n",
    "\t\t\telse:\n",
    "\t\t\t\tself.manipulator = torch.tensor([new_coord[0], 0], dtype=torch.float32)\n",
    "\t\telif self.mode == 'manipulator':\n",
    "\t\t\ttotal_movement += torch.norm(pre_coord - self.manipulator)\n",
    "\t\t\ttotal_movement += torch.norm(new_coord - pre_coord)\n",
    "\t\t\tself.manipulator = new_coord.clone()\n",
    "\n",
    "\t\treturn total_movement * self.normalization_factor\n",
    "\n",
    "\tdef random_action(self):\n",
    "\t\treturn random.choice(self.get_valid_actions())\n",
    "\n",
    "\tdef step_move(self, node, coordinates, log=True):\n",
    "\t\taction = self.encode_action('move', node, node, flatten_pos(coordinates, self.grid_size))\n",
    "\t\treturn self.step(action, log)\n",
    "\n",
    "\tdef step_on(self, start_node, target_node, log=True):\n",
    "\t\taction = self.encode_action('on', start_node, target_node, 0)\n",
    "\t\treturn self.step(action, log)\n",
    "\n",
    "\tdef step(self, action, log=False):\n",
    "\t\taction_type, start_node, target_node, coordinates = self.decode_action(action)\n",
    "\t\treturn self._step(action_type, start_node, target_node, coordinates, log=log)\n",
    "\n",
    "\tdef _step(self, action_type, start_node, target_node, coordinates, log=False):\n",
    "\t\tcoordinates = unflatten_pos(coordinates, self.grid_size)\n",
    "\t\tcost, truncated, terminated = 0.0, False, False\n",
    "\n",
    "\t\tif action_type == 'move':\n",
    "\t\t\tcost += self.move_func(start_node, coordinates)\n",
    "\t\telif action_type == 'on':\n",
    "\t\t\tcost += self.stack_func(start_node, target_node)\n",
    "\t\t\t\n",
    "\t\tcost += self.pp_cost\n",
    "\t\t\n",
    "\t\tif self.is_terminal_state():\n",
    "\t\t\tif self.mode == 'mobile':\n",
    "\t\t\t\tcost += self.cal_manipulator_movement(self.manipulator, self.manipulator_initial_pos) * self.normalization_factor\n",
    "\t\t\telif self.mode == 'manipulator':\n",
    "\t\t\t\tcost += torch.norm(self.manipulator - self.manipulator_initial_pos) * self.normalization_factor\n",
    "\t\t\telse:\n",
    "\t\t\t\traise ValueError('Invalid mode')\n",
    "\t\t\t# self.manipulator = self.manipulator_initial_pos.clone()\n",
    "\t\t\tterminated = True\n",
    "\t\n",
    "\t\tif log:\n",
    "\t\t\tif action_type == 'move':\n",
    "\t\t\t\tprint(f'Moved {start_node} to: {coordinates.numpy()} | cost: {cost:.3f} | done: {terminated or truncated}')\n",
    "\t\t\telse:\n",
    "\t\t\t\tprint(f'{start_node} -> {target_node} | cost: {cost:.3f} | done: {terminated or truncated}')\n",
    "\n",
    "\t\tself.make_table()\n",
    "\t\treturn cost, self.get_state()\n",
    "\n",
    "env = ContinuousEnv(mode='mobile', num_nodes=4, grid_size=(15, 30), verbose=0)\n",
    "env.reset(stack=False, ratio=0.5)\n",
    "initial_graph, target_graph = copy_graph(env.initial_graph), copy_graph(env.target_graph)\n",
    "env.reset(initial_graph, target_graph)\n",
    "env.render(with_target=False)\n",
    "for i in range(10):\n",
    "\tenv.step(env.random_action(), log=True)\n",
    "\tenv.render(with_target=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Algs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SearchAlg:\n",
    "    def __init__(self, env, node_class):\n",
    "        \"\"\"\n",
    "        Base class for search algorithms.\n",
    "        :param env: The environment in which the search is performed.\n",
    "        :param node_class: The class used for representing nodes in the search.\n",
    "        \"\"\"\n",
    "        self.env = env\n",
    "        self.node_class = node_class  # Generalized node class\n",
    "\n",
    "class LabbeNode:\n",
    "\tnode_counter = 0  # Static variable to assign unique IDs to each node\n",
    "\n",
    "\tdef __init__(self, state, remaining_nodes, parent=None, action=None, c=1):\n",
    "\t\tself.state = state\n",
    "\t\tself.parent = parent\n",
    "\t\tself.action = action\n",
    "\t\tself.children = {}\n",
    "\t\tself.n = 0\n",
    "\t\tself.w = 0.0\n",
    "\t\tself.c = c\n",
    "\t\tself.terminal_flag = False\n",
    "\t\tself.unexpanded_actions = remaining_nodes\n",
    "\t\t\n",
    "\t\t# Assign a unique ID to each node\n",
    "\t\tself.id = LabbeNode.node_counter\n",
    "\t\tLabbeNode.node_counter += 1\n",
    "\n",
    "\tdef get_state(self):\n",
    "\t\treturn copy_state(self.state)\n",
    "\n",
    "\tdef is_fully_expanded(self):\n",
    "\t\treturn len(self.unexpanded_actions) == 0\n",
    "\n",
    "\tdef ucb(self):\n",
    "\t\tif self.n == 0:\n",
    "\t\t\treturn float('inf')  # Prioritize unvisited nodes\n",
    "\n",
    "\t\texpected_value = self.w / self.n\n",
    "\t\texploration_term = self.c * np.sqrt(2 * np.log(self.parent.n) / self.n)\n",
    "\n",
    "\t\treturn expected_value + exploration_term\n",
    "\n",
    "\tdef best_child(self):\n",
    "\t\t# Accesses child nodes for best selection\n",
    "\t\treturn max(self.children.values(), key=lambda child: child.ucb())\n",
    "\n",
    "class Labbe(SearchAlg):\n",
    "\tdef __init__(self, env):\n",
    "\t\tsuper().__init__(env, LabbeNode)\n",
    "\n",
    "\tdef backup_search(self, node, reward, terminal_flag):\n",
    "\t\twhile node is not None:\n",
    "\t\t\tnode.n += 1\n",
    "\t\t\tnode.w += reward\n",
    "\t\t\tnode.terminal_flag = terminal_flag or node.terminal_flag\n",
    "\t\t\tnode = node.parent\n",
    "\n",
    "\tdef expand(self, node):\n",
    "\t\tif node.is_fully_expanded():\n",
    "\t\t\treturn None  # Prevents further expansion if no actions remain\n",
    "\n",
    "\t\tself.env.set_state(node.get_state())\n",
    "\t\t# random.shuffle(node.unexpanded_actions)\n",
    "\t\taction = self.get_motion(node.unexpanded_actions.pop())\n",
    "\t\tif action is None:\n",
    "\t\t\treturn None\n",
    "\t\t_, child_state = self.env.step_cost(action)\n",
    "\n",
    "\t\t# Continue expanding if the state hasn't changed\n",
    "\t\tif torch.equal(child_state['graph'].x, node.state['graph'].x):\n",
    "\t\t\treturn self.expand(node)\n",
    "\n",
    "\t\tremaining_nodes = self.get_remaining_nodes(self.env.get_state())\n",
    "\t\tchild_node = self.node_class(child_state, remaining_nodes, node, action, node.c)\n",
    "\t\tnode.children[action] = child_node\n",
    "\t\treturn child_node\n",
    "\n",
    "\tdef print_tree(self, node, depth=0, ter=False):\n",
    "\t\t# Print the current node with indentation to show its depth in the tree\n",
    "\t\tindent = \"    \" * depth  # Four spaces per level of depth\n",
    "\t\tif node.id == 0:\n",
    "\t\t\tprint(f\"Root | Visits: {node.n} | Value: {node.w:.2f} | Terminal: {node.terminal_flag}\")\n",
    "\t\telse:\n",
    "\t\t\tprint(f\"{indent}ID: {node.id} | Action: {node.action} | \"\n",
    "\t\t\t\t\tf\"Visits: {node.n} | Value: {node.w:.2f} | Terminal: {node.terminal_flag}\")\n",
    "\n",
    "\t\t# Sort children by value estimate\n",
    "\t\tif ter:\n",
    "\t\t\taccepted_children = [child for child in node.children.values() if child.terminal_flag]\n",
    "\t\t\tchildren = sorted(accepted_children, key=lambda child: child.w / child.n if child.n > 0 else float('inf'))\n",
    "\t\telse:\n",
    "\t\t\tchildren = sorted(node.children.values(), key=lambda child: child.w / child.n if child.n > 0 else float('inf'))\n",
    "\n",
    "\t\t# Recurse on children\n",
    "\t\tfor child in children:\n",
    "\t\t\tself.print_tree(child, depth + 1, ter)\n",
    "\n",
    "\tdef evaluate_state(self, state):\n",
    "\t\tstate_graph = state['graph']\n",
    "\t\treward = 0\n",
    "\t\t\n",
    "\t\tfor k in range(state_graph.num_nodes):\n",
    "\t\t\ti = find_target_node(self.env.target_graph, k)\n",
    "\t\t\tif i is not None:\n",
    "\t\t\t\tif is_edge_in_graph(state_graph, k, i):\n",
    "\t\t\t\t\treward += 1\n",
    "\t\t\telif find_target_node(state_graph, k) is None:\n",
    "\t\t\t\tif torch.equal(state_graph.x[k, Indices.COORD], self.env.target_graph.x[k, Indices.COORD]):\n",
    "\t\t\t\t\treward += 1\n",
    "\n",
    "\t\treturn reward\n",
    "\n",
    "\tdef find_best_path(self, ter=False):\n",
    "\t\tpath = []\n",
    "\t\tcurrent_node = self.root_node\n",
    "\n",
    "\t\twhile current_node.children:\n",
    "\t\t\tif ter:\n",
    "\t\t\t\taccepted_children = [child for child in current_node.children.values() if child.terminal_flag]\n",
    "\t\t\t\tif len(accepted_children) == 0:\n",
    "\t\t\t\t\tbreak\n",
    "\t\t\t\tnext_node = max(accepted_children, key=lambda child: child.w / child.n if child.n > 0 else float('inf'))\n",
    "\t\t\telse:\n",
    "\t\t\t\tnext_node = max(current_node.children.values(), key=lambda child: child.w / child.n if child.n > 0 else float('inf'))\n",
    "\t\t\tpath.append((next_node.action, next_node.w))\n",
    "\t\t\tcurrent_node = next_node\n",
    "\n",
    "\t\treturn [action for action, _ in path]\n",
    "\n",
    "\tdef get_remaining_nodes(self, state):\n",
    "\t\tstate_graph = state['graph']\n",
    "\n",
    "\t\tremaining_nodes = []\n",
    "\t\tfor k in range(state_graph.num_nodes):\n",
    "\t\t\tif not torch.equal(state_graph.x[k, Indices.COORD], self.env.target_graph.x[k, Indices.COORD]):\n",
    "\t\t\t\tremaining_nodes.append(k)\n",
    "\n",
    "\t\t# shuffle remaining nodes\n",
    "\t\trandom.shuffle(remaining_nodes)\n",
    "\n",
    "\t\treturn remaining_nodes\n",
    "\n",
    "\tdef get_motion(self, k):\n",
    "\t\tTk = self.env.target_graph.x[k, Indices.COORD]\n",
    "\t\tCK = self.env.state_graph.x[k, Indices.COORD]\n",
    "\t\tif torch.equal(Tk, CK):\n",
    "\t\t\treturn None\n",
    "\t\telif not self.env.is_coor_occupied(Tk, k):\n",
    "\t\t\t# Tk is free\n",
    "\t\t\tposition = Tk[0] * self.env.grid_size + Tk[1]\n",
    "\t\t\treturn self.env.encode_action('move', k, k, int(position.item()))\n",
    "\t\telse:\n",
    "\t\t\t# find which node is occupying Tk\n",
    "\t\t\tsize = self.env.get_obj_size(k)\n",
    "\t\t\toccupying_nodes = find_occupying_nodes(self.env.table, Tk, size)\n",
    "\t\t\tif len(occupying_nodes) == 0:\n",
    "\t\t\t\treturn None\n",
    "\t\t\tj = random.choice(occupying_nodes)\n",
    "\t\t\tfree_positions = get_empty_positions(self.env, ref_node=j, n=1)\n",
    "\t\t\tif len(free_positions) == 0:\n",
    "\t\t\t\treturn None\n",
    "\t\t\treturn self.env.encode_action('move', j, j, free_positions[0])\n",
    "\n",
    "\tdef loop(self):\n",
    "\t\tnode = self.root_node\n",
    "\n",
    "\t\t# Selection\n",
    "\t\tself.env.set_state(node.get_state())\n",
    "\t\twhile node.is_fully_expanded() and not self.env.is_terminal_state():\n",
    "\t\t\tnode = node.best_child()\n",
    "\t\t\tself.env.set_state(node.get_state())\n",
    "\n",
    "\t\t# Expansion\n",
    "\t\tif not self.env.is_terminal_state():\n",
    "\t\t\tnode = self.expand(node)\n",
    "\t\t\tif node is None:\n",
    "\t\t\t\treturn\n",
    "\n",
    "\t\t# Backpropagation\n",
    "\t\tterminal_flag = True if self.env.is_terminal_state() else False\n",
    "\t\treward = self.evaluate_state(node.get_state())\n",
    "\t\tself.backup_search(node, reward, terminal_flag)\n",
    "\n",
    "\tdef solve(self, verbose=1, c=1):\n",
    "\t\tfor i in range(self.env.num_nodes):\n",
    "\t\t\tif torch.sum(self.env.state_graph.x[:, Indices.RELATION.start+i]) > 0:\n",
    "\t\t\t\traise ValueError('Initial graph has edges')\n",
    "\t\treturn self._solve(verbose, c)\n",
    "\n",
    "\tdef _solve(self, verbose=1, c=1):\n",
    "\t\tself.root_node = self.node_class(self.env.get_state(), self.get_remaining_nodes(self.env.get_state()), c=c)\n",
    "\t\t\n",
    "\t\tsteps = 0\n",
    "\t\tif verbose > 0:\n",
    "\t\t\tpbar = tqdm(total=None, unit='iterations')\n",
    "\t\twhile self.root_node.terminal_flag is False:\n",
    "\t\t\tsteps += 1\n",
    "\t\t\tself.loop()\n",
    "\t\t\tif verbose > 0:\n",
    "\t\t\t\tpbar.update(1)\n",
    "\t\tif verbose > 0:\n",
    "\t\t\tpbar.close()\n",
    "\n",
    "\t\treturn self.find_best_path(ter=True), steps\n",
    "\n",
    "class LabbeS(Labbe):\n",
    "\tdef get_remaining_nodes(self, state):\n",
    "\t\tstate_graph = state['graph']\n",
    "\n",
    "\t\tremaining_nodes = []\n",
    "\t\tfor k in range(state_graph.num_nodes):\n",
    "\t\t\ti = find_target_node(self.env.target_graph, k)\n",
    "\t\t\tif i is not None:\n",
    "\t\t\t\tif not is_edge_in_graph(state_graph, k, i):\n",
    "\t\t\t\t\tremaining_nodes.append(k)\n",
    "\t\t\telif find_target_node(state_graph, k) is not None:\n",
    "\t\t\t\tremaining_nodes.append(k)\n",
    "\t\t\telse:\n",
    "\t\t\t\tif not torch.equal(state_graph.x[k, Indices.COORD], self.env.target_graph.x[k, Indices.COORD]):\n",
    "\t\t\t\t\tremaining_nodes.append(k)\n",
    "\n",
    "\t\t# shuffle remaining nodes\n",
    "\t\trandom.shuffle(remaining_nodes)\n",
    "\n",
    "\t\treturn remaining_nodes\n",
    "\n",
    "\tdef get_action_move_node_away(self, k):\n",
    "\t\tfree_position = get_empty_positions(self.env, ref_node=k, n=1)\n",
    "\t\tfree_object = get_empty_objects(self.env, ref_node=k, n=1)\n",
    "\t\tif len(free_object) > 0 and len(free_position) > 0:\n",
    "\t\t\tif random.random() < 0.5:\n",
    "\t\t\t\t# move the node to a random position\n",
    "\t\t\t\treturn self.env.encode_action('move', k, k, free_position[0])\n",
    "\t\t\telse:\n",
    "\t\t\t\t# stack on a random node\n",
    "\t\t\t\treturn self.env.encode_action('on', k, free_object[0], 0)\n",
    "\t\telif len(free_object) == 0 and len(free_position) > 0:\n",
    "\t\t\t# move the node to a random position\n",
    "\t\t\treturn self.env.encode_action('move', k, k, free_position[0])\n",
    "\t\telif len(free_position) == 0 and len(free_object) > 0:\n",
    "\t\t\t# stack on a random node\n",
    "\t\t\treturn self.env.encode_action('on', k, free_object[0], 0)\n",
    "\t\treturn None\n",
    "\t\n",
    "\tdef get_motion(self, k):\n",
    "\t\ti = find_target_node(self.env.target_graph, k)\n",
    "\t\tif i is not None:\n",
    "\t\t\tj = find_start_node(self.env.state_graph, i)\n",
    "\t\t\tif j is not None:\n",
    "\t\t\t\treturn self.get_action_move_node_away(j)\n",
    "\t\t\telse:\n",
    "\t\t\t\treturn self.env.encode_action('on', k, i, 0)\n",
    "\t\telse:\n",
    "\t\t\tj = find_target_node(self.env.state_graph, k)\n",
    "\t\t\tTk = self.env.target_graph.x[k, Indices.COORD]\n",
    "\t\t\tCK = self.env.state_graph.x[k, Indices.COORD]\n",
    "\t\t\tif torch.equal(Tk, CK):\n",
    "\t\t\t\tif j is not None:\n",
    "\t\t\t\t\tj = find_base_node(self.env.state_graph, j)\n",
    "\t\t\t\t\treturn self.get_action_move_node_away(j)\n",
    "\t\t\telse:\n",
    "\t\t\t\tif not self.env.is_coor_occupied(Tk, k):\n",
    "\t\t\t\t\t# Tk is free\n",
    "\t\t\t\t\tposition = Tk[0] * self.env.grid_size + Tk[1]\n",
    "\t\t\t\t\treturn self.env.encode_action('move', k, k, int(position.item()))\n",
    "\t\t\t\telse:\n",
    "\t\t\t\t\t# find which nodes are occupying Tk\n",
    "\t\t\t\t\tsize = self.env.get_obj_size(k)\n",
    "\t\t\t\t\toccupying_nodes = find_occupying_nodes(self.env.table, Tk, size)\n",
    "\t\t\t\t\tif len(occupying_nodes) == 0:\n",
    "\t\t\t\t\t\treturn None\n",
    "\t\t\t\t\tj = random.choice(occupying_nodes)\n",
    "\t\t\t\t\treturn self.get_action_move_node_away(j)\n",
    "\n",
    "\tdef solve(self, verbose=1, c=1):\n",
    "\t\treturn self._solve(verbose, c)\n",
    "\n",
    "class MultiLabbe(Labbe):\n",
    "\t\"\"\"run multiple Labbe instances in parallel and return the best solution\"\"\"\n",
    "\tdef solve(self, num_agents, verbose=1, c=1):\n",
    "\t\tbest_path, best_cost = None, float('inf')\n",
    "\t\tfor _ in range(num_agents):\n",
    "\t\t\tpath, steps = self._solve(verbose, c)\n",
    "\t\t\tif steps < best_steps:\n",
    "\t\t\t\tbest_path, best_steps = path, steps\n",
    "\t\treturn best_path, best_steps\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SearchNode:\n",
    "\tdef __init__(self, state, parent=None, action=None, cost_to_come=0, heuristic=0, depth=0):\n",
    "\t\tself.state = state\n",
    "\t\tself.parent = parent\n",
    "\t\tself.action = action\n",
    "\t\tself.c_cost = cost_to_come\t  \t# cost-to-come\n",
    "\t\tself.h_cost = heuristic\t\t\t# cost-to-go\n",
    "\t\tself.total_cost = self.c_cost + self.h_cost\n",
    "\t\tself.depth = depth\n",
    "\n",
    "\tdef __lt__(self, other):\n",
    "\t\treturn self.total_cost < other.total_cost  # Lower cost first\n",
    "\n",
    "\tdef get_state(self):\n",
    "\t\treturn copy_state(self.state)\n",
    "\n",
    "def find_required_max_depth(env, state, max_depth=100, stack=False):\n",
    "\tsteps = 0\n",
    "\tfor _ in range(5):\n",
    "\t\tenv.set_state(copy_state(state))\n",
    "\t\tif stack:\n",
    "\t\t\tfeasible_path, labbe_steps = LabbeS(env).solve(verbose=0)\n",
    "\t\telse:\n",
    "\t\t\tfeasible_path, labbe_steps = Labbe(env).solve(verbose=0)\n",
    "\t\tsteps += labbe_steps\n",
    "\t\tmax_depth = min(max_depth, len(feasible_path))\n",
    "\treturn max_depth, steps\n",
    "\n",
    "class Dijkstra(SearchAlg):\n",
    "\tdef __init__(self, env):\n",
    "\t\tsuper().__init__(env, SearchNode)\n",
    "\n",
    "\tdef get_valid_actions(self, state):\n",
    "\t\treturn self.env.get_valid_actions()\n",
    "\n",
    "\tdef solve(self, max_depth=100):\n",
    "\t\tsteps = 0\n",
    "\t\tstart_node = self.node_class(self.env.get_state(), cost_to_come=0)\n",
    "\n",
    "\t\tqueue = []\n",
    "\t\theapq.heappush(queue, start_node)\n",
    "\t\tvisited = {}\n",
    "\n",
    "\t\twhile queue:\n",
    "\t\t\tcurrent_node = heapq.heappop(queue)\n",
    "\n",
    "\t\t\t# Check if the current node's state matches the target state\n",
    "\t\t\tself.env.set_state(current_node.get_state())\n",
    "\t\t\tif self.env.is_terminal_state():\n",
    "\t\t\t\treturn reconstruct_path(current_node), steps\n",
    "\n",
    "\t\t\tif current_node.depth >= max_depth:\n",
    "\t\t\t\tcontinue\n",
    "\n",
    "\t\t\tlast_changed_node = self.env.decode_action(current_node.action)[1] if current_node.action is not None else None\n",
    "\t\t\tfor action in self.get_valid_actions(current_node.get_state()):\n",
    "\t\t\t\tsteps += 1\n",
    "\t\t\t\tself.env.set_state(current_node.get_state())\n",
    "\t\t\t\taction_type, start_node, target_node, coordinates = self.env.decode_action(action)\n",
    "\n",
    "\t\t\t\tif last_changed_node == start_node:\n",
    "\t\t\t\t\t# if the last changed node is the same as the current node, continue\n",
    "\t\t\t\t\tcontinue\n",
    "\n",
    "\t\t\t\tcost, child_state = self.env._step_cost(action_type, start_node, target_node, coordinates)\n",
    "\n",
    "\t\t\t\tif torch.equal(child_state['graph'].x, current_node.get_state()['graph'].x):\n",
    "\t\t\t\t\t# if state hasn't changed, continue\n",
    "\t\t\t\t\tcontinue\n",
    "\t\t\t\t\n",
    "\t\t\t\tchild_hash = state_to_hashable(child_state)\n",
    "\n",
    "\t\t\t\t# Calculate the accumulated cost for the current path\n",
    "\t\t\t\tnew_total_cost = current_node.total_cost + cost\n",
    "\n",
    "\t\t\t\t# Retain the node with better cost\n",
    "\t\t\t\tif child_hash not in visited or visited[child_hash] > new_total_cost:\n",
    "\t\t\t\t\tvisited[child_hash] = new_total_cost\n",
    "\t\t\t\t\tchild_node = self.node_class(child_state, current_node, action, cost_to_come=new_total_cost, depth=current_node.depth+1)\n",
    "\n",
    "\t\t\t\t\theapq.heappush(queue, child_node)\n",
    "\n",
    "\t\treturn None, steps  # No path found\n",
    "\n",
    "class A_star(SearchAlg):\n",
    "\tdef __init__(self, env):\n",
    "\t\tsuper().__init__(env, SearchNode)\n",
    "\t\tself.num_buffers = 2\n",
    "\n",
    "\tdef evaluate_state(self, state):\n",
    "\t\tstate_graph = state['graph']\n",
    "\t\theuristic = 0\n",
    "\n",
    "\t\tfor k in range(state_graph.num_nodes):\n",
    "\t\t\tTK = self.env.target_graph.x[k, Indices.COORD]\n",
    "\t\t\tCK = state_graph.x[k, Indices.COORD]\n",
    "\t\t\tmin_dis = torch.norm(CK - TK)\n",
    "\n",
    "\t\t\ti = find_target_node(self.env.target_graph, k)\n",
    "\t\t\tif i is not None:\n",
    "\t\t\t\tif not is_edge_in_graph(state_graph, k, i):\n",
    "\t\t\t\t\tCI = state_graph.x[i, Indices.COORD]\n",
    "\t\t\t\t\tnew_dis = torch.norm(CK - CI)\n",
    "\t\t\t\t\tif new_dis < min_dis:\n",
    "\t\t\t\t\t\tmin_dis = new_dis\n",
    "\t\t\t\t\t\tif find_start_node(state_graph, i) is not None:\n",
    "\t\t\t\t\t\t\theuristic += self.env.pp_cost\n",
    "\t\t\t\t\theuristic += self.env.pp_cost\n",
    "\t\t\t\t\theuristic += self.env.normalization_factor * min_dis\n",
    "\t\t\telif find_target_node(state_graph, k) is not None:\n",
    "\t\t\t\tif min_dis == 0:\n",
    "\t\t\t\t\theuristic += self.env.pp_cost\n",
    "\t\t\telse:\n",
    "\t\t\t\tif min_dis != 0:\n",
    "\t\t\t\t\tstack = False\n",
    "\t\t\t\t\tfor j in range(state_graph.num_nodes):\n",
    "\t\t\t\t\t\tif k != j and is_stable(state_graph.x, k, j):\n",
    "\t\t\t\t\t\t\tCJ = state_graph.x[j, Indices.COORD]\n",
    "\t\t\t\t\t\t\tTJ = self.env.target_graph.x[j, Indices.COORD]\n",
    "\t\t\t\t\t\t\tnew_dis = torch.norm(CK - CJ) + torch.norm(TK - TJ)\n",
    "\t\t\t\t\t\t\tif new_dis < min_dis:\n",
    "\t\t\t\t\t\t\t\tmin_dis = new_dis\n",
    "\t\t\t\t\t\t\t\tstack = True\n",
    "\t\t\t\t\tif stack:\n",
    "\t\t\t\t\t\theuristic += self.env.pp_cost\n",
    "\t\t\t\t\theuristic += self.env.pp_cost\n",
    "\t\t\t\t\theuristic += self.env.normalization_factor * min_dis\n",
    "\t\t\n",
    "\t\t# return self.env.normalize_cost(heuristic)\n",
    "\t\treturn heuristic\n",
    "\n",
    "\tdef evaluate_state(self, state):\n",
    "\t\tstate_graph = state['graph']\n",
    "\t\theuristic = 0\n",
    "\n",
    "\t\tfor k in range(state_graph.num_nodes):\n",
    "\t\t\tTK = self.env.target_graph.x[k, Indices.COORD]\n",
    "\t\t\tCK = state_graph.x[k, Indices.COORD]\n",
    "\t\t\tmin_dis = torch.norm(CK - TK)\n",
    "\n",
    "\t\t\ti = find_target_node(self.env.target_graph, k)\n",
    "\t\t\tif i is not None:\n",
    "\t\t\t\tif not is_edge_in_graph(state_graph, k, i):\n",
    "\t\t\t\t\tCI = state_graph.x[i, Indices.COORD]\n",
    "\t\t\t\t\tnew_dis = torch.norm(CK - CI)\n",
    "\t\t\t\t\tif new_dis < min_dis:\n",
    "\t\t\t\t\t\tmin_dis = new_dis\n",
    "\t\t\t\t\t\tif find_start_node(state_graph, i) is not None:\n",
    "\t\t\t\t\t\t\theuristic += self.env.pp_cost\n",
    "\t\t\t\t\theuristic += self.env.pp_cost\n",
    "\t\t\t\t\theuristic += self.env.normalization_factor * min_dis\n",
    "\t\t\telif find_target_node(state_graph, k) is not None:\n",
    "\t\t\t\tif min_dis == 0:\n",
    "\t\t\t\t\theuristic += self.env.pp_cost\n",
    "\t\t\telse:\n",
    "\t\t\t\tif min_dis != 0:\n",
    "\t\t\t\t\tstack = False\n",
    "\t\t\t\t\tfor j in range(state_graph.num_nodes):\n",
    "\t\t\t\t\t\tif k != j and is_stable(state_graph.x, k, j):\n",
    "\t\t\t\t\t\t\tCJ = state_graph.x[j, Indices.COORD]\n",
    "\t\t\t\t\t\t\tTJ = self.env.target_graph.x[j, Indices.COORD]\n",
    "\t\t\t\t\t\t\tnew_dis = torch.norm(CK - CJ) + torch.norm(TK - TJ)\n",
    "\t\t\t\t\t\t\tif new_dis < min_dis:\n",
    "\t\t\t\t\t\t\t\tmin_dis = new_dis\n",
    "\t\t\t\t\t\t\t\tstack = True\n",
    "\t\t\t\t\tif stack:\n",
    "\t\t\t\t\t\theuristic += self.env.pp_cost\n",
    "\t\t\t\t\theuristic += self.env.pp_cost\n",
    "\t\t\t\t\theuristic += self.env.normalization_factor * min_dis\n",
    "\t\t\n",
    "\t\t# return self.env.normalize_cost(heuristic)\n",
    "\t\treturn heuristic\n",
    "\n",
    "\tdef get_remaining_nodes(self, state):\n",
    "\t\tstate_graph = state['graph']\n",
    "\n",
    "\t\tremaining_nodes = []\n",
    "\t\tfor k in range(state_graph.num_nodes):\n",
    "\t\t\ti = find_target_node(self.env.target_graph, k)\n",
    "\t\t\tif i is not None:\n",
    "\t\t\t\tif not is_edge_in_graph(state_graph, k, i):\n",
    "\t\t\t\t\tremaining_nodes.append(k)\n",
    "\t\t\telif find_target_node(state_graph, k) is not None:\n",
    "\t\t\t\tremaining_nodes.append(k)\n",
    "\t\t\telse:\n",
    "\t\t\t\tif not torch.equal(state_graph.x[k, Indices.COORD], self.env.target_graph.x[k, Indices.COORD]):\n",
    "\t\t\t\t\tremaining_nodes.append(k)\n",
    "\n",
    "\t\t# shuffle remaining nodes\n",
    "\t\trandom.shuffle(remaining_nodes)\n",
    "\n",
    "\t\treturn remaining_nodes\n",
    "\n",
    "\tdef get_empty_positions_with_target(self, ref_node, n=1):\n",
    "\t\tpositions = []\n",
    "\t\ttarget_pos = self.env.target_graph.x[ref_node, Indices.COORD]\n",
    "\t\tp = int(target_pos[0] * self.env.grid_size + target_pos[1])\n",
    "\t\tif not self.env.is_coor_occupied(target_pos, ref_node):\n",
    "\t\t\tpositions.append(p)\n",
    "\t\telse:\n",
    "\t\t\tif n == 0:\n",
    "\t\t\t\treturn positions\n",
    "\t\t\tall_positions = list(range(self.env.grid_size * self.env.grid_size))\n",
    "\t\t\trandom.shuffle(all_positions)\n",
    "\t\t\tfor position in all_positions:\n",
    "\t\t\t\tp = unflatten_pos(position, self.env.grid_size)\n",
    "\t\t\t\tif not torch.equal(p, target_pos) and not self.env.is_coor_occupied(p, ref_node):\n",
    "\t\t\t\t\tpositions.append(position)\n",
    "\t\t\t\t\tif len(positions) >= n:\n",
    "\t\t\t\t\t\tbreak\n",
    "\t\treturn positions\n",
    "\n",
    "\tdef get_valid_actions(self, state):\n",
    "\t\tself.env.set_state(state)\n",
    "\n",
    "\t\tstack_nums = max(int(0.6 * self.num_buffers), 1)\n",
    "\n",
    "\t\tnodes = list(range(self.env.num_nodes))\n",
    "\t\trandom.shuffle(nodes)\n",
    "\n",
    "\t\tvalid_actions = []\n",
    "\t\tfor k in self.get_remaining_nodes(state):\n",
    "\t\t\tvalid_stacks = []\n",
    "\t\t\tfor j in nodes:\n",
    "\t\t\t\tif k != j and not is_edge_in_graph(self.env.state_graph, k, j):\n",
    "\t\t\t\t\tif is_stable(self.env.state_graph.x, k, j):\n",
    "\t\t\t\t\t\tif is_empty_object(self.env.state_graph, j):\n",
    "\t\t\t\t\t\t\tvalid_stacks.append(self.env.encode_action('on', k, j, 0))\n",
    "\t\t\t\t\t\t\tif len(valid_stacks) >= stack_nums:\n",
    "\t\t\t\t\t\t\t\tbreak\n",
    "\n",
    "\t\t\tvalid_moves = []\n",
    "\t\t\tfor position in self.get_empty_positions_with_target(ref_node=k, n=self.num_buffers-len(valid_stacks)):\n",
    "\t\t\t\tvalid_moves.append(self.env.encode_action('move', k, k, position))\n",
    "\t\t\t\t\n",
    "\t\t\tvalid_actions += valid_stacks + valid_moves\n",
    "\n",
    "\t\treturn valid_actions\n",
    "\n",
    "\tdef solve(self, max_depth=100, num_buffers=2):\n",
    "\t\tself.num_buffers = num_buffers\n",
    "\t\treturn self._solve(max_depth)\n",
    "\n",
    "\tdef _solve(self, max_depth=100):\n",
    "\t\tsteps = 0\n",
    "\t\th_cost = self.evaluate_state(self.env.get_state())\n",
    "\t\tstart_node = self.node_class(self.env.get_state(), cost_to_come=0, heuristic=h_cost)\n",
    "\n",
    "\t\tqueue = []\n",
    "\t\theapq.heappush(queue, start_node)\n",
    "\t\tvisited = {}\n",
    "\n",
    "\t\twhile queue:\n",
    "\t\t\tcurrent_node = heapq.heappop(queue)\n",
    "\n",
    "\t\t\t# Check if the current node's state matches the target state\n",
    "\t\t\tself.env.set_state(current_node.get_state())\n",
    "\t\t\tif self.env.is_terminal_state():\n",
    "\t\t\t\treturn reconstruct_path(current_node), steps\n",
    "\n",
    "\t\t\tif current_node.depth >= max_depth:\n",
    "\t\t\t\tcontinue\n",
    "\n",
    "\t\t\tlast_changed_node = self.env.decode_action(current_node.action)[1] if current_node.action is not None else None\n",
    "\t\t\tfor action in self.get_valid_actions(current_node.get_state()):\n",
    "\t\t\t\tsteps += 1\n",
    "\t\t\t\taction_type, start_node, target_node, coordinates = self.env.decode_action(action)\n",
    "\n",
    "\t\t\t\tif start_node == last_changed_node:\n",
    "\t\t\t\t\t# If the last changed node is the same as the current node, continue\n",
    "\t\t\t\t\tcontinue\n",
    "\n",
    "\t\t\t\tself.env.set_state(current_node.get_state())\n",
    "\t\t\t\tcost, child_state = self.env._step_cost(action_type, start_node, target_node, coordinates)\n",
    "\n",
    "\t\t\t\tif torch.equal(child_state['graph'].x, current_node.get_state()['graph'].x):\n",
    "\t\t\t\t\t# if state hasn't changed, continue\n",
    "\t\t\t\t\tcontinue\n",
    "\n",
    "\t\t\t\tchild_hash = state_to_hashable(child_state)\n",
    "\n",
    "\t\t\t\t# Calculate the accumulated cost for the current path\n",
    "\t\t\t\tnew_c_cost = current_node.c_cost + cost\n",
    "\t\t\t\th_cost = self.evaluate_state(child_state)\n",
    "\t\t\t\tnew_total_cost = new_c_cost + h_cost\n",
    "\n",
    "\t\t\t\t# Retain the node with better cost\n",
    "\t\t\t\tif child_hash not in visited or visited[child_hash] > new_total_cost:\n",
    "\t\t\t\t\tvisited[child_hash] = new_total_cost\n",
    "\t\t\t\t\tchild_node = self.node_class(\n",
    "\t\t\t\t\t\tstate=child_state, \n",
    "\t\t\t\t\t\tparent=current_node, \n",
    "\t\t\t\t\t\taction=action, \n",
    "\t\t\t\t\t\tcost_to_come=new_c_cost, \n",
    "\t\t\t\t\t\theuristic=h_cost,\n",
    "\t\t\t\t\t\tdepth=current_node.depth+1\n",
    "\t\t\t\t\t)\n",
    "\n",
    "\t\t\t\t\theapq.heappush(queue, child_node)\n",
    "\n",
    "\t\treturn None, steps  # No path found\n",
    "\n",
    "class A_starGA(A_star):\n",
    "\tdef _solve(self, max_depth=100):\n",
    "\t\tbest_plan = None\n",
    "\t\tbest_cost = float('inf')\n",
    "\n",
    "\t\tsteps = 0\n",
    "\t\th_cost = self.evaluate_state(self.env.get_state())\n",
    "\t\tstart_node = self.node_class(self.env.get_state(), cost_to_come=0, heuristic=h_cost)\n",
    "\n",
    "\t\tqueue = []\n",
    "\t\theapq.heappush(queue, start_node)\n",
    "\t\tvisited = {}\n",
    "\n",
    "\t\twhile queue:\n",
    "\t\t\tcurrent_node = heapq.heappop(queue)\n",
    "\n",
    "\t\t\t# Check if the current node's state matches the target state\n",
    "\t\t\tself.env.set_state(current_node.get_state())\n",
    "\t\t\tif self.env.is_terminal_state():\n",
    "\t\t\t\treturn reconstruct_path(current_node), steps\n",
    "\n",
    "\t\t\tif current_node.depth >= max_depth:\n",
    "\t\t\t\tcontinue\n",
    "\n",
    "\t\t\tlast_changed_node = self.env.decode_action(current_node.action)[1] if current_node.action is not None else None\n",
    "\t\t\tfor action in self.get_valid_actions(current_node.get_state()):\n",
    "\t\t\t\tsteps += 1\n",
    "\t\t\t\taction_type, start_node, target_node, coordinates = self.env.decode_action(action)\n",
    "\n",
    "\t\t\t\tif start_node == last_changed_node:\n",
    "\t\t\t\t\t# If the last changed node is the same as the current node, continue\n",
    "\t\t\t\t\tcontinue\n",
    "\n",
    "\t\t\t\tself.env.set_state(current_node.get_state())\n",
    "\t\t\t\tcost, child_state = self.env._step_cost(action_type, start_node, target_node, coordinates)\n",
    "\n",
    "\t\t\t\tif torch.equal(child_state['graph'].x, current_node.get_state()['graph'].x):\n",
    "\t\t\t\t\t# if state hasn't changed, continue\n",
    "\t\t\t\t\tcontinue\n",
    "\n",
    "\t\t\t\tchild_hash = state_to_hashable(child_state)\n",
    "\n",
    "\t\t\t\t# Calculate the accumulated cost for the current path\n",
    "\t\t\t\tnew_c_cost = current_node.c_cost + cost\n",
    "\t\t\t\th_cost = self.evaluate_state(child_state)\n",
    "\t\t\t\tnew_total_cost = new_c_cost + h_cost\n",
    "\n",
    "\t\t\t\t# Retain the node with better cost\n",
    "\t\t\t\tif child_hash not in visited or visited[child_hash] > new_total_cost:\n",
    "\t\t\t\t\tvisited[child_hash] = new_total_cost\n",
    "\t\t\t\t\tchild_node = self.node_class(\n",
    "\t\t\t\t\t\tstate=child_state, \n",
    "\t\t\t\t\t\tparent=current_node, \n",
    "\t\t\t\t\t\taction=action, \n",
    "\t\t\t\t\t\tcost_to_come=new_c_cost, \n",
    "\t\t\t\t\t\theuristic=h_cost,\n",
    "\t\t\t\t\t\tdepth=current_node.depth+1\n",
    "\t\t\t\t\t)\n",
    "\n",
    "\t\t\t\t\theapq.heappush(queue, child_node)\n",
    "\n",
    "\t\t\t# Goal Attempting\n",
    "\t\t\tself.env.set_state(current_node.get_state())\n",
    "\t\t\tfeasible_path, labbe_steps = LabbeS(self.env).solve(verbose=0)\n",
    "\t\t\tsteps += labbe_steps\n",
    "\n",
    "\t\t\tfeasible_path_cost = current_node.c_cost\n",
    "\t\t\tself.env.set_state(current_node.get_state())\n",
    "\t\t\tfor action in feasible_path:\n",
    "\t\t\t\tfeasible_path_cost += self.env.step_cost(action)[0]\n",
    "\n",
    "\t\t\t# Remove all the nodes with their total cost is greater than the feasible path cost\n",
    "\t\t\tfor node in queue:\n",
    "\t\t\t\tif node.total_cost > feasible_path_cost:\n",
    "\t\t\t\t\tqueue.remove(node)\n",
    "\n",
    "\t\t\tif feasible_path_cost < best_cost:\n",
    "\t\t\t\tbest_plan = reconstruct_path(current_node) + feasible_path\n",
    "\t\t\t\tbest_cost = feasible_path_cost\n",
    "\n",
    "\t\treturn best_plan, steps  # No path found\n",
    "\n",
    "class Strap(A_star):\n",
    "\tdef evaluate_state(self, state):\n",
    "\t\tstate_graph = state['graph']\n",
    "\t\theuristic = 0\n",
    "\n",
    "\t\tfor k in self.get_remaining_nodes(state):\n",
    "\t\t\tCK = state_graph.x[k, Indices.COORD]\n",
    "\t\t\tTK = self.env.target_graph.x[k, Indices.COORD]\n",
    "\t\t\theuristic += torch.norm(CK - TK) * self.env.normalization_factor\n",
    "\t\t\theuristic += self.env.pp_cost\n",
    "\t\t\n",
    "\t\t# return self.env.normalize_cost(heuristic)\n",
    "\t\treturn heuristic\n",
    "\n",
    "\tdef get_remaining_nodes(self, state):\n",
    "\t\tstate_graph = state['graph']\n",
    "\n",
    "\t\tremaining_nodes = []\n",
    "\t\tfor k in range(state_graph.num_nodes):\n",
    "\t\t\tif not torch.equal(state_graph.x[k, Indices.COORD], self.env.target_graph.x[k, Indices.COORD]):\n",
    "\t\t\t\tremaining_nodes.append(k)\n",
    "\n",
    "\t\t# shuffle remaining nodes\n",
    "\t\trandom.shuffle(remaining_nodes)\n",
    "\t\t\n",
    "\t\treturn remaining_nodes\n",
    "\n",
    "\tdef get_valid_actions(self, state):\n",
    "\t\tself.env.set_state(copy_state(state))\n",
    "\n",
    "\t\tvalid_actions = []\n",
    "\t\tfor k in self.get_remaining_nodes(state):\n",
    "\t\t\tTk = self.env.target_graph.x[k, Indices.COORD]\n",
    "\t\t\tif not self.env.is_coor_occupied(Tk, k):\n",
    "\t\t\t\t# Tk is free\n",
    "\t\t\t\tvalid_actions.append(self.env.encode_action('move', k, k, Tk))\n",
    "\t\t\telse:\n",
    "\t\t\t\t# Choose random buffer position\n",
    "\t\t\t\tfor position in get_empty_positions(self.env, ref_node=k, n=self.num_buffers):\n",
    "\t\t\t\t\tvalid_actions.append(self.env.encode_action('move', k, k, position))\n",
    "\n",
    "\t\treturn valid_actions\n",
    "\n",
    "\tdef solve(self, max_depth=100, num_buffers=2, verbose=1):\n",
    "\t\tself.verbose = verbose\n",
    "\n",
    "\t\tself.env.reset(self.env.initial_graph, self.env.target_graph)\n",
    "\t\tmax_depth, labbe_steps = find_required_max_depth(self.env, self.env.get_state(), max_depth, stack=False)\n",
    "\t\tif self.verbose > 0:\n",
    "\t\t\tprint('max depth:', max_depth)\n",
    "\n",
    "\t\tself.env.reset(self.env.initial_graph, self.env.target_graph)\n",
    "\t\toptimal_path, steps = super().solve(max_depth=max_depth, num_buffers=num_buffers)\n",
    "\t\t# steps += labbe_steps\n",
    "\n",
    "\t\treturn optimal_path, steps\n",
    "\n",
    "class StrapGA(Strap):\n",
    "\tdef _solve(self, max_depth=100):\n",
    "\t\tbest_plan = None\n",
    "\t\tbest_cost = float('inf')\n",
    "\n",
    "\t\tsteps = 0\n",
    "\t\th_cost = self.evaluate_state(self.env.get_state())\n",
    "\t\tstart_node = self.node_class(self.env.get_state(), cost_to_come=0, heuristic=h_cost)\n",
    "\n",
    "\t\tqueue = []\n",
    "\t\theapq.heappush(queue, start_node)\n",
    "\t\tvisited = {}\n",
    "\n",
    "\t\twhile queue:\n",
    "\t\t\tcurrent_node = heapq.heappop(queue)\n",
    "\n",
    "\t\t\t# Check if the current node's state matches the target state\n",
    "\t\t\tself.env.set_state(current_node.get_state())\n",
    "\t\t\tif self.env.is_terminal_state():\n",
    "\t\t\t\treturn reconstruct_path(current_node), steps\n",
    "\n",
    "\t\t\tif current_node.depth >= max_depth:\n",
    "\t\t\t\tcontinue\n",
    "\n",
    "\t\t\tlast_changed_node = self.env.decode_action(current_node.action)[1] if current_node.action is not None else None\n",
    "\t\t\tfor action in self.get_valid_actions(current_node.get_state()):\n",
    "\t\t\t\tsteps += 1\n",
    "\t\t\t\taction_type, start_node, target_node, coordinates = self.env.decode_action(action)\n",
    "\n",
    "\t\t\t\tif start_node == last_changed_node:\n",
    "\t\t\t\t\t# If the last changed node is the same as the current node, continue\n",
    "\t\t\t\t\tcontinue\n",
    "\n",
    "\t\t\t\tself.env.set_state(current_node.get_state())\n",
    "\t\t\t\tcost, child_state = self.env._step_cost(action_type, start_node, target_node, coordinates)\n",
    "\n",
    "\t\t\t\tif torch.equal(child_state['graph'].x, current_node.get_state()['graph'].x):\n",
    "\t\t\t\t\t# if state hasn't changed, continue\n",
    "\t\t\t\t\tcontinue\n",
    "\n",
    "\t\t\t\tchild_hash = state_to_hashable(child_state)\n",
    "\n",
    "\t\t\t\t# Calculate the accumulated cost for the current path\n",
    "\t\t\t\tnew_c_cost = current_node.c_cost + cost\n",
    "\t\t\t\th_cost = self.evaluate_state(child_state)\n",
    "\t\t\t\tnew_total_cost = new_c_cost + h_cost\n",
    "\n",
    "\t\t\t\t# Retain the node with better cost\n",
    "\t\t\t\tif child_hash not in visited or visited[child_hash] > new_total_cost:\n",
    "\t\t\t\t\tvisited[child_hash] = new_total_cost\n",
    "\t\t\t\t\tchild_node = self.node_class(\n",
    "\t\t\t\t\t\tstate=child_state, \n",
    "\t\t\t\t\t\tparent=current_node, \n",
    "\t\t\t\t\t\taction=action, \n",
    "\t\t\t\t\t\tcost_to_come=new_c_cost, \n",
    "\t\t\t\t\t\theuristic=h_cost,\n",
    "\t\t\t\t\t\tdepth=current_node.depth+1\n",
    "\t\t\t\t\t)\n",
    "\n",
    "\t\t\t\t\theapq.heappush(queue, child_node)\n",
    "\n",
    "\t\t\t# Goal Attempting\n",
    "\t\t\tself.env.set_state(current_node.get_state())\n",
    "\t\t\tfeasible_path, labbe_steps = Labbe(self.env).solve(verbose=0)\n",
    "\t\t\tsteps += labbe_steps\n",
    "\n",
    "\t\t\tfeasible_path_cost = current_node.c_cost\n",
    "\t\t\tself.env.set_state(current_node.get_state())\n",
    "\t\t\tfor action in feasible_path:\n",
    "\t\t\t\tfeasible_path_cost += self.env.step_cost(action)[0]\n",
    "\n",
    "\t\t\t# Remove all the nodes with their total cost is greater than the feasible path cost\n",
    "\t\t\tfor node in queue:\n",
    "\t\t\t\tif node.total_cost > feasible_path_cost:\n",
    "\t\t\t\t\tqueue.remove(node)\n",
    "\n",
    "\t\t\tif feasible_path_cost < best_cost:\n",
    "\t\t\t\tbest_plan = reconstruct_path(current_node) + feasible_path\n",
    "\t\t\t\tbest_cost = feasible_path_cost\n",
    "\n",
    "\t\treturn best_plan, steps  # No path found\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score(env, coor, obj):\n",
    "\tdis_obj = torch.norm(env.target_graph.x[obj, Indices.COORD] - coor).item()\n",
    "\treturn env.occupied_score(coor, obj) + dis_obj * env.normalization_factor\n",
    "\n",
    "class MctsNode:\n",
    "\tnode_counter = 0  # Static variable to assign unique IDs to each node\n",
    "\n",
    "\tdef __init__(self, state, valid_actions, parent=None, action=None, cost_to_come=0.0, c=1, depth=0):\n",
    "\t\tself.state = state\n",
    "\t\tself.parent = parent\n",
    "\t\tself.action = action\n",
    "\t\tself.children = {}\n",
    "\t\tself.visit_count = 0\n",
    "\t\tself.value = float('inf')\n",
    "\t\tself.value_upper = -float('inf')\n",
    "\t\tself.c_cost = cost_to_come\n",
    "\t\tself.c = c\n",
    "\t\tself.unexpanded_actions = valid_actions\n",
    "\t\tself.depth = depth\n",
    "\t\t\n",
    "\t\t# Assign a unique ID to each node\n",
    "\t\tself.id = MctsNode.node_counter\n",
    "\t\tMctsNode.node_counter += 1\n",
    "\n",
    "\tdef get_state(self):\n",
    "\t\treturn copy_state(self.state)\n",
    "\n",
    "\tdef is_fully_expanded(self):\n",
    "\t\treturn len(self.unexpanded_actions) == 0\n",
    "\n",
    "\tdef uct(self):\n",
    "\t\t# if self.visit_count == 0:\n",
    "\t\t# \treturn -float('inf')  # Prioritize unvisited nodes\n",
    "\t\t# visit_count = self.visit_count\n",
    "\t\tvisit_count = self.visit_count + 1\n",
    "\n",
    "\t\ttotal_cost_estimate = self.value #(self.parent.value - self.value) / (self.parent.value_upper - self.value_upper)\n",
    "\t\texploration_term = self.c * np.sqrt(2 * np.log(self.parent.visit_count) / visit_count)\n",
    "\n",
    "\t\treturn total_cost_estimate - exploration_term  # Minimization form\n",
    "\n",
    "class Sorp(SearchAlg):\n",
    "\tdef __init__(self, env, node_class=None):\n",
    "\t\tif node_class is None:\n",
    "\t\t\tnode_class = MctsNode\n",
    "\t\tsuper().__init__(env, node_class)\n",
    "\t\tself.num_buffers = 2\n",
    "\n",
    "\tdef get_remaining_nodes(self, state):\n",
    "\t\tstate_graph = state['graph']\n",
    "\n",
    "\t\tremaining_nodes = []\n",
    "\t\tfor k in range(state_graph.num_nodes):\n",
    "\t\t\ti = find_target_node(self.env.target_graph, k)\n",
    "\t\t\tif i is not None:\n",
    "\t\t\t\tif not is_edge_in_graph(state_graph, k, i):\n",
    "\t\t\t\t\tremaining_nodes.append(k)\n",
    "\t\t\telif find_target_node(state_graph, k) is not None:\n",
    "\t\t\t\tremaining_nodes.append(k)\n",
    "\t\t\telse:\n",
    "\t\t\t\tif not torch.equal(state_graph.x[k, Indices.COORD], self.env.target_graph.x[k, Indices.COORD]):\n",
    "\t\t\t\t\tremaining_nodes.append(k)\n",
    "\n",
    "\t\t# shuffle remaining nodes\n",
    "\t\trandom.shuffle(remaining_nodes)\n",
    "\n",
    "\t\treturn remaining_nodes\n",
    "\n",
    "\tdef get_empty_positions_with_target(self, ref_node, n=1):\n",
    "\t\tpositions = []\n",
    "\t\ttarget_p = self.env.target_graph.x[ref_node, Indices.COORD]\n",
    "\t\tif not self.env.is_coor_occupied(target_p, ref_node):\n",
    "\t\t\tpositions.append(flatten_pos(target_p, self.env.grid_size))\n",
    "\t\telse:\n",
    "\t\t\tif n == 0:\n",
    "\t\t\t\treturn positions\n",
    "\t\t\tall_positions = get_all_positions_in_env(self.env.grid_size, self.env.get_obj_size(ref_node))\n",
    "\t\t\t# all_positions = sorted(all_positions, key=lambda x: score(self.env, torch.tensor(x), ref_node))\n",
    "\t\t\trandom.shuffle(all_positions)\n",
    "\t\t\t\n",
    "\t\t\tfor position in all_positions:\n",
    "\t\t\t\tposition = torch.tensor(position)\n",
    "\t\t\t\tif not torch.equal(position, target_p) and not self.env.is_coor_occupied(position, ref_node):\n",
    "\t\t\t\t\tpositions.append(flatten_pos(position, self.env.grid_size))\n",
    "\t\t\t\t\tif len(positions) >= n:\n",
    "\t\t\t\t\t\tbreak\n",
    "\t\treturn positions\n",
    "\n",
    "\tdef get_valid_actions(self, state):\n",
    "\t\tself.env.set_state(state)\n",
    "\n",
    "\t\tstack_nums = max(int(0.6 * self.num_buffers), 1)\n",
    "\n",
    "\t\tnodes = list(range(self.env.num_nodes))\n",
    "\t\trandom.shuffle(nodes)\n",
    "\n",
    "\t\tvalid_actions = []\n",
    "\t\tfor k in self.get_remaining_nodes(state):\n",
    "\t\t\tvalid_stacks = []\n",
    "\t\t\tfor j in nodes:\n",
    "\t\t\t\tif k != j and not is_edge_in_graph(self.env.state_graph, k, j):\n",
    "\t\t\t\t\tif is_stable(self.env.state_graph.x, k, j):\n",
    "\t\t\t\t\t\tif is_empty_object(self.env.state_graph, j):\n",
    "\t\t\t\t\t\t\tvalid_stacks.append(self.env.encode_action('on', k, j, 0))\n",
    "\t\t\t\t\t\t\tif len(valid_stacks) >= stack_nums:\n",
    "\t\t\t\t\t\t\t\tbreak\n",
    "\n",
    "\t\t\tvalid_moves = []\n",
    "\t\t\tfor position in self.get_empty_positions_with_target(ref_node=k, n=self.num_buffers-len(valid_stacks)):\n",
    "\t\t\t\tvalid_moves.append(self.env.encode_action('move', k, k, position))\n",
    "\n",
    "\t\t\tvalid_actions += valid_stacks + valid_moves\n",
    "\n",
    "\t\treturn valid_actions\n",
    "\n",
    "\tdef select(self, node):\n",
    "\t\t# Accesses child nodes for best selection\n",
    "\t\treturn min(node.children.values(), key=lambda child: child.uct())\n",
    "\n",
    "\tdef expand(self, node):\n",
    "\t\tif node.is_fully_expanded():\n",
    "\t\t\treturn None  # Prevents further expansion if no actions remain\n",
    "\n",
    "\t\taction = node.unexpanded_actions.pop()\n",
    "\t\tself.env.set_state(node.get_state())\n",
    "\t\taction_type, start_node, target_node, coordinates = self.env.decode_action(action)\n",
    "\n",
    "\t\t# Continue expanding if the last changed node is the same as the current node\n",
    "\t\tif node.action is not None:\n",
    "\t\t\t_, last_changed_node, _, _ = self.env.decode_action(node.action)\n",
    "\t\t\tif last_changed_node == start_node:\n",
    "\t\t\t\treturn self.expand(node)\n",
    "\n",
    "\t\tcost, child_state = self.env._step_cost(action_type, start_node, target_node, coordinates)\n",
    "\n",
    "\t\t# Continue expanding if the state hasn't changed\n",
    "\t\tif torch.equal(child_state['graph'].x, node.state['graph'].x):\n",
    "\t\t\treturn self.expand(node)\n",
    "\n",
    "\t\tnew_c_cost = cost + node.c_cost\n",
    "\t\tchild_node = self.node_class(child_state, self.get_valid_actions(self.env.get_state()), node, action, new_c_cost, node.c, node.depth+1)\n",
    "\t\tnode.children[action] = child_node\n",
    "\t\treturn child_node\n",
    "\n",
    "\tdef rollout(self, state):\n",
    "\t\tself.env.set_state(state)\n",
    "\t\tcosts = 0\n",
    "\t\tfeasible_path, steps = LabbeS(self.env).solve(verbose=0)\n",
    "\t\tself.env.set_state(state)\n",
    "\t\tfor action in feasible_path:\n",
    "\t\t\tcosts += self.env.step_cost(action)[0]\n",
    "\n",
    "\t\treturn costs, steps\n",
    "\n",
    "\tdef rollout_live(self, node):\n",
    "\t\tcosts = 0\n",
    "\t\tself.env.set_state(node.get_state())\n",
    "\t\tfeasible_path, steps = LabbeS(self.env).solve(verbose=0)\n",
    "\t\tself.env.set_state(node.get_state())\n",
    "\t\tfor action in feasible_path:\n",
    "\t\t\tcost, child_state = self.env.step_cost(action)\n",
    "\t\t\tcosts += cost\n",
    "\t\t\t# remove action from the node's unexpanded actions\n",
    "\t\t\tif action in node.unexpanded_actions:\n",
    "\t\t\t\tnode.unexpanded_actions.remove(action)\n",
    "\t\t\t# add the new child to the node\n",
    "\t\t\tnew_c_cost = cost + node.c_cost\n",
    "\t\t\tchild_node = self.node_class(child_state, self.get_valid_actions(self.env.get_state()), node, action, new_c_cost, node.c, node.depth+1)\n",
    "\t\t\tnode.children[action] = child_node\n",
    "\t\t\tnode = child_node\n",
    "\n",
    "\t\treturn costs, steps, node\n",
    "\n",
    "\tdef backup_search(self, node, c_min):\n",
    "\t\twhile node is not None:\n",
    "\t\t\tnode.visit_count += 1\n",
    "\t\t\tif node.value > c_min:\n",
    "\t\t\t\tnode.value = c_min\n",
    "\t\t\tif node.value_upper < c_min:\n",
    "\t\t\t\tnode.value_upper = c_min\n",
    "\t\t\tnode = node.parent\n",
    "\n",
    "\tdef print_tree(self, node, depth=0, max_depth=float('inf'), ter=False):\n",
    "\t\tif depth >= max_depth:\n",
    "\t\t\treturn\n",
    "\n",
    "\t\t# Print the current node with indentation to show its depth in the tree\n",
    "\t\tindent = \"    \" * depth  # Four spaces per level of depth\n",
    "\t\tif node.id == 0:\n",
    "\t\t\tprint(f\"Root | Visits: {node.visit_count} | Value: {node.value:.2f}\")\n",
    "\t\telse:\n",
    "\t\t\tprint(f\"{indent}Node ID: {node.id} | Action: {node.action} | cost: {node.c_cost:.2f} | \"\n",
    "\t\t\t\t\tf\"Visits: {node.visit_count} | Value: {node.value:.2f}\")\n",
    "\n",
    "\t\t# Sort children by value estimate\n",
    "\t\tif ter:\n",
    "\t\t\taccepted_children = [child for child in node.children.values()]\n",
    "\t\t\tchildren = sorted(accepted_children, key=lambda child: child.value)\n",
    "\t\telse:\n",
    "\t\t\tchildren = sorted(node.children.values(), key=lambda child: child.value)\n",
    "\n",
    "\t\t# Recurse on children\n",
    "\t\tfor child in children:\n",
    "\t\t\tself.print_tree(child, depth + 1, max_depth, ter)\n",
    "\n",
    "\tdef find_best_path(self, ter=False):\n",
    "\t\tpath = []\n",
    "\t\tcurrent_node = self.root_node\n",
    "\t\tself.env.set_state(current_node.get_state())\n",
    "\n",
    "\t\twhile current_node.children:\n",
    "\t\t\tnext_node = min(current_node.children.values(), key=lambda child: child.value)\n",
    "\t\t\tpath.append(next_node.action)\n",
    "\t\t\tcurrent_node = next_node\n",
    "\t\t\tself.env.step_cost(next_node.action)\n",
    "\n",
    "\t\tif ter and not self.env.is_terminal_state():\n",
    "\t\t\tprint('Path isn\\'t completed in the iteration')\n",
    "\t\t\tprint(f'path continues from {path}')\n",
    "\t\t\tfeasible_path = LabbeS(self.env).solve(c=1, verbose=0)[0]\n",
    "\t\t\tself.env.set_state(current_node.get_state())\n",
    "\t\t\tfor action in feasible_path:\n",
    "\t\t\t\tpath.append(action)\n",
    "\t\t\tprint(f'new path: {path}')\n",
    "\t\treturn path\n",
    "\n",
    "\tdef loop(self, max_depth):\n",
    "\t\tnode = self.root_node\n",
    "\n",
    "\t\t# Selection\n",
    "\t\tself.env.set_state(node.get_state())\n",
    "\t\twhile node.is_fully_expanded() and not self.env.is_terminal_state():\n",
    "\t\t\tnode = self.select(node)\n",
    "\t\t\tself.env.set_state(node.get_state())\n",
    "\t\t\n",
    "\t\t# Expansion\n",
    "\t\tif not self.env.is_terminal_state():\n",
    "\t\t\tnode = self.expand(node)\n",
    "\t\t\tif node is None:\n",
    "\t\t\t\treturn 0\n",
    "\n",
    "\t\t# Simulation (Rollout)\n",
    "\t\tc_cost = node.c_cost\n",
    "\t\tterminal_cost, steps = 0, 0\n",
    "\t\tif self.env.is_terminal_state():\n",
    "\t\t\tc_rollout = terminal_cost\n",
    "\t\telif node.depth >= max_depth:\n",
    "\t\t\tc_rollout = float('inf')\n",
    "\t\telse:\n",
    "\t\t\tc_rollout, steps, node = self.rollout_live(node)\n",
    "\n",
    "\t\tc_min = c_rollout + c_cost\n",
    "\n",
    "\t\t# Backpropagation\n",
    "\t\tself.backup_search(node, c_min)\n",
    "\n",
    "\t\treturn steps\n",
    "\n",
    "\tdef solve(self, iterations, max_depth=100, verbose=1, c=1, num_buffers=2):\n",
    "\t\tself.num_buffers = num_buffers\n",
    "\t\tself.root_node = self.node_class(self.env.get_state(), self.get_valid_actions(self.env.get_state()), c=c)\n",
    "\t\tlast_value = self.root_node.value\n",
    "\t\t\n",
    "\t\tsteps, iteration = 0, 0\n",
    "\t\tif verbose > 0:\n",
    "\t\t\tpbar = tqdm(total=None, unit='iterations')\n",
    "\t\twhile iteration < iterations:\n",
    "\t\t\titeration += 1\n",
    "\t\t\tsteps += self.loop(max_depth) + 1\n",
    "\t\t\tif verbose > 0:\n",
    "\t\t\t\tpbar.update(1)\n",
    "\t\t\tif iteration != 0 and iteration % 100 == 0:\n",
    "\t\t\t\tif abs(last_value - self.root_node.value) < 0.01:\n",
    "\t\t\t\t\tbreak\n",
    "\t\t\t\t\n",
    "\t\t\t\tlast_value = self.root_node.value\n",
    "\n",
    "\t\tif verbose > 0:\n",
    "\t\t\tpbar.close()\n",
    "\n",
    "\t\treturn self.find_best_path(ter=True), steps\n",
    "\n",
    "class MctsNode2:\n",
    "\tnode_counter = 0  # Static variable to assign unique IDs to each node\n",
    "\n",
    "\tdef __init__(self, state, valid_actions, parent=None, action=None, cost=0.0, cost_to_come=0.0, c=1, depth=0):\n",
    "\t\tself.state = state\n",
    "\t\tself.parent = parent\n",
    "\t\tself.action = action\n",
    "\t\tself.children = {}\n",
    "\t\tself.visit_count = 0\n",
    "\t\tself.value = 0\n",
    "\t\tself.cost = cost\n",
    "\t\tself.cost_to_come = cost_to_come\n",
    "\t\tself.c = c\n",
    "\t\tself.unexpanded_actions = valid_actions\n",
    "\t\tself.depth = depth\n",
    "\t\t\n",
    "\t\t# Assign a unique ID to each node\n",
    "\t\tself.id = MctsNode2.node_counter\n",
    "\t\tMctsNode2.node_counter += 1\n",
    "\n",
    "\tdef get_state(self):\n",
    "\t\treturn copy_state(self.state)\n",
    "\n",
    "\tdef is_fully_expanded(self):\n",
    "\t\treturn len(self.unexpanded_actions) == 0\n",
    "\n",
    "\tdef uct(self, c_min=0, c_max=1):\n",
    "\t\tvisit_count = self.visit_count + 1\n",
    "\n",
    "\t\ttotal_cost_estimate = ( (self.cost_to_come + self.value / visit_count) - c_min ) / (c_max - c_min)\n",
    "\t\texploration_term = self.c * np.sqrt(2 * np.log(self.parent.visit_count) / visit_count)\n",
    "\n",
    "\t\treturn total_cost_estimate - exploration_term  # Minimization form\n",
    "\n",
    "class Sorp2(Sorp):\n",
    "\tdef __init__(self, env):\n",
    "\t\tsuper().__init__(env, MctsNode2)\n",
    "\t\tself.num_buffers = 2\n",
    "\n",
    "\tdef get_empty_positions_with_target(self, ref_node, n=1):\n",
    "\t\tpositions = []\n",
    "\t\ttarget_p = self.env.target_graph.x[ref_node, Indices.COORD]\n",
    "\t\tif not self.env.is_coor_occupied(target_p, ref_node):\n",
    "\t\t\tpositions.append(flatten_pos(target_p, self.env.grid_size))\n",
    "\t\telse:\n",
    "\t\t\tif n == 0:\n",
    "\t\t\t\treturn positions\n",
    "\t\t\tall_positions = get_all_positions_in_env(self.env.grid_size, self.env.get_obj_size(ref_node))\n",
    "\t\t\t# all_positions = sorted(all_positions, key=lambda x: score(self.env, torch.tensor(x), ref_node))\n",
    "\t\t\trandom.shuffle(all_positions)\n",
    "\t\t\t\n",
    "\t\t\tfor position in all_positions:\n",
    "\t\t\t\tposition = torch.tensor(position)\n",
    "\t\t\t\tif not torch.equal(position, target_p) and not self.env.is_coor_occupied(position, ref_node):\n",
    "\t\t\t\t\tpositions.append(flatten_pos(position, self.env.grid_size))\n",
    "\t\t\t\t\tif len(positions) >= n:\n",
    "\t\t\t\t\t\tbreak\n",
    "\t\treturn positions\n",
    "\n",
    "\tdef select(self, node):\n",
    "\t\t# Accesses child nodes for best selection\n",
    "\t\tif self.c_min == np.inf or self.c_max == self.c_min:\n",
    "\t\t\treturn min(node.children.values(), key=lambda child: child.uct())\n",
    "\t\telse:\n",
    "\t\t\treturn min(node.children.values(), key=lambda child: child.uct(self.c_min, self.c_max))\n",
    "\n",
    "\tdef expand(self, node):\n",
    "\t\tif node.is_fully_expanded():\n",
    "\t\t\treturn None  # Prevents further expansion if no actions remain\n",
    "\n",
    "\t\taction = node.unexpanded_actions.pop()\n",
    "\t\tself.env.set_state(node.get_state())\n",
    "\t\taction_type, start_node, target_node, coordinates = self.env.decode_action(action)\n",
    "\n",
    "\t\t# Continue expanding if the last changed node is the same as the current node\n",
    "\t\tif node.action is not None:\n",
    "\t\t\t_, last_changed_node, _, _ = self.env.decode_action(node.action)\n",
    "\t\t\tif last_changed_node == start_node:\n",
    "\t\t\t\treturn self.expand(node)\n",
    "\n",
    "\t\tcost, child_state = self.env._step_cost(action_type, start_node, target_node, coordinates)\n",
    "\n",
    "\t\t# Continue expanding if the state hasn't changed\n",
    "\t\tif torch.equal(child_state['graph'].x, node.state['graph'].x):\n",
    "\t\t\treturn self.expand(node)\n",
    "\n",
    "\t\tchild_node = self.node_class(\n",
    "\t\t\tstate=child_state, \n",
    "\t\t\tvalid_actions=self.get_valid_actions(self.env.get_state()), \n",
    "\t\t\tparent=node, \n",
    "\t\t\taction=action, \n",
    "\t\t\tcost=cost.item(), \n",
    "\t\t\tcost_to_come=node.cost_to_come+cost.item(),\n",
    "\t\t\tc=node.c, \n",
    "\t\t\tdepth=node.depth+1\n",
    "\t\t)\n",
    "\t\tnode.children[action] = child_node\n",
    "\n",
    "\t\treturn child_node\n",
    "\n",
    "\tdef rollout(self, node):\n",
    "\t\tc_rollout = 0\n",
    "\t\tself.env.set_state(node.get_state())\n",
    "\t\tfeasible_path, steps = LabbeS(self.env).solve(verbose=0)\n",
    "\t\tself.env.set_state(node.get_state())\n",
    "\t\tfor i, action in enumerate(feasible_path):\n",
    "\t\t\tcost, child_state = self.env.step_cost(action)\n",
    "\t\t\tc_rollout += cost.item()\n",
    "\t\t\tif i == 0:\n",
    "\t\t\t\t# remove action from the node's unexpanded actions\n",
    "\t\t\t\tif action in node.unexpanded_actions:\n",
    "\t\t\t\t\tnode.unexpanded_actions.remove(action)\n",
    "\t\t\t\t# add the new child to the node\n",
    "\t\t\t\tchild_node = self.node_class(\n",
    "\t\t\t\t\tstate=child_state, \n",
    "\t\t\t\t\tvalid_actions=self.get_valid_actions(self.env.get_state()), \n",
    "\t\t\t\t\tparent=node, \n",
    "\t\t\t\t\taction=action, \n",
    "\t\t\t\t\tcost=cost.item(), \n",
    "\t\t\t\t\tcost_to_come=node.cost_to_come+cost.item(),\n",
    "\t\t\t\t\tc=node.c, \n",
    "\t\t\t\t\tdepth=node.depth+1\n",
    "\t\t\t\t)\n",
    "\t\t\t\tnode.children[action] = child_node\n",
    "\n",
    "\t\treturn c_rollout, steps, feasible_path, child_node\n",
    "\n",
    "\tdef backup_search(self, node, value):\n",
    "\t\twhile node is not None:\n",
    "\t\t\tnode.visit_count += 1\n",
    "\t\t\tnode.value += value\n",
    "\t\t\tnode = node.parent\n",
    "\n",
    "\tdef print_tree(self, node, depth=0, max_depth=float('inf'), ter=False):\n",
    "\t\tif depth >= max_depth:\n",
    "\t\t\treturn\n",
    "\n",
    "\t\t# Print the current node with indentation to show its depth in the tree\n",
    "\t\tindent = \"    \" * depth  # Four spaces per level of depth\n",
    "\t\tif node.id == 0:\n",
    "\t\t\tprint(f\"Root | Visits: {node.visit_count} | Value: {node.value:.2f}\")\n",
    "\t\telse:\n",
    "\t\t\tprint(f\"{indent}Node ID: {node.id} | Action: {node.action} | CtC: {node.cost_to_come:.2f} | \"\n",
    "\t\t\t\t\tf\"Visits: {node.visit_count} | Value: {node.value:.2f}\")\n",
    "\n",
    "\t\t# Sort children by value estimate\n",
    "\t\tif ter:\n",
    "\t\t\taccepted_children = [child for child in node.children.values()]\n",
    "\t\t\tchildren = sorted(accepted_children, key=lambda child: child.value)\n",
    "\t\telse:\n",
    "\t\t\tchildren = sorted(node.children.values(), key=lambda child: child.value)\n",
    "\n",
    "\t\t# Recurse on children\n",
    "\t\tfor child in children:\n",
    "\t\t\tself.print_tree(child, depth + 1, max_depth, ter)\n",
    "\n",
    "\tdef find_best_path(self, ter=False):\n",
    "\t\treturn reconstruct_path(self.best_plan[0])+self.best_plan[1]\n",
    "\n",
    "\tdef loop(self, max_depth):\n",
    "\t\tnode = self.root_node\n",
    "\n",
    "\t\t# Selection\n",
    "\t\tself.env.set_state(node.get_state())\n",
    "\t\twhile node.is_fully_expanded() and not self.env.is_terminal_state():\n",
    "\t\t\tnode = self.select(node)\n",
    "\t\t\tself.env.set_state(node.get_state())\n",
    "\t\t\n",
    "\t\t# Expansion\n",
    "\t\tif not self.env.is_terminal_state():\n",
    "\t\t\tnode = self.expand(node)\n",
    "\t\t\tif node is None:\n",
    "\t\t\t\treturn 0\n",
    "\n",
    "\t\t# Simulation (Rollout)\n",
    "\t\tfeasible_plan = []\n",
    "\t\tsteps = 0\n",
    "\t\tif self.env.is_terminal_state():\n",
    "\t\t\tvalue = 0\n",
    "\t\telse:\n",
    "\t\t\tc_rollout, steps, feasible_plan, child_node = self.rollout(node)\n",
    "\n",
    "\t\t\tnew_cost = c_rollout + node.cost_to_come\n",
    "\t\t\tself.c_max = max(self.c_max, new_cost)\n",
    "\t\t\tif new_cost < self.c_min:\n",
    "\t\t\t\tself.best_plan = (node, feasible_plan)\n",
    "\t\t\t\tself.c_min = new_cost\n",
    "\n",
    "\t\t\tnode = child_node\n",
    "\t\t\tvalue = c_rollout - node.cost\n",
    "\n",
    "\t\t# Backpropagation\n",
    "\t\tself.backup_search(node, value)\n",
    "\n",
    "\t\treturn steps\n",
    "\n",
    "\tdef solve(self, iterations, max_depth=100, verbose=1, c=1, num_buffers=2):\n",
    "\t\tself.num_buffers = num_buffers\n",
    "\t\tself.root_node = self.node_class(\n",
    "\t\t\tstate=self.env.get_state(), \n",
    "\t\t\tvalid_actions=self.get_valid_actions(self.env.get_state()), \n",
    "\t\t\tc=c\n",
    "\t\t)\n",
    "\t\tself.c_max = -np.inf\n",
    "\t\tself.c_min = np.inf\n",
    "\t\tself.best_plan = None\n",
    "\n",
    "\t\twindow_last_values = []\n",
    "\t\twindow_last_values.append(self.root_node.value)\n",
    "\t\t\n",
    "\t\tsteps, iteration = 0, 0\n",
    "\t\tif verbose > 0:\n",
    "\t\t\tpbar = tqdm(total=None, unit='iterations')\n",
    "\t\twhile iteration < iterations:\n",
    "\t\t\titeration += 1\n",
    "\t\t\tsteps += self.loop(max_depth) + 1\n",
    "\t\t\tif verbose > 0:\n",
    "\t\t\t\tpbar.update(1)\n",
    "\t\t\tif iteration != 0 and iteration % 20 == 0:\n",
    "\t\t\t\tif self.c_max == self.c_min:\n",
    "\t\t\t\t\tshit_value = np.inf\n",
    "\t\t\t\telse:\n",
    "\t\t\t\t\tshit_value = ((self.root_node.value / self.root_node.visit_count) - self.c_min) / (self.c_max - self.c_min)\n",
    "\t\t\t\t# print(f'v_shit: {shit_value:.3f} | c_min: {self.c_min:.3f} | c_max: {self.c_max:.3f}')\n",
    "\t\t\t\twindow_last_values.append(self.c_min)\n",
    "\t\t\t\tif len(window_last_values) > 5:\n",
    "\t\t\t\t\twindow_last_values.pop(0)\n",
    "\t\t\t\t\tif len(set(window_last_values)) == 1:\n",
    "\t\t\t\t\t\tbreak\n",
    "\n",
    "\t\tif verbose > 0:\n",
    "\t\t\tpbar.close()\n",
    "\n",
    "\t\treturn self.find_best_path(ter=True), steps\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def refine_until_convergence(env, plan, initial_graph, target_graph, alg, verbose=0):\n",
    "\tstart_time = time.time()\n",
    "\tbest_cost = env_cost(env, plan, initial_graph, target_graph, log=False)\n",
    "\twhile True:\n",
    "\t\t# print('-------------------------')\n",
    "\t\tif alg == 'Strap' or alg == 'Labbe':\n",
    "\t\t\trefined_plan = plan_refinement(env, plan, initial_graph, target_graph, verbose=verbose)\n",
    "\t\telif alg == 'Sorp' or alg == 'Sorp2' or alg == 'A_star' or alg == 'LabbeS':\n",
    "\t\t\trefined_plan = plan_refinement_stack(env, plan, initial_graph, target_graph, verbose=verbose)\n",
    "\t\telse:\n",
    "\t\t\traise ValueError('Invalid algorithm')\n",
    "\n",
    "\t\tif plan == refined_plan:\n",
    "\t\t\tbreak\n",
    "\n",
    "\t\tcost = env_cost(env, refined_plan, initial_graph, target_graph, log=False)\n",
    "\t\tif cost < best_cost:\n",
    "\t\t\tif verbose > 0:\n",
    "\t\t\t\tprint(f'cost get better from {best_cost:.3f} to {cost:.3f}')\n",
    "\t\t\tbest_cost = cost\n",
    "\n",
    "\t\tplan = refined_plan\n",
    "\n",
    "\tend_time = time.time()\n",
    "\treturn plan, best_cost, end_time - start_time\n",
    "\n",
    "def plan_refinement_stack(env, plan, initial_graph, target_graph, verbose=0):\n",
    "\tpre_costs = 0\n",
    "\taction_sequence = []\n",
    "\tenv.reset(initial_graph, target_graph)\n",
    "\tfor action in plan:\n",
    "\t\ta_type, k, l, coordinates = env.decode_action(action)\n",
    "\t\tp_pick = env.state_graph.x[k, Indices.COORD].clone()\n",
    "\t\tif a_type == 'move':\n",
    "\t\t\tp_place = unflatten_pos(coordinates, env.grid_size)\n",
    "\t\telif a_type == 'on':\n",
    "\t\t\tp_place = env.state_graph.x[l, Indices.COORD].clone()\n",
    "\t\telse:\n",
    "\t\t\traise ValueError('Invalid action type')\n",
    "\n",
    "\t\taction_sequence.append({\n",
    "\t\t\t'type': a_type,\n",
    "\t\t\t'k': k,\n",
    "\t\t\t'l': l,\n",
    "\t\t\t'p_pick': p_pick,\n",
    "\t\t\t'p_place': p_place\n",
    "\t\t})\n",
    "\t\tpre_costs += env.step_cost(action)[0]\n",
    "\n",
    "\tenv.reset(initial_graph, target_graph)\n",
    "\tB = {}\n",
    "\tH = {0: (env.get_state(), env.table)} # arrangement history\n",
    "\tfor i in range(len(action_sequence)):\n",
    "\t\tk = action_sequence[i]['k']\n",
    "\n",
    "\t\tif k in B:\t# if object k was moved\n",
    "\t\t\tbIdx = B[k]\t# previous action index on k\n",
    "\n",
    "\t\t\t# Find constraints\n",
    "\t\t\tC = []\n",
    "\n",
    "\t\t\t# Occupied possitions in the action index bIdx\n",
    "\t\t\tfor j in range(env.grid_size * env.grid_size):\n",
    "\t\t\t\tposition = unflatten_pos(j, env.grid_size)\n",
    "\t\t\t\tif env.is_coor_occupied(position, k, H[bIdx][1]):\n",
    "\t\t\t\t\tC.append(position)\n",
    "\n",
    "\t\t\t# Ocuupied buffers in the action index bIdx to i-1\n",
    "\t\t\tsize_k = env.get_obj_size(k)\n",
    "\t\t\tfor j in range(bIdx, i):\n",
    "\t\t\t\tif action_sequence[j]['type'] == 'on':\n",
    "\t\t\t\t\t# if the action is stack, continue\n",
    "\t\t\t\t\tcontinue\n",
    "\t\t\t\t\n",
    "\t\t\t\tsize = env.get_obj_size(action_sequence[j]['k'])\n",
    "\t\t\t\tsize = (size[0]+size_k[0]-1, size[1]+size_k[1]-1)\n",
    "\t\t\t\tidx = in_table_index(action_sequence[j]['p_place'], size)\n",
    "\t\t\t\tfor position in itertools.product(range(idx[0].start, idx[0].stop), range(idx[1].start, idx[1].stop)):\n",
    "\t\t\t\t\tposition = torch.tensor(position, dtype=torch.float32)\n",
    "\t\t\t\t\tC.append(position)\n",
    "\n",
    "\t\t\tempty_objs = []\n",
    "\t\t\tfor obj in range(env.num_nodes):\n",
    "\t\t\t\tif is_stable(H[0][0]['graph'].x, k, obj):\n",
    "\t\t\t\t\tis_empty = True\n",
    "\t\t\t\t\tfor j in range(bIdx, i):\n",
    "\t\t\t\t\t\tif not is_empty_object(H[j][0]['graph'], obj):\n",
    "\t\t\t\t\t\t\tis_empty = False\n",
    "\t\t\t\t\t\t\tbreak\n",
    "\t\t\t\t\tif is_empty:\n",
    "\t\t\t\t\t\tempty_objs.append(obj)\n",
    "\n",
    "\t\t\tp1 = action_sequence[bIdx]['p_pick']\n",
    "\t\t\tp2 = action_sequence[i-1]['p_place']\n",
    "\t\t\tp3 = action_sequence[bIdx+1]['p_pick']\n",
    "\t\t\tp4 = action_sequence[i]['p_place']\n",
    "\n",
    "\t\t\t# Generate a buffer set under constraint C\n",
    "\t\t\tP = []\n",
    "\t\t\tfor j in range(env.grid_size * env.grid_size):\n",
    "\t\t\t\tp = unflatten_pos(j, env.grid_size)\n",
    "\t\t\t\tif not any(torch.equal(p, c) for c in C):\n",
    "\t\t\t\t\tP.append(p)\n",
    "\t\t\tif len(P) == 0:\n",
    "\t\t\t\tif verbose > 0:\n",
    "\t\t\t\t\tprint(f'No feasible buffer set')\n",
    "\t\t\t\n",
    "\t\t\t# Find the best buffer\n",
    "\t\t\tif action_sequence[bIdx]['type'] == 'on':\n",
    "\t\t\t\tp_to_buff = action_sequence[bIdx]['p_place']\n",
    "\t\t\t\tcontainer = find_base_node(H[i][0]['graph'], k)\n",
    "\t\t\t\tp_i = H[i][0]['graph'].x[container, Indices.COORD].clone()\n",
    "\t\t\t\tmin_cost = torch.norm(p1 - p_to_buff) + torch.norm(p2 - p_i) + torch.norm(p3 - p_to_buff) + torch.norm(p4 - p_i)\n",
    "\t\t\telse:\n",
    "\t\t\t\tp = action_sequence[bIdx]['p_place'].clone()\n",
    "\t\t\t\tmin_cost = torch.norm(p1 - p) + torch.norm(p2 - p) + torch.norm(p3 - p) + torch.norm(p4 - p)\n",
    "\n",
    "\t\t\tbest_p = None\n",
    "\t\t\tfor p in P:\n",
    "\t\t\t\tcost = torch.norm(p1 - p) + torch.norm(p2 - p) + torch.norm(p3 - p) + torch.norm(p4 - p)\n",
    "\t\t\t\tif cost < min_cost:\n",
    "\t\t\t\t\tbest_p = p.clone()\n",
    "\t\t\t\t\tmin_cost = cost\n",
    "\n",
    "\t\t\tbest_obj = None\n",
    "\t\t\tfor empty_obj in empty_objs:\n",
    "\t\t\t\tp_to_buff = H[bIdx][0]['graph'].x[empty_obj, Indices.COORD].clone()\n",
    "\t\t\t\tp_i = H[i][0]['graph'].x[empty_obj, Indices.COORD].clone()\n",
    "\t\t\t\tcost = torch.norm(p1 - p_to_buff) + torch.norm(p2 - p_i) + torch.norm(p3 - p_to_buff) + torch.norm(p4 - p_i)\n",
    "\t\t\t\tif cost < min_cost:\n",
    "\t\t\t\t\tmin_cost = cost\n",
    "\t\t\t\t\tbest_obj = empty_obj\n",
    "\n",
    "\t\t\tif best_obj is not None:\n",
    "\t\t\t\tif verbose > 0:\n",
    "\t\t\t\t\tif action_sequence[bIdx]['type'] == 'on':\n",
    "\t\t\t\t\t\tlast_obj = action_sequence[bIdx]['l']\n",
    "\t\t\t\t\t\tprint(f'Buffer of object {k} changed from obj {last_obj} to obj {best_obj}')\n",
    "\t\t\t\t\telse:\n",
    "\t\t\t\t\t\tlast_pos = action_sequence[bIdx]['p_place']\n",
    "\t\t\t\t\t\tprint(f'Buffer of object {k} changed from pos {last_pos} to obj {best_obj}')\n",
    "\n",
    "\t\t\t\taction_sequence[bIdx] = {\n",
    "\t\t\t\t\t'type': 'on',\n",
    "\t\t\t\t\t'k': k,\n",
    "\t\t\t\t\t'l': best_obj,\n",
    "\t\t\t\t\t'p_pick': action_sequence[bIdx]['p_pick'].clone(),\n",
    "\t\t\t\t\t'p_place': H[bIdx][0]['graph'].x[best_obj, Indices.COORD].clone()\n",
    "\t\t\t\t}\n",
    "\t\t\t\taction_sequence[i] = {\n",
    "\t\t\t\t\t'type': 'move',\n",
    "\t\t\t\t\t'k': k,\n",
    "\t\t\t\t\t'l': k,\n",
    "\t\t\t\t\t'p_pick': H[i][0]['graph'].x[best_obj, Indices.COORD].clone(),\n",
    "\t\t\t\t\t'p_place': action_sequence[i]['p_place'].clone()\n",
    "\t\t\t\t}\n",
    "\t\t\t\tbreak\n",
    "\t\t\telif best_p is not None:\n",
    "\t\t\t\tif verbose > 0:\n",
    "\t\t\t\t\tif action_sequence[bIdx]['type'] == 'on':\n",
    "\t\t\t\t\t\tlast_obj = action_sequence[bIdx]['l']\n",
    "\t\t\t\t\t\tprint(f'Buffer of object {k} changed from obj {last_obj} to pos {best_p}')\n",
    "\t\t\t\t\telse:\n",
    "\t\t\t\t\t\tlast_pos = action_sequence[bIdx]['p_place']\n",
    "\t\t\t\t\t\tprint(f'Buffer of object {k} changed from pos {last_pos} to pos {best_p}')\n",
    "\n",
    "\t\t\t\taction_sequence[bIdx] = {\n",
    "\t\t\t\t\t'type': 'move',\n",
    "\t\t\t\t\t'k': k,\n",
    "\t\t\t\t\t'l': k,\n",
    "\t\t\t\t\t'p_pick': action_sequence[bIdx]['p_pick'].clone(),\n",
    "\t\t\t\t\t'p_place': best_p\n",
    "\t\t\t\t}\n",
    "\t\t\t\taction_sequence[i] = {\n",
    "\t\t\t\t\t'type': 'move',\n",
    "\t\t\t\t\t'k': k,\n",
    "\t\t\t\t\t'l': k,\n",
    "\t\t\t\t\t'p_pick': best_p,\n",
    "\t\t\t\t\t'p_place': action_sequence[i]['p_place'].clone()\n",
    "\t\t\t\t}\n",
    "\t\t\t\tbreak\n",
    "\n",
    "\t\tenv.step_cost(plan[i])\n",
    "\t\tH[i+1] = (env.get_state(), env.table)\n",
    "\t\tB[k] = i\n",
    "\n",
    "\trefined_actions = []\n",
    "\tfor action in action_sequence:\n",
    "\t\tif action['type'] == 'on':\n",
    "\t\t\trefined_actions.append(env.encode_action('on', action['k'], action['l'], 0))\n",
    "\t\telse:\n",
    "\t\t\trefined_actions.append(env.encode_action('move', action['k'], action['k'], action['p_place']))\n",
    "\n",
    "\treturn refined_actions\n",
    "\n",
    "def plan_refinement(env, plan, initial_graph, target_graph, verbose=0):\n",
    "\tpre_costs = 0\n",
    "\taction_sequence = []\n",
    "\tenv.reset(initial_graph, target_graph)\n",
    "\tfor action in plan:\n",
    "\t\taction_type, k, _, coordinates = env.decode_action(action)\n",
    "\t\tif action_type == 'on':\n",
    "\t\t\treturn plan\n",
    "\t\tp_pick = env.state_graph.x[k, Indices.COORD].clone()\n",
    "\t\tp_place = unflatten_pos(coordinates, env.grid_size)\n",
    "\t\t\n",
    "\t\taction_sequence.append({\n",
    "\t\t\t'k': k,\n",
    "\t\t\t'p_pick': p_pick,\n",
    "\t\t\t'p_place': p_place\n",
    "\t\t})\n",
    "\t\tpre_costs += env.step_cost(action)[0]\n",
    "\n",
    "\tenv.reset(initial_graph, target_graph)\n",
    "\tB = {}\n",
    "\tH = {0: (env.get_state(), env.table)} # arrangement history\n",
    "\tfor i in range(len(action_sequence)):\n",
    "\t\tk = action_sequence[i]['k']\n",
    "\n",
    "\t\tif k in B:\t# if object k was moved\n",
    "\t\t\tbIdx = B[k]\t# previous action index on k\n",
    "\n",
    "\t\t\t# Find constraints\n",
    "\t\t\tC = []\n",
    "\n",
    "\t\t\t# Occupied possitions in the action index bIdx\n",
    "\t\t\tfor j in range(env.grid_size * env.grid_size):\n",
    "\t\t\t\tposition = unflatten_pos(j, env.grid_size)\n",
    "\t\t\t\tif env.is_coor_occupied(position, k, H[bIdx][1]):\n",
    "\t\t\t\t\tC.append(position)\n",
    "\n",
    "\t\t\t# Ocuupied buffers in the action index bIdx to i-1\n",
    "\t\t\tsize_k = env.get_obj_size(k)\n",
    "\t\t\tfor j in range(bIdx, i):\n",
    "\t\t\t\tsize = env.get_obj_size(action_sequence[j]['k'])\n",
    "\t\t\t\tsize = (size[0]+size_k[0]-1, size[1]+size_k[1]-1)\n",
    "\t\t\t\tidx = in_table_index(action_sequence[j]['p_place'], size)\n",
    "\t\t\t\tfor position in itertools.product(range(idx[0].start, idx[0].stop), range(idx[1].start, idx[1].stop)):\n",
    "\t\t\t\t\tposition = torch.tensor(position, dtype=torch.float32)\n",
    "\t\t\t\t\tC.append(position)\n",
    "\n",
    "\t\t\tp1 = action_sequence[bIdx]['p_pick']\n",
    "\t\t\tp2 = action_sequence[i-1]['p_place']\n",
    "\t\t\tp3 = action_sequence[bIdx+1]['p_pick']\n",
    "\t\t\tp4 = action_sequence[i]['p_place']\n",
    "\n",
    "\t\t\t# Generate a buffer set under constraint C\n",
    "\t\t\tP = []\n",
    "\t\t\tfor j in range(env.grid_size * env.grid_size):\n",
    "\t\t\t\tp = unflatten_pos(j, env.grid_size)\n",
    "\t\t\t\tif not any(torch.equal(p, c) for c in C):\n",
    "\t\t\t\t\tP.append(p)\n",
    "\t\t\tif len(P) == 0:\n",
    "\t\t\t\tif verbose > 0:\n",
    "\t\t\t\t\tprint(f'No feasible buffer set')\n",
    "\t\t\t\n",
    "\t\t\t# Find the best buffer\n",
    "\t\t\tp = action_sequence[bIdx]['p_place'].clone()\n",
    "\t\t\tmin_cost = torch.norm(p1 - p) + torch.norm(p2 - p) + torch.norm(p3 - p) + torch.norm(p4 - p)\n",
    "\n",
    "\t\t\tbest_p = None\n",
    "\t\t\tfor p in P:\n",
    "\t\t\t\tcost = torch.norm(p1 - p) + torch.norm(p2 - p) + torch.norm(p3 - p) + torch.norm(p4 - p)\n",
    "\t\t\t\tif cost < min_cost:\n",
    "\t\t\t\t\tbest_p = p.clone()\n",
    "\t\t\t\t\tmin_cost = cost\n",
    "\n",
    "\t\t\tif best_p is not None:\n",
    "\t\t\t\tif verbose > 0:\n",
    "\t\t\t\t\tlast_pos = action_sequence[bIdx]['p_place']\n",
    "\t\t\t\t\tprint(f'Buffer of object {k} changed from pos {last_pos} to pos {best_p}')\n",
    "\n",
    "\t\t\t\taction_sequence[bIdx] = {\n",
    "\t\t\t\t\t'k': k,\n",
    "\t\t\t\t\t'p_pick': action_sequence[bIdx]['p_pick'].clone(),\n",
    "\t\t\t\t\t'p_place': best_p\n",
    "\t\t\t\t}\n",
    "\t\t\t\taction_sequence[i] = {\n",
    "\t\t\t\t\t'k': k,\n",
    "\t\t\t\t\t'p_pick': best_p,\n",
    "\t\t\t\t\t'p_place': action_sequence[i]['p_place'].clone()\n",
    "\t\t\t\t}\n",
    "\t\t\t\tbreak\n",
    "\n",
    "\t\tenv.step_cost(plan[i])\n",
    "\t\tH[i+1] = (env.get_state(), env.table)\n",
    "\t\tB[k] = i\n",
    "\n",
    "\trefined_actions = []\n",
    "\tfor action in action_sequence:\n",
    "\t\trefined_actions.append(env.encode_action('move', action['k'], action['k'], action['p_place']))\n",
    "\n",
    "\treturn refined_actions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = ContinuousEnv(mode='mobile', num_nodes=4, grid_size=20, verbose=0)\n",
    "env.reset(stack=False, ratio=0.5)\n",
    "# initial_graph, target_graph = copy_graph(env.initial_graph), copy_graph(env.target_graph)\n",
    "# env.reset(initial_graph, target_graph)\n",
    "env.render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimal_actions = evaluate_alg(env, Sorp2, initial_graph, target_graph, iterations=1000, num_buffers=4, c=1, verbose=1);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimal_actions = evaluate_alg(env, Sorp, initial_graph, target_graph, iterations=1000, num_buffers=4, c=1, verbose=1);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimal_actions = evaluate_alg(env, Strap, initial_graph, target_graph, num_buffers=4);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "refine_until_convergence(env, optimal_actions, initial_graph, target_graph, 'Labbe', verbose=1);\n",
    "print('------')\n",
    "refine_until_convergence(env, optimal_actions, initial_graph, target_graph, 'LabbeS', verbose=1);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_runs(mode, phi, env, graphs, alg, file_name, **kwargs):\n",
    "\tfild_dir = f'runs/{mode}/{phi}/g{env.grid_size}/n{env.num_nodes}'\n",
    "\tif not os.path.exists(fild_dir):\n",
    "\t\tos.makedirs(fild_dir)\n",
    "\t\n",
    "\tfile_dir = f'{fild_dir}/{file_name}.pkl'\n",
    "\n",
    "\truns = []\n",
    "\tpbar = tqdm(total=len(graphs), unit='rearrangement')\n",
    "\tfor graph in graphs:\n",
    "\t\tstart = time.time()\n",
    "\t\tenv.reset(state_graph=graph['initial_graph'], target_graph=graph['target_graph'])\n",
    "\t\toptimal_actions, steps = alg(env).solve(**kwargs)\n",
    "\t\telapsed_time = time.time() - start\n",
    "\t\truns.append({\n",
    "\t\t\t'optimal_actions': optimal_actions,\n",
    "\t\t\t'steps': steps,\n",
    "\t\t\t'elapsed_time': elapsed_time\n",
    "\t\t})\n",
    "\t\twith open(file_dir, 'wb') as f:\n",
    "\t\t\tpickle.dump(runs, f)\n",
    "\n",
    "\t\tpbar.update(1)\n",
    "\tpbar.close()\n",
    "\n",
    "def make_graphs(env, num_graphs, stack, ratio=0.5):\n",
    "\tgraphs = []\n",
    "\tfor _ in range(num_graphs):\n",
    "\t\tenv.reset(stack=stack, ratio=ratio)\n",
    "\t\tgraphs.append({\n",
    "\t\t\t'initial_graph': env.initial_graph,\n",
    "\t\t\t'target_graph': env.target_graph\n",
    "\t\t})\n",
    "\treturn graphs\n",
    "\n",
    "def save_graphs(dir, graphs, num_nodes, grid_size):\n",
    "\tif not os.path.exists(f'graphs/{dir}'):\n",
    "\t\tos.makedirs(f'graphs/{dir}')\n",
    "\twith open(f'graphs/{dir}/{num_nodes}n_{grid_size}g.pkl', 'wb') as f:\n",
    "\t\tpickle.dump(graphs, f)\n",
    "\n",
    "def load_graphs(dir, num_nodes, grid_size):\n",
    "\twith open(f'graphs/{dir}/{num_nodes}n_{grid_size}g.pkl', 'rb') as f:\n",
    "\t\tgraphs = pickle.load(f)\n",
    "\treturn graphs\n",
    "\n",
    "def plot_characteristics(ax, runs, key, title=\"\"):\n",
    "\txtics = []\n",
    "\tfor run in runs:\n",
    "\t\tx_axis = range(1, len(run['runs'])+1)\n",
    "\t\ty_axis = [run[key] for run in run['runs']]\n",
    "\t\tax.plot(x_axis, y_axis, label=f\"{run['num_nodes']}n_{run['grid_size']}g\")\n",
    "\t\tif len(xtics) < len(x_axis):\n",
    "\t\t\txtics = x_axis\n",
    "\t\n",
    "\tax.set_xticks(xtics)\n",
    "\tax.set_title(title)\n",
    "\tax.set_xlabel('Samples')\n",
    "\tif key == 'elapsed_time':\n",
    "\t\tax.set_ylabel(f'Time elapsed (s)')\n",
    "\telse:\n",
    "\t\tax.set_ylabel(f'{key}')\n",
    "\tax.legend()\n",
    "\n",
    "def load_runs(mode, phi, algs, n_values, grid_size, refine=False):\n",
    "\truns = {}\n",
    "\tfor num_nodes in n_values:\n",
    "\t\tpath = glob.glob(f'runs/{mode}/{phi}/g{grid_size}/n{num_nodes}/*')\n",
    "\t\truns[num_nodes] = {}\n",
    "\t\tfor file in path:\n",
    "\t\t\twith open(file, 'rb') as f:\n",
    "\t\t\t\tfirst_back_slash = file.rindex('\\\\')\n",
    "\t\t\t\talg_name = f'{file[first_back_slash+1:-4]}'\n",
    "\t\t\t\tif alg_name not in algs:\n",
    "\t\t\t\t\tcontinue\n",
    "\t\t\t\truns[num_nodes][alg_name] = pickle.load(f)\n",
    "\t\t\t\n",
    "\t\t\tgraphs = load_graphs(phi, num_nodes, grid_size)\n",
    "\t\t\tassert len(graphs) == len(runs[num_nodes][alg_name])\n",
    "\n",
    "\t\t\tenv = ContinuousEnv(mode=mode, num_nodes=num_nodes, grid_size=grid_size, verbose=0)\n",
    "\t\t\tfor i, graph in enumerate(graphs):\n",
    "\t\t\t\tenv.reset(graph['initial_graph'], graph['target_graph'])\n",
    "\t\t\t\trun = runs[num_nodes][alg_name][i]\n",
    "\t\t\t\tif refine:\n",
    "\t\t\t\t\t# print(f'------n:{num_nodes} // alg:{alg_name}------')\n",
    "\t\t\t\t\t_, cost, elapsed_time = refine_until_convergence(env, run['optimal_actions'], graph['initial_graph'], graph['target_graph'], alg_name, verbose=0)\n",
    "\t\t\t\t\trun['elapsed_time'] += elapsed_time\n",
    "\t\t\t\t\trun['cost'] = cost\n",
    "\t\t\t\telse:\n",
    "\t\t\t\t\trun['cost'] = env_cost(env, run['optimal_actions'], graph['initial_graph'], graph['target_graph'], log=False).item()\n",
    "\treturn runs\n",
    "\n",
    "def plot_bars(data, title, ylabel, std_data=[], log_scale=False, ax=None, cmap=colormaps['viridis']):\n",
    "\tn_values = list(data.keys())\n",
    "\talgorithms = list(data[n_values[0]].keys())\n",
    "\n",
    "\tx = np.arange(len(n_values))  # The x positions for the groups\n",
    "\tbar_width = 0.2  # Width of the bars\n",
    "\n",
    "\tif ax is None:\n",
    "\t\tfig, ax = plt.subplots(figsize=(5, 4))\n",
    "\n",
    "\t# Fill missing values with 0\n",
    "\tfor i, sec in enumerate(data):\n",
    "\t\tfor alg in algorithms:\n",
    "\t\t\tif alg not in data[sec]:\n",
    "\t\t\t\tdata[sec][alg] = 0\n",
    "\n",
    "\tfor i, sec in enumerate(std_data):\n",
    "\t\tfor alg in algorithms:\n",
    "\t\t\tif alg not in std_data[sec]:\n",
    "\t\t\t\tstd_data[sec][alg] = 0\n",
    "\n",
    "\tvalues = {alg: [data[sec][alg] for sec in data] for alg in algorithms}\n",
    "\tif len(std_data):\n",
    "\t\tstd_devs = {alg: [std_data[sec][alg] for sec in std_data] for alg in algorithms}\n",
    "\n",
    "\tcolors = [cmap(i / len(algorithms)) for i in range(len(algorithms))]\n",
    "\n",
    "\tfor i, (alg, color) in enumerate(zip(algorithms, colors)):\n",
    "\t\tlabel = {'A_star': 'STRAP+Stack', 'Strap': 'STRAP', 'Sorp': 'SORP', 'Labbe': 'MCTS', 'LabbeS': 'MCTS+Stack'}.get(alg, alg)\n",
    "\t\tif len(std_data):\n",
    "\t\t\tax.bar(x + i * bar_width, values[alg], width=bar_width, color=color, label=label, yerr=std_devs[alg], capsize=5)\n",
    "\t\telse:\n",
    "\t\t\tax.bar(x + i * bar_width, values[alg], width=bar_width, color=color, label=label)\n",
    "\n",
    "\t# Formatting the plot\n",
    "\tax.set_xlabel('Number of Objects (n)')\n",
    "\tax.set_ylabel(ylabel)\n",
    "\tax.set_title(title)\n",
    "\tax.set_xticks(x + bar_width * (len(algorithms) - 1) / 2)\n",
    "\tax.set_xticklabels(n_values)\n",
    "\tax.legend(title='Algorithm')\n",
    "\n",
    "\t# Set y-axis to log scale if specified\n",
    "\tif log_scale:\n",
    "\t\tax.set_yscale('log')\n",
    "\n",
    "def compare_algs(mode, phi, grid_size, algs, n_values, refine=False):\n",
    "\truns = load_runs(mode, phi, algs, n_values, grid_size, refine=refine)\n",
    "\n",
    "\tcosts, times, steps = {}, {}, {}\n",
    "\tcosts_std, times_std, steps_std = {}, {}, {}  # Store standard deviations\n",
    "\n",
    "\tfor n in n_values:\n",
    "\t\tcosts[n], times[n], steps[n] = {}, {}, {}\n",
    "\t\tcosts_std[n], times_std[n], steps_std[n] = {}, {}, {}\n",
    "\n",
    "\t\tfor alg in runs[n]:\n",
    "\t\t\tcost_values = [run['cost'] for run in runs[n][alg]]\n",
    "\t\t\ttime_values = [run['elapsed_time'] for run in runs[n][alg]]\n",
    "\t\t\tstep_values = [run['steps'] for run in runs[n][alg]]\n",
    "\n",
    "\t\t\tcosts[n][alg] = np.mean(cost_values)\n",
    "\t\t\ttimes[n][alg] = np.mean(time_values)\n",
    "\t\t\tsteps[n][alg] = np.mean(step_values)\n",
    "\n",
    "\t\t\tcosts_std[n][alg] = np.std(cost_values)\n",
    "\t\t\ttimes_std[n][alg] = np.std(time_values)\n",
    "\t\t\tsteps_std[n][alg] = np.std(step_values)\n",
    "\n",
    "\tsns.set_style('whitegrid')\n",
    "\tfig, axs = plt.subplots(1, 2, figsize=(10, 4))\n",
    "\n",
    "\t# plot_bars(costs, 'Cost Comparison', 'Cost', ax=axs[0], cmap=colormaps['tab20b'])\n",
    "\t# plot_bars(times, 'Time Comparison', 'Time (log scale)', log_scale=True, ax=axs[1], cmap=colormaps['tab20b'])\n",
    "\tplot_bars(costs, 'Cost Comparison', 'Cost', ax=axs[0], cmap=colormaps['tab20b'], std_data=costs_std)\n",
    "\tplot_bars(times, 'Time Comparison', 'Time (log scale)', log_scale=True, ax=axs[1], cmap=colormaps['tab20b'])\n",
    "\n",
    "\tplt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "\tplt.tight_layout()\n",
    "\tif mode == 'manipulator':\t\n",
    "\t\tplt.suptitle(f'Mode: Stationary | φ = {phi[1:]}', fontsize=16, fontweight='bold')\n",
    "\telse:\n",
    "\t\tplt.suptitle(f'Mode: Mobile | φ = {phi[1:]}', fontsize=16, fontweight='bold')\n",
    "\tplt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_graphs = 15\n",
    "grid_size = 30\n",
    "ratio = 0.5\n",
    "phi = f'r{ratio}'\n",
    "mode = 'manipulator'\n",
    "num_nodes = 4\n",
    "env = ContinuousEnv(mode=mode, num_nodes=num_nodes, grid_size=grid_size, verbose=0)\n",
    "# graphs = make_graphs(env, num_graphs, stack=False, ratio=ratio)\n",
    "# save_graphs(phi, graphs, num_nodes, grid_size)\n",
    "graphs = load_graphs(phi, num_nodes, grid_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_runs(mode, phi, env, graphs, Labbe, \"Labbe\", verbose=0)\n",
    "save_runs(mode, phi, env, graphs, Sorp, \"Sorp\", iterations=1000, num_buffers=4, c=1, verbose=0)\n",
    "# save_runs(mode, phi, env, graphs, Sorp, \"Sorp_c2\", iterations=1000, num_buffers=4, c=2, verbose=0)\n",
    "save_runs(mode, phi, env, graphs, Sorp2, \"Sorp2\", iterations=1000, num_buffers=4, c=1, verbose=0)\n",
    "# save_runs(mode, phi, env, graphs, Sorp2, \"Sorp2_c2\", iterations=1000, num_buffers=4, c=2, verbose=0)\n",
    "save_runs(mode, phi, env, graphs, Strap, \"Strap\", num_buffers=4, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_nodes = 5\n",
    "env = ContinuousEnv(mode=mode, num_nodes=num_nodes, grid_size=grid_size, verbose=0)\n",
    "# graphs = make_graphs(env, num_graphs, stack=False, ratio=ratio)\n",
    "# save_graphs(phi, graphs, num_nodes, grid_size)\n",
    "graphs = load_graphs(phi, num_nodes, grid_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_runs(mode, phi, env, graphs, Labbe, \"Labbe\", verbose=0)\n",
    "save_runs(mode, phi, env, graphs, Sorp, \"Sorp\", iterations=1000, num_buffers=4, c=1, verbose=0)\n",
    "# save_runs(mode, phi, env, graphs, Sorp, \"Sorp_c2\", iterations=1000, num_buffers=4, c=2, verbose=0)\n",
    "# save_runs(mode, phi, env, graphs, Sorp2, \"Sorp2\", iterations=1000, num_buffers=4, c=1, verbose=0)\n",
    "# save_runs(mode, phi, env, graphs, Sorp2, \"Sorp2_c2\", iterations=1000, num_buffers=4, c=2, verbose=0)\n",
    "save_runs(mode, phi, env, graphs, Strap, \"Strap\", num_buffers=4, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phi = 'r0.5'\n",
    "grid_size = 30\n",
    "algs = ['Sorp', 'Strap']\n",
    "n_values = [3, 4, 5, 6]\n",
    "mode = 'mobile'\n",
    "compare_algs(mode, phi, grid_size, algs, n_values, refine=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mode = 'manipulator'\n",
    "compare_algs(mode, phi, grid_size, algs, n_values, refine=False)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
