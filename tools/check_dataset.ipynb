{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "943f521a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking scene IDs 1 to 2500...\n",
      "Found 2500 existing folders\n",
      "Missing 0 folders\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checking folder contents: 100%|██████████| 2500/2500 [00:00<00:00, 11644.07it/s]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== FOLDER COMPLETENESS SUMMARY ===\n",
      "Expected scenes: 2500\n",
      "Existing folders: 2500\n",
      "Complete folders: 2500\n",
      "Missing folders: 0\n",
      "Incomplete folders: 0\n",
      "Total problematic: 0\n",
      "Completion rate: 100.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checking for black images: 100%|██████████| 2500/2500 [01:11<00:00, 35.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== COMBINED SUMMARY ===\n",
      "File completeness issues: 0\n",
      "Black image issues: 0\n",
      "Total unique problematic scenes: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from collections import Counter\n",
    "from tqdm import tqdm\n",
    "import shutil\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "def check_folder_file_completeness(dataset_dir, save_problematic=True, max_scene_id=2500):\n",
    "    required_files = {\n",
    "        'initial_image.png',\n",
    "        'initial_labels.json', \n",
    "        'meta.json',\n",
    "        'target_image.png',\n",
    "        'target_labels.json'\n",
    "    }\n",
    "    \n",
    "    # Get all existing rearrangement directories\n",
    "    existing_dirs = [d for d in os.listdir(dataset_dir) \n",
    "                    if d.startswith('rearrangement_') and os.path.isdir(os.path.join(dataset_dir, d))]\n",
    "    \n",
    "    # Extract existing scene IDs\n",
    "    existing_scene_ids = set()\n",
    "    for dir_name in existing_dirs:\n",
    "        scene_id = int(dir_name.replace('rearrangement_', ''))\n",
    "        existing_scene_ids.add(scene_id)\n",
    "    \n",
    "    # Find missing scene IDs\n",
    "    all_expected_ids = set(range(1, max_scene_id + 1))\n",
    "    missing_scene_ids = all_expected_ids - existing_scene_ids\n",
    "    \n",
    "    complete_folders = []\n",
    "    incomplete_folders = []\n",
    "    folder_issues = {}\n",
    "    \n",
    "    print(f\"Checking scene IDs 1 to {max_scene_id}...\")\n",
    "    print(f\"Found {len(existing_dirs)} existing folders\")\n",
    "    print(f\"Missing {len(missing_scene_ids)} folders\")\n",
    "    \n",
    "    # Add missing folders to problematic list\n",
    "    for scene_id in missing_scene_ids:\n",
    "        folder_issues[str(scene_id)] = \"Missing folder\"\n",
    "        incomplete_folders.append(str(scene_id))\n",
    "    \n",
    "    # Check existing folders for file completeness\n",
    "    for scene_dir in tqdm(existing_dirs, desc=\"Checking folder contents\"):\n",
    "        scene_path = os.path.join(dataset_dir, scene_dir)\n",
    "        scene_id = str(int(scene_dir.replace('rearrangement_', '')))\n",
    "        \n",
    "        try:\n",
    "            files_in_folder = set(os.listdir(scene_path))\n",
    "        except Exception as e:\n",
    "            folder_issues[scene_id] = f\"Error reading folder: {e}\"\n",
    "            incomplete_folders.append(scene_id)\n",
    "            continue\n",
    "        \n",
    "        missing_files = required_files - files_in_folder\n",
    "        extra_files = files_in_folder - required_files\n",
    "        \n",
    "        # A folder is problematic if it has missing files OR extra files\n",
    "        if missing_files or extra_files:\n",
    "            issues = []\n",
    "            if missing_files:\n",
    "                issues.append(f\"Missing: {sorted(missing_files)}\")\n",
    "            if extra_files:\n",
    "                issues.append(f\"Extra: {sorted(extra_files)}\")\n",
    "            \n",
    "            incomplete_folders.append(scene_id)\n",
    "            folder_issues[scene_id] = \"; \".join(issues)\n",
    "        else:\n",
    "            complete_folders.append(scene_id)\n",
    "    \n",
    "    if save_problematic and incomplete_folders:\n",
    "        with open('problematic_scene_ids.txt', 'w') as f:\n",
    "            f.write(f\"# Problematic Scene IDs (1-{max_scene_id})\\n\")\n",
    "            f.write(f\"# Total problematic: {len(incomplete_folders)}\\n\")\n",
    "            f.write(f\"# Missing folders: {len(missing_scene_ids)}\\n\")\n",
    "            f.write(f\"# Incomplete folders: {len(incomplete_folders) - len(missing_scene_ids)}\\n\")\n",
    "            f.write(\"#\" + \"=\"*50 + \"\\n\")\n",
    "            \n",
    "            for scene_id in sorted(incomplete_folders, key=int):\n",
    "                issue = folder_issues.get(scene_id, \"Unknown issue\")\n",
    "                f.write(f\"{scene_id}  # {issue}\\n\")\n",
    "        print(f\"Saved {len(incomplete_folders)} problematic scene IDs to 'problematic_scene_ids.txt'\")\n",
    "    \n",
    "    print(f\"\\n=== FOLDER COMPLETENESS SUMMARY ===\")\n",
    "    print(f\"Expected scenes: {max_scene_id}\")\n",
    "    print(f\"Existing folders: {len(existing_dirs)}\")\n",
    "    print(f\"Complete folders: {len(complete_folders)}\")\n",
    "    print(f\"Missing folders: {len(missing_scene_ids)}\")\n",
    "    print(f\"Incomplete folders: {len(incomplete_folders) - len(missing_scene_ids)}\")\n",
    "    print(f\"Total problematic: {len(incomplete_folders)}\")\n",
    "    print(f\"Completion rate: {len(complete_folders)/max_scene_id*100:.2f}%\")\n",
    "    \n",
    "    if folder_issues:\n",
    "        print(f\"\\n=== SAMPLE FOLDER ISSUES ===\")\n",
    "        sample_issues = list(folder_issues.items())[:10]\n",
    "        for scene_id, issue in sample_issues:\n",
    "            print(f\"Scene {scene_id}: {issue}\")\n",
    "        if len(folder_issues) > 10:\n",
    "            print(f\"... and {len(folder_issues) - 10} more folders with issues\")\n",
    "    \n",
    "    return {\n",
    "        'complete_scene_ids': sorted([int(x) for x in complete_folders]),\n",
    "        'incomplete_scene_ids': sorted([int(x) for x in incomplete_folders]),\n",
    "        'missing_scene_ids': sorted(list(missing_scene_ids)),\n",
    "        'folder_issues': folder_issues\n",
    "    }\n",
    "\n",
    "def load_problematic_scene_ids(txt_file):\n",
    "    scene_ids = []\n",
    "    \n",
    "    if not os.path.exists(txt_file):\n",
    "        print(f\"File {txt_file} not found!\")\n",
    "        return scene_ids\n",
    "    \n",
    "    with open(txt_file, 'r') as f:\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            if line.startswith('#') or not line:\n",
    "                continue\n",
    "            scene_id = line.split('#')[0].strip()\n",
    "            if scene_id.isdigit():\n",
    "                scene_ids.append(scene_id)\n",
    "    \n",
    "    return scene_ids\n",
    "\n",
    "def is_image_black(image_path, threshold: float = 0.01) -> bool:\n",
    "    \"\"\"Check if an image is completely black.\"\"\"\n",
    "    try:\n",
    "        image = Image.open(image_path)\n",
    "        img_array = np.array(image) / 255.0\n",
    "        return np.mean(img_array) < threshold\n",
    "    except Exception as e:\n",
    "        print(f\"Error checking image {image_path}: {e}\")\n",
    "        return False\n",
    "\n",
    "def find_black_image_scenes(dataset_dir):\n",
    "    rearrangement_dirs = [d for d in os.listdir(dataset_dir) \n",
    "                         if d.startswith('rearrangement_') and os.path.isdir(os.path.join(dataset_dir, d))]\n",
    "    \n",
    "    problematic_scenes = []\n",
    "    \n",
    "    for scene_dir in tqdm(rearrangement_dirs, desc=\"Checking for black images\"):\n",
    "        scene_path = os.path.join(dataset_dir, scene_dir)\n",
    "        scene_id = str(int(scene_dir.replace('rearrangement_', '')))\n",
    "        \n",
    "        initial_img = os.path.join(scene_path, 'initial_image.png')\n",
    "        target_img = os.path.join(scene_path, 'target_image.png')\n",
    "        \n",
    "        initial_black = os.path.exists(initial_img) and is_image_black(initial_img)\n",
    "        target_black = os.path.exists(target_img) and is_image_black(target_img)\n",
    "        \n",
    "        if initial_black or target_black:\n",
    "            problematic_scenes.append(scene_id)\n",
    "    \n",
    "    return problematic_scenes\n",
    "\n",
    "def create_combined_report(dataset_dir, report_file, check_black_images: bool = True, max_scene_id: int = 2500):\n",
    "    # Get file completeness issues\n",
    "    file_completeness_result = check_folder_file_completeness(dataset_dir, save_problematic=False, max_scene_id=max_scene_id)\n",
    "    \n",
    "    # Get black image issues if enabled\n",
    "    black_image_scenes = []\n",
    "    if check_black_images:\n",
    "        black_image_scenes = find_black_image_scenes(dataset_dir)\n",
    "    \n",
    "    # Combine problematic scene IDs\n",
    "    all_problematic = set(map(str, file_completeness_result['incomplete_scene_ids'])) | set(black_image_scenes)\n",
    "    folder_issues = file_completeness_result['folder_issues'].copy()\n",
    "    \n",
    "    # Add black image issues\n",
    "    for scene_id in black_image_scenes:\n",
    "        if scene_id not in folder_issues:\n",
    "            folder_issues[scene_id] = \"Black images\"\n",
    "        else:\n",
    "            folder_issues[scene_id] += \"; Black images\"\n",
    "    \n",
    "    # Save combined report\n",
    "    if all_problematic:\n",
    "        with open(report_file, 'w') as f:\n",
    "            f.write(f\"# Problematic Scene IDs (File Issues{' + Black Images' if check_black_images else ''})\\n\")\n",
    "            f.write(f\"# Total problematic: {len(all_problematic)}\\n\")\n",
    "            f.write(f\"# File issues: {len(file_completeness_result['incomplete_scene_ids'])}\\n\")\n",
    "            if check_black_images:\n",
    "                f.write(f\"# Black images: {len(black_image_scenes)}\\n\")\n",
    "            f.write(\"#\" + \"=\"*50 + \"\\n\")\n",
    "            \n",
    "            for scene_id in sorted(all_problematic, key=int):\n",
    "                issue = folder_issues.get(scene_id, \"Unknown issue\")\n",
    "                f.write(f\"{scene_id}  # {issue}\\n\")\n",
    "        print(f\"Saved {len(all_problematic)} problematic scene IDs to '{report_file}'\")\n",
    "    \n",
    "    print(f\"\\n=== COMBINED SUMMARY ===\")\n",
    "    print(f\"File completeness issues: {len(file_completeness_result['incomplete_scene_ids'])}\")\n",
    "    if check_black_images:\n",
    "        print(f\"Black image issues: {len(black_image_scenes)}\")\n",
    "    print(f\"Total unique problematic scenes: {len(all_problematic)}\")\n",
    "    \n",
    "    return all_problematic\n",
    "\n",
    "dataset_dir = \"dataset-sim\"\n",
    "report_file = \"problematic_scene_ids.txt\"\n",
    "\n",
    "# Remove the report file if it exists\n",
    "if os.path.exists(report_file):\n",
    "    os.remove(report_file)\n",
    "    print(f\"Removed existing {report_file}\")\n",
    "\n",
    "# Create combined report with black image checking enabled\n",
    "all_problematic = create_combined_report(dataset_dir, report_file, check_black_images=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c579ca8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== DRY RUN ===\n",
      "File problematic_scene_ids.txt not found!\n",
      "No problematic scene IDs found in the file.\n"
     ]
    }
   ],
   "source": [
    "def remove_scenes_from_file(dataset_dir, txt_file, dry_run: bool = True):\n",
    "    problematic_scene_ids = load_problematic_scene_ids(txt_file)\n",
    "    \n",
    "    if not problematic_scene_ids:\n",
    "        print(\"No problematic scene IDs found in the file.\")\n",
    "        return\n",
    "    \n",
    "    print(f\"Loaded {len(problematic_scene_ids)} scene IDs from {txt_file}\")\n",
    "    \n",
    "    removed_count = 0\n",
    "    not_found_count = 0\n",
    "    \n",
    "    for scene_id in tqdm(problematic_scene_ids, desc=\"Processing scenes\"):\n",
    "        folder_name = f\"rearrangement_{scene_id.zfill(5)}\"\n",
    "        folder_path = os.path.join(dataset_dir, folder_name)\n",
    "        \n",
    "        if os.path.exists(folder_path):\n",
    "            if dry_run:\n",
    "                print(f\"Would remove: {folder_path}\")\n",
    "            else:\n",
    "                try:\n",
    "                    shutil.rmtree(folder_path)\n",
    "                    print(f\"Removed: {folder_path}\")\n",
    "                    removed_count += 1\n",
    "                except Exception as e:\n",
    "                    print(f\"Error removing {folder_path}: {e}\")\n",
    "        else:\n",
    "            not_found_count += 1\n",
    "    \n",
    "    print(f\"\\n=== REMOVAL SUMMARY ===\")\n",
    "    if dry_run:\n",
    "        print(f\"DRY RUN: Found {len(problematic_scene_ids)} scenes to process\")\n",
    "        print(f\"Folders that would be removed: {len(problematic_scene_ids) - not_found_count}\")\n",
    "        print(f\"Missing folders (already absent): {not_found_count}\")\n",
    "        print(\"Set dry_run=False to actually delete the folders.\")\n",
    "    else:\n",
    "        print(f\"Successfully removed: {removed_count} folders\")\n",
    "        print(f\"Missing folders (already absent): {not_found_count}\")\n",
    "        print(f\"Total processed: {len(problematic_scene_ids)}\")\n",
    "\n",
    "# First do a dry run to see what would be deleted (run in problematic version)\n",
    "print(\"=== DRY RUN ===\")\n",
    "remove_scenes_from_file(dataset_dir, report_file, dry_run=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "021fa1c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File problematic_scene_ids.txt not found!\n",
      "No problematic scene IDs found in the file.\n"
     ]
    }
   ],
   "source": [
    "def copy_problematic_scenes_to_folder(dataset_dir, output_dir, txt_file):\n",
    "    problematic_scene_ids = load_problematic_scene_ids(txt_file)\n",
    "    \n",
    "    if not problematic_scene_ids:\n",
    "        print(\"No problematic scene IDs found in the file.\")\n",
    "        return\n",
    "    \n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    print(f\"Created output directory: {output_dir}\")\n",
    "    \n",
    "    copied_count = 0\n",
    "    not_found_count = 0\n",
    "    \n",
    "    for scene_id in tqdm(problematic_scene_ids, desc=\"Copying scenes\"):\n",
    "        folder_name = f\"rearrangement_{scene_id.zfill(5)}\"\n",
    "        source_path = os.path.join(dataset_dir, folder_name)\n",
    "        dest_path = os.path.join(output_dir, folder_name)\n",
    "        \n",
    "        if os.path.exists(source_path):\n",
    "            try:\n",
    "                shutil.copytree(source_path, dest_path)\n",
    "                copied_count += 1\n",
    "            except Exception as e:\n",
    "                print(f\"Error copying {source_path}: {e}\")\n",
    "        else:\n",
    "            not_found_count += 1\n",
    "    \n",
    "    print(f\"\\n=== COPY SUMMARY ===\")\n",
    "    print(f\"Successfully copied: {copied_count} folders\")\n",
    "    print(f\"Missing folders (not found): {not_found_count}\")\n",
    "    print(f\"Total processed: {len(problematic_scene_ids)}\")\n",
    "\n",
    "# Copy problematic scenes to a separate folder (run in correct version)\n",
    "copy_problematic_scenes_to_folder(dataset_dir, output_dir=\"problematic_scenes\", txt_file=report_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
