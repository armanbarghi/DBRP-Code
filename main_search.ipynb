{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import json\n",
    "import torch\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import seaborn as sns\n",
    "import cProfile, pstats\n",
    "from pandas.api.types import CategoricalDtype\n",
    "from matplotlib import colormaps\n",
    "\n",
    "from core.env.scene_manager import Indices, SceneManager, show_valid_score_map, draw_dependency_graph\n",
    "from core.planners.utils import env_cost, evaluate_alg, plan_refinement\n",
    "from core.planners.Labbe import Labbe, Labbe_S\n",
    "from core.planners.Strap import StrapGA, StrapGA_S\n",
    "\n",
    "phi = 0.2\n",
    "num_objects = 6\n",
    "grid_size = (100, 100)\n",
    "\n",
    "env = SceneManager(\n",
    "\tmode='stationary', num_objects=num_objects, \n",
    "\tgrid_size=grid_size, phi=phi, verbose=1\n",
    ")\n",
    "env.reset(use_stack=False, use_sides=False)\n",
    "initial_scene, target_scene = env.initial_x.clone(), env.target_x.clone()\n",
    "env.reset(initial_scene, target_scene)\n",
    "env.render(show_manipulator=True, fig_size=3)\n",
    "show_valid_score_map(env, obj=0)\n",
    "# show_valid_score_map(env, obj=0)\n",
    "# draw_dependency_graph(env, fig_size=(3, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# num_runs = 1\n",
    "# score_sorting = False\n",
    "# num_buffers = 4\n",
    "# time_limit = 20\n",
    "# static_stack = False\n",
    "\n",
    "# prof = cProfile.Profile()\n",
    "# prof.enable()\n",
    "# evaluate_alg(\n",
    "# \tenv, StrapGA_S, initial_scene, target_scene, \n",
    "# \tnum_runs=num_runs, score_sorting=score_sorting, static_stack=static_stack,\n",
    "# \tnum_buffers=num_buffers, time_limit=time_limit\n",
    "# );\n",
    "# prof.disable()\n",
    "# pstats.Stats(prof).sort_stats('tottime').print_stats(30);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plan = evaluate_alg(env, Labbe_S, initial_scene, target_scene, num_runs=1, c=0.1, time_limit=20)\n",
    "# print('-----')\n",
    "# plan_refinement(env, plan, initial_scene, target_scene, refine_mode=\"move\", verbose=1)\n",
    "# print('-----')\n",
    "# plan_refinement(env, plan, initial_scene, target_scene, refine_mode=\"stack\", verbose=1);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--n: 3-- (existing: 40, need: 0)\n",
      "  Already have 40 scenes (target: 5)\n",
      "--n: 4-- (existing: 40, need: 0)\n",
      "  Already have 40 scenes (target: 5)\n",
      "--n: 5-- (existing: 40, need: 0)\n",
      "  Already have 40 scenes (target: 5)\n",
      "--n: 6-- (existing: 40, need: 0)\n",
      "  Already have 40 scenes (target: 5)\n",
      "--n: 7-- (existing: 40, need: 0)\n",
      "  Already have 40 scenes (target: 5)\n",
      "--n: 8-- (existing: 40, need: 0)\n",
      "  Already have 40 scenes (target: 5)\n"
     ]
    }
   ],
   "source": [
    "from core.env.scene_utils import SceneCreator\n",
    "config = {\n",
    "    \"num_cases\": 5,\n",
    "    \"phi\": 0.5,\n",
    "    \"grid_size\": (100, 100),\n",
    "    \"n_values\": [3, 4, 5, 6, 7, 8],\n",
    "    \"use_stack\": False,\n",
    "    \"use_sides\": False,\n",
    "    \"verbose\": 1\n",
    "}\n",
    "\n",
    "creator = SceneCreator(config)\n",
    "creator.create_scenes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from core.env.scene_utils import load_scene_metas, scene_meta_to_x\n",
    "\n",
    "def save_runs(scene_metas, env, phi, alg, file_name, num_runs=1, **kwargs):\n",
    "\tdir_path = f'abstract_scenes/runs/phi_{phi}/{env.mode}/g{env.grid_size[0]}.{env.grid_size[1]}/n{env.N}'\n",
    "\tos.makedirs(dir_path, exist_ok=True)\n",
    "\t\n",
    "\tdata_path = os.path.join(dir_path, f'{file_name}.csv')\n",
    "\n",
    "\tfile_exists = os.path.exists(data_path)\n",
    "\tif file_exists:\n",
    "\t\tdf = pd.read_csv(data_path, converters={\n",
    "\t\t\t'plans': eval, 'steps': eval,\n",
    "\t\t\t'elapsed_times': eval, 'costs': eval\n",
    "\t\t})\n",
    "\telse:\n",
    "\t\tdf = pd.DataFrame()\n",
    "\n",
    "\tprint(f'----{alg.__name__}:{file_name}----')\n",
    "\ttotal_runs = len(scene_metas) * num_runs\n",
    "\tpbar = tqdm(total=total_runs, unit='run')\n",
    "\n",
    "\tfor scene_idx, scene_meta in enumerate(scene_metas):\n",
    "\t\tscene_id = scene_meta['scene_id']\n",
    "\t\talready_num_runs = 0\n",
    "\t\tremaining_num_runs = num_runs\n",
    "\t\tif file_exists and scene_id in df['scene_id'].values:\n",
    "\t\t\tidx = df.index[df['scene_id'] == scene_id][0]\n",
    "\t\t\talready_num_runs = len(df.at[idx, 'plans'])\n",
    "\t\t\tremaining_num_runs = num_runs - already_num_runs\n",
    "\t\t\tpbar.update(already_num_runs)\n",
    "\t\t\tif remaining_num_runs <= 0:\n",
    "\t\t\t\tpbar.set_description(f'Skipping scene {scene_id} - already solved {already_num_runs} times')\n",
    "\t\t\t\tcontinue\n",
    "\n",
    "\t\tfor run_idx in range(1, remaining_num_runs + 1):\n",
    "\t\t\tpbar.set_description(f'Scene {scene_idx}/{len(scene_metas)} - Run {run_idx+already_num_runs}/{num_runs}')\n",
    "\n",
    "\t\t\tinitial_x, target_x = scene_meta_to_x(scene_meta)\n",
    "\t\t\tinitial_x, target_x = initial_x.to(torch.long), target_x.to(torch.long)\n",
    "\t\t\tenv.reset(initial_x, target_x)\n",
    "\t\t\tplan, step, elapsed_time = alg(env).solve(**kwargs)\n",
    "\t\t\tcost = env_cost(env, plan, initial_x, target_x, log=False)\n",
    "\n",
    "\t\t\tif file_exists and scene_id in df['scene_id'].values:\n",
    "\t\t\t\tidx = df.index[df['scene_id'] == scene_id][0]\n",
    "\t\t\t\tdf.at[idx, 'plans'] += [plan]\n",
    "\t\t\t\tdf.at[idx, 'steps'] += [step]\n",
    "\t\t\t\tdf.at[idx, 'elapsed_times'] += [elapsed_time]\n",
    "\t\t\t\tdf.at[idx, 'costs'] += [cost]\n",
    "\t\t\telse:\n",
    "\t\t\t\tnew_row = pd.DataFrame([{\n",
    "\t\t\t\t\t'scene_id': scene_id,\n",
    "\t\t\t\t\t'mode': env.mode,\n",
    "\t\t\t\t\t'n': scene_meta['num_objects'],\n",
    "\t\t\t\t\t'grid_size': scene_meta['grid_size'],\n",
    "\t\t\t\t\t'alg': file_name,\n",
    "\t\t\t\t\t'plans': [plan],\n",
    "\t\t\t\t\t'steps': [step],\n",
    "\t\t\t\t\t'elapsed_times': [elapsed_time],\n",
    "\t\t\t\t\t'costs': [cost],\n",
    "\t\t\t\t}])\n",
    "\t\t\t\tdf = pd.concat([df, new_row], ignore_index=True)\n",
    "\n",
    "\t\t\t# Sort and save\n",
    "\t\t\tdf = df.sort_values(by='scene_id').reset_index(drop=True)\n",
    "\t\t\tdf.to_csv(data_path, index=False)\n",
    "\t\t\tfile_exists = True\n",
    "\n",
    "\t\t\tpbar.update(1)\n",
    "\t\tpbar.set_description(f'Scene {scene_idx}/{len(scene_metas)} - Run {run_idx+already_num_runs}/{num_runs}')\n",
    "\t\t\n",
    "\tpbar.close()\n",
    "\n",
    "def run_(num_runs, mode, num_objects, grid_size, phi, time_limit):\n",
    "\tnum_buffers = 4\n",
    "\tenv = SceneManager(\n",
    "\t\tmode=mode, num_objects=num_objects, \n",
    "\t\tgrid_size=grid_size, phi=phi, verbose=0\n",
    "\t)\n",
    "\n",
    "\tscene_metas = load_scene_metas(num_objects, grid_size, phi)\n",
    "\n",
    "\tsave_runs(scene_metas, env, phi, Labbe, \"Labbe\", num_runs=num_runs, \n",
    "\t\tc=0.1, time_limit=time_limit\n",
    "\t)\n",
    "\tsave_runs(scene_metas, env, phi, Labbe_S, \"Labbe+S\", num_runs=num_runs, \n",
    "\t\tc=0.1, time_limit=time_limit\n",
    "\t)\n",
    "\tsave_runs(scene_metas, env, phi, StrapGA, f\"StrapGA_{num_buffers}b\", num_runs=num_runs, \n",
    "\t\tnum_buffers=num_buffers, time_limit=time_limit\n",
    "\t)\n",
    "\tsave_runs(scene_metas, env, phi, StrapGA_S, f\"StrapGA+S_{num_buffers}b\", num_runs=num_runs, \n",
    "\t\tnum_buffers=num_buffers, time_limit=time_limit\n",
    "\t)\n",
    "\n",
    "\tsave_runs(scene_metas, env, phi, Labbe_S, \"Labbe+SS\", num_runs=num_runs, \n",
    "\t\tc=0.1, time_limit=time_limit, static_stack=True\n",
    "\t)\n",
    "\tsave_runs(scene_metas, env, phi, StrapGA_S, f\"StrapGA+SS_{num_buffers}b\", num_runs=num_runs, \n",
    "\t\tnum_buffers=num_buffers, time_limit=time_limit, static_stack=True\n",
    "\t)\n",
    "\n",
    "\t# print('-- Score Sorting --')\n",
    "\n",
    "\t# save_runs(scene_metas, env, phi, StrapGA, f\"StrapGA_sort_{num_buffers}b\", num_runs=num_runs, \n",
    "\t# \tnum_buffers=num_buffers, time_limit=time_limit, score_sorting=True\n",
    "\t# )\n",
    "\t# save_runs(scene_metas, env, phi, StrapGA_S, f\"StrapGA+S_sort_{num_buffers}b\", num_runs=num_runs, \n",
    "\t# \tnum_buffers=num_buffers, time_limit=time_limit, score_sorting=True\n",
    "\t# )\n",
    "\n",
    "\t# save_runs(scene_metas, env, phi, StrapGA_S, f\"StrapGA+SS_sort_{num_buffers}b\", num_runs=num_runs, \n",
    "\t# \tnum_buffers=num_buffers, time_limit=time_limit, static_stack=True, score_sorting=True\n",
    "\t# )\n",
    "\n",
    "phi = 0.2\n",
    "num_runs = 1\n",
    "time_limit = 360\n",
    "grid_size = (100, 100)\n",
    "mode = 'stationary'\n",
    "\n",
    "run_(num_runs=num_runs, mode=mode, num_objects=3, grid_size=grid_size, phi=phi, time_limit=time_limit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style('white')\n",
    "\n",
    "def load_runs(mode, grid_size, algs, n_values, phi, runs_dir='runs', refine_mode=None):\n",
    "\tall_dfs = []\n",
    "\n",
    "\tfor num_objects in n_values:\n",
    "\t\tfor alg_name in algs:\n",
    "\t\t\tfilename = f'{runs_dir}/phi_{phi}/{mode}/g{grid_size[0]}.{grid_size[1]}/n{num_objects}/{alg_name}.csv'\n",
    "\t\t\tif not os.path.isfile(filename):\n",
    "\t\t\t\tcontinue\n",
    "\n",
    "\t\t\t# Read CSV\n",
    "\t\t\tdf = pd.read_csv(filename)\n",
    "\n",
    "\t\t\tif refine_mode is not None:\n",
    "\t\t\t\t# Determine refinement algorithm based on alg_name\n",
    "\t\t\t\tif 'Labbe+SS' in alg_name or 'StrapGA+SS' in alg_name:\n",
    "\t\t\t\t\tstatic_stack = True\n",
    "\t\t\t\telif 'Labbe+S' in alg_name or 'StrapGA+S' in alg_name:\n",
    "\t\t\t\t\tstatic_stack = False\n",
    "\t\t\t\telse:\n",
    "\t\t\t\t\tstatic_stack = False\n",
    "\n",
    "\t\t\t\t# Create temporary environment for refinement\n",
    "\t\t\t\ttemp_env = SceneManager(\n",
    "\t\t\t\t\tmode=mode, num_objects=num_objects, grid_size=grid_size, \n",
    "\t\t\t\t\tstatic_stack=static_stack, phi=phi, verbose=0\n",
    "\t\t\t\t)\n",
    "\t\t\t\t\n",
    "\t\t\t\t# Process each row for refinement\n",
    "\t\t\t\tfor idx, row in df.iterrows():\n",
    "\t\t\t\t\tscene_id = row['scene_id']\n",
    "\t\t\t\t\tplans = eval(row['plans'])\n",
    "\t\t\t\t\tsteps = eval(row['steps'])\n",
    "\t\t\t\t\telapsed_times = eval(row['elapsed_times'])\n",
    "\t\t\t\t\tcosts = eval(row['costs'])\n",
    "\t\t\t\t\t\n",
    "\t\t\t\t\trefined_plans = []\n",
    "\t\t\t\t\trefined_costs = []\n",
    "\t\t\t\t\trefined_elapsed_times = []\n",
    "\t\t\t\t\t\n",
    "\t\t\t\t\t# Load the corresponding scene\n",
    "\t\t\t\t\tscene_filename = f'abstract_scenes/scenes/phi_{phi}/g{grid_size[0]}.{grid_size[1]}/n{num_objects}/scene_{scene_id:04d}.json'\n",
    "\t\t\t\t\tif os.path.exists(scene_filename):\n",
    "\t\t\t\t\t\twith open(scene_filename, 'r') as f:\n",
    "\t\t\t\t\t\t\tjson_scene = json.load(f)\n",
    "\t\t\t\t\t\tinitial_x, target_x = scene_json_to_x(json_scene)\n",
    "\t\t\t\t\t\t\n",
    "\t\t\t\t\t\t# Refine each run\n",
    "\t\t\t\t\t\tfor i, (plan, elapsed_time, cost) in enumerate(zip(plans, elapsed_times, costs)):\n",
    "\t\t\t\t\t\t\tif plan is not None and cost is not None:\n",
    "\t\t\t\t\t\t\t\ttemp_env.reset(initial_x, target_x)\n",
    "\t\t\t\t\t\t\t\t\n",
    "\t\t\t\t\t\t\t\trefined_plan, refined_cost, refinement_time = plan_refinement(\n",
    "\t\t\t\t\t\t\t\t\ttemp_env, plan, initial_x, target_x, refine_mode, verbose=0\n",
    "\t\t\t\t\t\t\t\t)\n",
    "\t\t\t\t\t\t\t\t\n",
    "\t\t\t\t\t\t\t\trefined_plans.append(refined_plan)\n",
    "\t\t\t\t\t\t\t\trefined_costs.append(refined_cost)\n",
    "\t\t\t\t\t\t\t\trefined_elapsed_times.append(elapsed_time + refinement_time)\n",
    "\t\t\t\t\t\t\telse:\n",
    "\t\t\t\t\t\t\t\t# Keep failed runs as they are\n",
    "\t\t\t\t\t\t\t\trefined_plans.append(plan)\n",
    "\t\t\t\t\t\t\t\trefined_costs.append(cost)\n",
    "\t\t\t\t\t\t\t\trefined_elapsed_times.append(elapsed_time)\n",
    "\t\t\t\t\telse:\n",
    "\t\t\t\t\t\tprint(f\"Warning: Scene file {scene_filename} not found. Skipping refinement for scene {scene_id}\")\n",
    "\t\t\t\t\t\trefined_plans = plans\n",
    "\t\t\t\t\t\trefined_costs = costs\n",
    "\t\t\t\t\t\trefined_elapsed_times = elapsed_times\n",
    "\t\t\t\t\t\n",
    "\t\t\t\t\t# Update the dataframe row\n",
    "\t\t\t\t\tdf.at[idx, 'plans'] = str(refined_plans)\n",
    "\t\t\t\t\tdf.at[idx, 'costs'] = str(refined_costs)\n",
    "\t\t\t\t\tdf.at[idx, 'elapsed_times'] = str(refined_elapsed_times)\n",
    "\n",
    "\t\t\t# calculate the mean not-None costs\n",
    "\t\t\tdf['cost'] = df['costs'].apply(lambda x: \n",
    "\t\t\t\tnp.mean([cost for cost in eval(x) if cost is not None]) \n",
    "\t\t\t\tif isinstance(eval(x), list) and any(cost is not None for cost in eval(x)) \n",
    "\t\t\t\telse np.nan\n",
    "\t\t\t)\n",
    "\t\t\tdf['step'] = df['steps'].apply(lambda x: np.mean([step for step in eval(x)]))\n",
    "\t\t\tdf['elapsed_time'] = df['elapsed_times'].apply(lambda x: np.mean([time for time in eval(x)]))\n",
    "\t\t\t# Add plan length calculation\n",
    "\t\t\tdf['plan_length'] = df['plans'].apply(lambda x: \n",
    "\t\t\t\tnp.mean([len(plan) for plan in eval(x) if plan is not None]) \n",
    "\t\t\t\tif isinstance(eval(x), list) and any(plan is not None for plan in eval(x)) \n",
    "\t\t\t\telse np.nan\n",
    "\t\t\t)\n",
    "\n",
    "\t\t\tall_dfs.append(df)\n",
    "\n",
    "\t# Merge all into one big DataFrame\n",
    "\tif all_dfs:\n",
    "\t\tmerged_df = pd.concat(all_dfs, ignore_index=True)\n",
    "\t\treturn merged_df\n",
    "\telse:\n",
    "\t\tprint(\"No valid run files found.\")\n",
    "\t\treturn pd.DataFrame()  # Return empty DF if nothing was loaded\n",
    "\n",
    "def process_algorithm_data(df, include_std=False):\n",
    "\t\"\"\"\n",
    "\tProcess algorithm comparison data and create pivot tables for plotting.\n",
    "\t\n",
    "\tParameters:\n",
    "\tdf: Input dataframe with algorithm results\n",
    "\tinclude_std: Whether to include standard deviation data\n",
    "\t\n",
    "\tReturns:\n",
    "\tdict: Contains all processed data organized by metric type\n",
    "\t\"\"\"\n",
    "\t# Filter successful runs (cost not null = successful run)\n",
    "\tdf['success'] = df['cost'].notna()\n",
    "\tdf_successful = df[df['success']].copy()\n",
    "\t\n",
    "\t# Preserve algorithm order as they appear in the dataframe\n",
    "\talg_order = df['alg'].drop_duplicates().tolist()\n",
    "\talg_dtype = CategoricalDtype(categories=alg_order, ordered=True)\n",
    "\tdf['alg'] = df['alg'].astype(alg_dtype)\n",
    "\tdf_successful['alg'] = df_successful['alg'].astype(alg_dtype)\n",
    "\t\n",
    "\t# Group data for aggregation\n",
    "\tgrouped_successful = df_successful.groupby(['n', 'alg'])\n",
    "\tgrouped_all = df.groupby(['n', 'alg'])\n",
    "\t\n",
    "\t# Calculate aggregated metrics for successful runs\n",
    "\tagg_successful = grouped_successful.agg(\n",
    "\t\tcost_mean=('cost', 'mean'),\n",
    "\t\tcost_std=('cost', 'std'),\n",
    "\t\tstep_mean=('step', 'mean'),\n",
    "\t\tstep_std=('step', 'std'),\n",
    "\t\ttime_mean=('elapsed_time', 'mean'),\n",
    "\t\ttime_std=('elapsed_time', 'std'),\n",
    "\t\tplan_length_mean=('plan_length', 'mean'),\n",
    "\t\tplan_length_std=('plan_length', 'std')\n",
    "\t).reset_index()\n",
    "\t\n",
    "\t# Calculate success rate using all runs\n",
    "\tagg_all = grouped_all.agg(\n",
    "\t\tsuccess_rate=('success', lambda x: 100 * x.sum() / len(x))\n",
    "\t).reset_index()\n",
    "\t\n",
    "\t# Ensure algorithm column ordering is preserved\n",
    "\tagg_successful['alg'] = agg_successful['alg'].astype(alg_dtype)\n",
    "\tagg_all['alg'] = agg_all['alg'].astype(alg_dtype)\n",
    "\t\n",
    "\t# Create pivot tables for plotting\n",
    "\tmean_data = {\n",
    "\t\t'cost': agg_successful.pivot(index='n', columns='alg', values='cost_mean')[alg_order],\n",
    "\t\t'step': agg_successful.pivot(index='n', columns='alg', values='step_mean')[alg_order],\n",
    "\t\t'time': agg_successful.pivot(index='n', columns='alg', values='time_mean')[alg_order],\n",
    "\t\t'plan_length': agg_successful.pivot(index='n', columns='alg', values='plan_length_mean')[alg_order],\n",
    "\t\t'success_rate': agg_all.pivot(index='n', columns='alg', values='success_rate')[alg_order]\n",
    "\t}\n",
    "\t\n",
    "\tstd_data = {}\n",
    "\tif include_std:\n",
    "\t\tstd_data = {\n",
    "\t\t\t'cost': agg_successful.pivot(index='n', columns='alg', values='cost_std')[alg_order],\n",
    "\t\t\t'step': agg_successful.pivot(index='n', columns='alg', values='step_std')[alg_order],\n",
    "\t\t\t'time': agg_successful.pivot(index='n', columns='alg', values='time_std')[alg_order],\n",
    "\t\t\t'plan_length': agg_successful.pivot(index='n', columns='alg', values='plan_length_std')[alg_order]\n",
    "\t\t}\n",
    "\t\n",
    "\treturn {\n",
    "\t\t'mean': mean_data,\n",
    "\t\t'std': std_data,\n",
    "\t\t'algorithm_order': alg_order\n",
    "\t}\n",
    "\n",
    "def draw_row(axs, data, std, sr, steps, plan_len, cmap):\n",
    "    \"\"\"Shared function to draw algorithm comparison plots in a row.\"\"\"\n",
    "    idx = 0\n",
    "    if plan_len:\n",
    "        plot_algorithm_bars(data['mean']['plan_length'], '# of Actions', '',\n",
    "                            data['std'].get('plan_length'), ax=axs[idx], cmap=cmap, show_legend=False)\n",
    "        idx += 1\n",
    "    plot_algorithm_bars(data['mean']['cost'], 'Travel Cost', '',\n",
    "                        data['std'].get('cost'), ax=axs[idx], cmap=cmap, show_legend=False)\n",
    "    idx += 1\n",
    "    plot_algorithm_bars(data['mean']['time'], 'Computation Time\\n(log scale)', '',\n",
    "                        data['std'].get('time'), log_scale=True, ax=axs[idx], cmap=cmap, show_legend=False)\n",
    "    idx += 1\n",
    "    if steps:\n",
    "        st = data['mean']['step'] / 1000\n",
    "        ss = data['std'].get('step') / 1000 if std and 'step' in data['std'] else None\n",
    "        plot_algorithm_bars(st, 'Step Comparison\\n(in thousands)', '', ss, ax=axs[idx], cmap=cmap, show_legend=False)\n",
    "        idx += 1\n",
    "    if sr:\n",
    "        plot_algorithm_bars(data['mean']['success_rate'], 'Success Rate (%)', '', ax=axs[idx], cmap=cmap, show_legend=False)\n",
    "\n",
    "def compare_algorithms_single_row(df, std=False, sr=False, steps=False, plan_len=False, title=''):\n",
    "    \"\"\"\n",
    "    Create a single row of comparison plots for algorithms.\n",
    "    \"\"\"\n",
    "    if df.empty:\n",
    "        print(\"No data to compare.\")\n",
    "        return {}\n",
    "\n",
    "    processed_data = process_algorithm_data(df, include_std=std)\n",
    "    mean_data, std_data = processed_data['mean'], processed_data['std']\n",
    "\n",
    "    return {'cost': mean_data['cost'], 'plan_length': mean_data['plan_length'], 'success_rate': mean_data['success_rate']}\n",
    "\n",
    "    num_plots = 2 + sum([sr, steps, plan_len])\n",
    "    plot_w, plot_h = 3.5, 3\n",
    "    fig_h = plot_h + 1.5  # increased for more spacing\n",
    "    fig = plt.figure(figsize=(num_plots * plot_w, fig_h))\n",
    "    gs = fig.add_gridspec(3, num_plots, height_ratios=[0.6, plot_h, 0.6], hspace=0.6)  # increased spacing\n",
    "\n",
    "    # Title row\n",
    "    ax_title = fig.add_subplot(gs[0, :])\n",
    "    ax_title.axis('off')\n",
    "    ax_title.text(0.5, 0.5, title, ha='center', va='center', fontsize=14)\n",
    "\n",
    "    # Plot row\n",
    "    axs = [fig.add_subplot(gs[1, i]) for i in range(num_plots)]\n",
    "    cmap = colormaps['tab10']\n",
    "    \n",
    "    # Use shared draw_row function\n",
    "    draw_row(axs, processed_data, std, sr, steps, plan_len, cmap)\n",
    "\n",
    "    # Legend row\n",
    "    ax_legend = fig.add_subplot(gs[2, :])\n",
    "    ax_legend.axis('off')\n",
    "    handles, labels = axs[0].get_legend_handles_labels()\n",
    "    ax_legend.legend(handles, labels, ncol=len(labels), loc='center')\n",
    "\n",
    "    plt.show()\n",
    "    return {'cost': mean_data['cost'], 'plan_length': mean_data['plan_length'], 'success_rate': mean_data['success_rate']}\n",
    "\n",
    "def compare_algorithms_double_row(df1, df2, std=False, sr=False, steps=False, plan_len=False,\n",
    "                                title1='', title2=''):\n",
    "    \"\"\"\n",
    "    Create two rows of comparison plots with identical plot-area sizes and consistent spacing.\n",
    "    \"\"\"\n",
    "    if df1.empty or df2.empty:\n",
    "        print(\"No data to compare.\")\n",
    "        return {}\n",
    "\n",
    "    d1 = process_algorithm_data(df1, include_std=std)\n",
    "    d2 = process_algorithm_data(df2, include_std=std)\n",
    "\n",
    "    num_plots = 2 + sum([sr, steps, plan_len])\n",
    "    plot_w, plot_h = 3.5, 3\n",
    "    fig_h = 2 * plot_h + 2.0  # increased for more spacing\n",
    "    fig = plt.figure(figsize=(num_plots * plot_w, fig_h))\n",
    "    gs = fig.add_gridspec(5, num_plots,\n",
    "                        height_ratios=[0.4, plot_h, 0.4, plot_h, 0.4],\n",
    "                        hspace=0.6)  # increased spacing\n",
    "\n",
    "    # Title1\n",
    "    ax_t1 = fig.add_subplot(gs[0, :]); ax_t1.axis('off')\n",
    "    ax_t1.text(0.5, 0.5, title1, ha='center', va='center', fontsize=14)\n",
    "    # Plots1\n",
    "    axs1 = [fig.add_subplot(gs[1, i]) for i in range(num_plots)]\n",
    "    # Title2\n",
    "    ax_t2 = fig.add_subplot(gs[2, :]); ax_t2.axis('off')\n",
    "    ax_t2.text(0.5, 0.5, title2, ha='center', va='center', fontsize=14)\n",
    "    # Plots2\n",
    "    axs2 = [fig.add_subplot(gs[3, i]) for i in range(num_plots)]\n",
    "    cmap = colormaps['tab10']\n",
    "    \n",
    "    # Use shared draw_row function for both rows\n",
    "    draw_row(axs1, d1, std, sr, steps, plan_len, cmap)\n",
    "    draw_row(axs2, d2, std, sr, steps, plan_len, cmap)\n",
    "\n",
    "    # Legend\n",
    "    ax_leg = fig.add_subplot(gs[4, :]); ax_leg.axis('off')\n",
    "    handles, labels = axs1[0].get_legend_handles_labels()\n",
    "    ax_leg.legend(handles, labels, ncol=len(labels), loc='center')\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "def plot_algorithm_bars(df, title, ylabel, std_data=None, log_scale=False, ax=None, cmap=None, show_legend=True):\n",
    "\t\"\"\"\n",
    "\tCreate bar plots for algorithm comparison with proper labeling.\n",
    "\t\n",
    "\tParameters:\n",
    "\tdf: Pivot table with algorithm data\n",
    "\ttitle: Plot title\n",
    "\tylabel: Y-axis label\n",
    "\tstd_data: Standard deviation data for error bars\n",
    "\tlog_scale: Whether to use log scale for y-axis\n",
    "\tax: Matplotlib axes object\n",
    "\tcmap: Color map for bars\n",
    "\tshow_legend: Whether to show legend\n",
    "\t\"\"\"\n",
    "\tif ax is None:\n",
    "\t\tfig, ax = plt.subplots(figsize=(6, 4))\n",
    "\n",
    "\tn_values = df.index.tolist()\n",
    "\talgorithms = df.columns.tolist()\n",
    "\tx = np.arange(len(n_values))\n",
    "\tbar_width = 0.12\n",
    "\n",
    "\tcolors = [cmap(i / len(algorithms)) for i in range(len(algorithms))]\n",
    "\n",
    "\t# Algorithm name mapping for cleaner labels\n",
    "\tlabel_mapping = {\n",
    "\t\t'StrapGA+S_4b': 'STRAP+DS',\n",
    "\t\t'StrapGA+SS_4b': 'STRAP+SS',\n",
    "\t\t'StrapGA_4b': 'STRAP',\n",
    "\t\t'Labbe': 'MCTS',\n",
    "\t\t'Labbe+S': 'MCTS+DS',\n",
    "\t\t'Labbe+SS': 'MCTS+SS'\n",
    "\t}\n",
    "\n",
    "\tfor i, alg in enumerate(algorithms):\n",
    "\t\tvalues = df[alg].values\n",
    "\t\terrors = std_data[alg].values if std_data is not None and alg in std_data.columns else None\n",
    "\t\tlabel = label_mapping.get(alg, alg)\n",
    "\n",
    "\t\tax.bar(x + i * bar_width, values, width=bar_width, color=colors[i], \n",
    "\t\t\tlabel=label, yerr=errors, capsize=5 if errors is not None else 0)\n",
    "\n",
    "\tax.set_xlabel('')\n",
    "\tax.set_ylabel(ylabel)\n",
    "\tax.set_title(title)\n",
    "\tax.set_xticks(x + bar_width * (len(algorithms) - 1) / 2)\n",
    "\tax.set_xticklabels(n_values)\n",
    "\t\n",
    "\tif show_legend:\n",
    "\t\tax.legend(title='Algorithm')\n",
    "\n",
    "\tif log_scale:\n",
    "\t\tax.set_yscale('log')\n",
    "\n",
    "\tax.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "\n",
    "# phi = 0.2\n",
    "# n_values = [4,5,6,7,8]\n",
    "# algs = [\"Labbe\", \"Labbe+S\", \"StrapGA_4b\", \"StrapGA+SS_4b\", \"StrapGA+S_4b\"]\n",
    "\n",
    "# mode = 'stationary'\n",
    "# grid_size = (100, 100)\n",
    "# df1 = load_runs(mode, grid_size, algs, n_values, phi, runs_dir='abstract_scenes/runs', refine=False)\n",
    "# title1 = f'{mode} | size = {grid_size} | φ = {phi}'\n",
    "\n",
    "# mode = 'mobile'\n",
    "# grid_size = (101, 201)\n",
    "# df2 = load_runs(mode, grid_size, algs, n_values, phi, runs_dir='abstract_scenes/runs', refine=False)\n",
    "# title2 = f'{mode} | size = {grid_size} | φ = {phi}'\n",
    "# compare_algorithms_double_row(df1, df2, plan_len=True, title1=title1, title2=title2);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def performance_improvement(df1, df2, alg1, alg2):\n",
    "\tESC1 = df1['cost'][alg1] / df1['success_rate'][alg1] * 100\n",
    "\tESC2 = df2['cost'][alg2] / df2['success_rate'][alg2] * 100\n",
    "\n",
    "\tOPS1 = ESC1.mean()\n",
    "\tOPS2 = ESC2.mean()\n",
    "\n",
    "\tPI = (OPS1 - OPS2) / OPS1 * 100\n",
    "\treturn PI\n",
    "\n",
    "dict_p = {\n",
    "\t'phis': [0.2, 0.2, 0.5],\n",
    "\t'modes': ['stationary', 'mobile', 'stationary'],\n",
    "\t'grid_sizes': [(100, 100), (101, 201), (100, 100)],\n",
    "}\n",
    "\n",
    "for phi, mode, grid_size in zip(dict_p['phis'], dict_p['modes'], dict_p['grid_sizes']):\n",
    "\n",
    "\tn_values = [4,5,6,7,8]\n",
    "\talgs = [\"Labbe\", \"Labbe+S\", \"StrapGA_4b\", \"StrapGA+SS_4b\", \"StrapGA+S_4b\"]\n",
    "\tdf = load_runs(mode, grid_size, algs, n_values, phi, runs_dir='abstract_scenes/runs')\n",
    "\tdata = compare_algorithms_single_row(df, plan_len=True, sr=True, title=f'{mode} | size = {grid_size} | φ = {phi}')\n",
    "\n",
    "\tfor key in data.keys():\n",
    "\t\tdata[key].columns = ['MCTS', 'MCTS+DS', 'STRAP', 'STRAP+SS', 'STRAP+DS']\n",
    "\t\tif phi == 0.5 and mode == 'stationary':\n",
    "\t\t\tdata[key] = data[key].drop(4)\n",
    "\n",
    "\tprint(f'--φ:{phi}, mode:{mode}--')\n",
    "\tPI = performance_improvement(data, data, 'STRAP', 'STRAP+SS')\n",
    "\tprint(f'STRAP+SS vs STRAP: {PI:.3f}%')\n",
    "\tPI = performance_improvement(data, data, 'STRAP', 'STRAP+DS')\n",
    "\tprint(f'STRAP+DS vs STRAP: {PI:.3f}%')\n",
    "\tPI = performance_improvement(data, data, 'STRAP', 'MCTS+DS')\n",
    "\tprint(f'MCTS+DS  vs STRAP: {PI:.3f}%')\n",
    "\tPI = performance_improvement(data, data, 'MCTS', 'MCTS+DS')\n",
    "\tprint(f'MCTS+DS  vs MCTS:  {PI:.3f}%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phi = 0.2\n",
    "mode = 'mobile'\n",
    "grid_size = (101, 201)\n",
    "\n",
    "n_values = [4,5,6,7,8]\n",
    "algs = [\"Labbe\", \"Labbe+S\", \"StrapGA_4b\", \"StrapGA+SS_4b\", \"StrapGA+S_4b\"]\n",
    "df = load_runs(mode, grid_size, algs, n_values, phi, runs_dir='abstract_scenes/runs')\n",
    "data = compare_algorithms_single_row(df, plan_len=True, sr=True, title=f'{mode} | size = {grid_size} | φ = {phi}')\n",
    "df = load_runs(mode, grid_size, algs, n_values, phi, runs_dir='abstract_scenes/runs', refine_mode=\"move\")\n",
    "data_move = compare_algorithms_single_row(df, plan_len=True, sr=True, title=f'{mode} | size = {grid_size} | φ = {phi}')\n",
    "df = load_runs(mode, grid_size, algs, n_values, phi, runs_dir='abstract_scenes/runs', refine_mode=\"stack\")\n",
    "data_stack = compare_algorithms_single_row(df, plan_len=True, sr=True, title=f'{mode} | size = {grid_size} | φ = {phi}')\n",
    "\n",
    "for key in data.keys():\n",
    "\tdata[key].columns = ['MCTS', 'MCTS+DS', 'STRAP', 'STRAP+SS', 'STRAP+DS']\n",
    "\tdata_move[key].columns = ['MCTS', 'MCTS+DS', 'STRAP', 'STRAP+SS', 'STRAP+DS']\n",
    "\tdata_stack[key].columns = ['MCTS', 'MCTS+DS', 'STRAP', 'STRAP+SS', 'STRAP+DS']\n",
    "\tif phi == 0.5 and mode == 'stationary':\n",
    "\t\tdata[key] = data[key].drop(4)\n",
    "\t\tdata_move[key] = data_move[key].drop(4)\n",
    "\t\tdata_stack[key] = data_stack[key].drop(4)\n",
    "\n",
    "print(f'--φ:{phi}, mode:{mode}--')\n",
    "print(f\"---------Refinement: Move---------\")\n",
    "PI = performance_improvement(data, data_move, 'MCTS', 'MCTS')\n",
    "print(f'MCTS:  {PI:.2f}%')\n",
    "PI = performance_improvement(data, data_move, 'MCTS+DS', 'MCTS+DS')\n",
    "print(f'MCTS+DS:  {PI:.2f}%')\n",
    "PI = performance_improvement(data, data_move, 'STRAP', 'STRAP')\n",
    "print(f'STRAP: {PI:.2f}%')\n",
    "PI = performance_improvement(data, data_move, 'STRAP+SS', 'STRAP+SS')\n",
    "print(f'STRAP+SS: {PI:.2f}%')\n",
    "PI = performance_improvement(data, data_move, 'STRAP+DS', 'STRAP+DS')\n",
    "print(f'STRAP+DS: {PI:.2f}%')\n",
    "print(f\"---------Refinement: Stack---------\")\n",
    "PI = performance_improvement(data, data_stack, 'MCTS', 'MCTS')\n",
    "print(f'MCTS:  {PI:.2f}%')\n",
    "PI = performance_improvement(data, data_stack, 'MCTS+DS', 'MCTS+DS')\n",
    "print(f'MCTS+DS:  {PI:.2f}%')\n",
    "PI = performance_improvement(data, data_stack, 'STRAP', 'STRAP')\n",
    "print(f'STRAP: {PI:.2f}%')\n",
    "PI = performance_improvement(data, data_stack, 'STRAP+SS', 'STRAP+SS')\n",
    "print(f'STRAP+SS: {PI:.2f}%')\n",
    "PI = performance_improvement(data, data_stack, 'STRAP+DS', 'STRAP+DS')\n",
    "print(f'STRAP+DS: {PI:.2f}%')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
